{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating your SAE\n",
    "\n",
    "Code based off Rob Graham's ([themachinefan](https://github.com/themachinefan)) SAE evaluation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/ViT-Prisma/src/vit_prisma/sae/evals'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_per_buffer (millions): 0.032\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 158691\n",
      "Total training images: 13000000\n",
      "Total wandb updates: 15869\n",
      "Expansion factor: 16\n",
      "n_tokens_per_feature_sampling_window (millions): 204.8\n",
      "n_tokens_per_dead_feature_window (millions): 1024.0\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 158 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Gradient clipping with max_norm=1.0\n",
      "Using SAE initialization method: encoder_transpose_decoder\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from vit_prisma.sae.config import VisionModelSAERunnerConfig\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EvalConfig(VisionModelSAERunnerConfig):\n",
    "    sae_path: str = '/workspace/sae_checkpoints/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-11-hook_resid_post-l1-0.0001/n_images_2600058.pt'\n",
    "    model_name: str = \"open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "    model_type: str =  \"clip\"\n",
    "    patch_size: str = 32\n",
    "\n",
    "    dataset_path = \"/workspace\"\n",
    "    dataset_train_path: str = \"/workspace/ILSVRC/Data/CLS-LOC/train\"\n",
    "    dataset_val_path: str = \"/workspace/ILSVRC/Data/CLS-LOC/val\"\n",
    "\n",
    "    verbose: bool = True\n",
    "\n",
    "    device: bool = 'cuda'\n",
    "\n",
    "    eval_max: int = 50_000 # 50_000\n",
    "    batch_size: int = 32\n",
    "\n",
    "    # make the max image output folder a subfolder of the sae path\n",
    "\n",
    "\n",
    "    @property\n",
    "    def max_image_output_folder(self) -> str:\n",
    "        # Get the base directory of sae_checkpoints\n",
    "        sae_base_dir = os.path.dirname(os.path.dirname(self.sae_path))\n",
    "        \n",
    "        # Get the name of the original SAE checkpoint folder\n",
    "        sae_folder_name = os.path.basename(os.path.dirname(self.sae_path))\n",
    "        \n",
    "        # Create a new folder path in sae_checkpoints/images with the original name\n",
    "        output_folder = os.path.join(sae_base_dir, 'max_images', sae_folder_name)\n",
    "        output_folder = os.path.join(output_folder, f\"layer_{self.hook_point_layer}\") # Add layer number\n",
    "\n",
    "        \n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        return output_folder\n",
    "\n",
    "cfg = EvalConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x78582d42ac50>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "Official model name open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "Converting OpenCLIP weights\n",
      "model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "visual projection shape torch.Size([768, 512])\n",
      "Setting center_writing_weights to False for OpenCLIP\n",
      "Setting fold_ln to False for OpenCLIP\n",
      "Loaded pretrained model open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from vit_prisma.models.base_vit import HookedViT\n",
    "\n",
    "model_name = \"open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "model = HookedViT.from_pretrained(model_name, is_timm=False, is_clip=True).to(cfg.device)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import vit_prisma\n",
    "# importlib.reload(vit_prisma.dataloaders.imagenet_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation data length: 50000\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "import open_clip\n",
    "from vit_prisma.utils.data_utils.imagenet_utils import setup_imagenet_paths\n",
    "from vit_prisma.dataloaders.imagenet_dataset import get_imagenet_transforms_clip, ImageNetValidationDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPProcessor\n",
    "\n",
    "og_model_name = \"hf-hub:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "og_model, _, preproc = open_clip.create_model_and_transforms(og_model_name)\n",
    "processor = preproc\n",
    "\n",
    "size=224\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                     std=[0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "    \n",
    "imagenet_paths = setup_imagenet_paths(cfg.dataset_path)\n",
    "imagenet_paths[\"train\"] = \"/workspace/ILSVRC/Data/CLS-LOC/train\"\n",
    "imagenet_paths[\"val\"] = \"/workspace/ILSVRC/Data/CLS-LOC/val\"\n",
    "imagenet_paths[\"val_labels\"] = \"/workspace/LOC_val_solution.csv\"\n",
    "imagenet_paths[\"label_strings\"] = \"/workspace/LOC_synset_mapping.txt\"\n",
    "print()\n",
    "train_data = torchvision.datasets.ImageFolder(cfg.dataset_train_path, transform=data_transforms)\n",
    "val_data = ImageNetValidationDataset(cfg.dataset_val_path, \n",
    "                                imagenet_paths['label_strings'], \n",
    "                                imagenet_paths['val_labels'], \n",
    "                                data_transforms,\n",
    "                                return_index=True,\n",
    ")\n",
    "val_data_visualize = ImageNetValidationDataset(cfg.dataset_val_path, \n",
    "                                imagenet_paths['label_strings'], \n",
    "                                imagenet_paths['val_labels'],\n",
    "                                torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),]), return_index=True)\n",
    "\n",
    "print(f\"Validation data length: {len(val_data)}\") if cfg.verbose else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_prisma.sae.training.activations_store import VisionActivationsStore\n",
    "# import dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# activations_loader = VisionActivationsStore(cfg, model, train_data, eval_dataset=val_data)\n",
    "val_dataloader = DataLoader(val_data, batch_size=cfg.batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained SAE to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_activation_fn received: activation_fn=relu, kwargs={}\n",
      "n_tokens_per_buffer (millions): 0.032\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 158691\n",
      "Total training images: 13000000\n",
      "Total wandb updates: 1586\n",
      "Expansion factor: 64\n",
      "n_tokens_per_feature_sampling_window (millions): 204.8\n",
      "n_tokens_per_dead_feature_window (millions): 1024.0\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 158 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Gradient clipping with max_norm=1.0\n",
      "Using SAE initialization method: encoder_transpose_decoder\n",
      "get_activation_fn received: activation_fn=relu, kwargs={}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (hook_sae_in): HookPoint()\n",
       "  (hook_hidden_pre): HookPoint()\n",
       "  (hook_hidden_post): HookPoint()\n",
       "  (hook_sae_out): HookPoint()\n",
       "  (activation_fn): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vit_prisma.sae.sae import SparseAutoencoder\n",
    "sparse_autoencoder = SparseAutoencoder(cfg).load_from_pretrained(\"/workspace/sae_checkpoints/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-11-hook_resid_post-l1-0.0001/n_images_2600058.pt\")\n",
    "sparse_autoencoder.to(cfg.device)\n",
    "sparse_autoencoder.eval()  # prevents error if we're expecting a dead neuron mask for who \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Labeling AutoInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_imagenet_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_prisma.dataloaders.imagenet_dataset import get_imagenet_index_to_name\n",
    "ind_to_name = get_imagenet_index_to_name()\n",
    "\n",
    "all_imagenet_class_names = []\n",
    "for i in range(len(ind_to_name)):\n",
    "    all_imagenet_class_names.append(ind_to_name[str(i)][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/sae_checkpoints/max_images/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-11-hook_resid_post-l1-0.0001/layer_9'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.max_image_output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steering_hook_fn(\n",
    "    activations, cfg, hook, sae, steering_indices, steering_strength=1.0, mean_ablation_values=None, include_error=False\n",
    "\n",
    "):\n",
    "    sae.to(activations.device)\n",
    "\n",
    "\n",
    "    sae_input = activations.clone()\n",
    "    sae_output, feature_activations, *data = sae(sae_input)\n",
    "    \n",
    "    steered_feature_activations = feature_activations.clone()\n",
    "    \n",
    "    steered_feature_activations[:, :, steering_indices] = steering_strength\n",
    "\n",
    "    steered_sae_out = einops.einsum(\n",
    "                steered_feature_activations,\n",
    "                sae.W_dec,\n",
    "                \"... d_sae, d_sae d_in -> ... d_in\",\n",
    "            ) + sae.b_dec\n",
    "\n",
    "    steered_sae_out = sae.run_time_activation_norm_fn_out(steered_sae_out)\n",
    "    \n",
    "    print(steered_sae_out.shape)\n",
    "    print(steered_sae_out.shape)\n",
    "    print(f\"steering norm: {(steered_sae_out - sae_output).norm()}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    if include_error:\n",
    "        error = sae_input - sae_output\n",
    "        print(f\"error.norm(): {error.norm()}\")\n",
    "        return steered_sae_out + error\n",
    "    return steered_sae_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_feat_idxs = np.random.randint(0, high=3000, size=(25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given feature, set it high/low on maxim activ. imgs and high/low on non-activ images\n",
    "# hook SAE and replace desired feature with 0 or 1 \n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_feature_activations_set_feat(\n",
    "    images: torch.Tensor,\n",
    "    model: torch.nn.Module,\n",
    "    sparse_autoencoder: torch.nn.Module,\n",
    "    encoder_weights: torch.Tensor,\n",
    "    encoder_biases: torch.Tensor,\n",
    "    feature_ids: List[int],\n",
    "    feature_categories: List[str],\n",
    "    top_k: int = 10,\n",
    "    steering_strength: float = 10.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the highest activating tokens for given features in a batch of images.\n",
    "    \n",
    "    Args:\n",
    "        images: Input images\n",
    "        model: The main model\n",
    "        sparse_autoencoder: The sparse autoencoder\n",
    "        encoder_weights: Encoder weights for selected features\n",
    "        encoder_biases: Encoder biases for selected features\n",
    "        feature_ids: List of feature IDs to analyze\n",
    "        feature_categories: Categories of the features\n",
    "        top_k: Number of top activations to return per feature\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping feature IDs to tuples of (top_indices, top_values)\n",
    "    \"\"\"\n",
    "#     _, cache = model.run_with_cache(images, names_filter=[sparse_autoencoder.cfg.hook_point])\n",
    "    recons_image_embeddings_feat_altered_list = []\n",
    "    for idx in np.array(range(sparse_autoencoder.W_dec.shape[0]))[random_feat_idxs]:\n",
    "        print(f\"Feature: {idx} ====================\")\n",
    "        \n",
    "        steering_hook = partial(\n",
    "            steering_hook_fn,\n",
    "            cfg=cfg,\n",
    "            sae=sparse_autoencoder,\n",
    "            steering_indices=[idx],\n",
    "            steering_strength=steering_strength,\n",
    "            mean_ablation_values = [1.0],\n",
    "            include_error=True,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        recons_image_embeddings_feat_altered = model.run_with_hooks(\n",
    "            images,\n",
    "            fwd_hooks=[(\"blocks.9.hook_mlp_out\", steering_hook)],\n",
    "        )\n",
    "        recons_image_embeddings_feat_altered_list.append(recons_image_embeddings_feat_altered)\n",
    "\n",
    "    \n",
    "    # output is in clip embedding space\n",
    "    recons_image_embeddings_default = model.run_with_hooks(\n",
    "        images,\n",
    "        fwd_hooks=[(\"blocks.9.hook_mlp_out\", lambda x, hook: x)],\n",
    "    )\n",
    "    \n",
    "    print(f\"recons_image_embeddings_default: {recons_image_embeddings_default}\")\n",
    "    print(f\"recons_image_embeddings_default.shape: {recons_image_embeddings_default.shape}\")\n",
    "    print(f\"recons_image_embeddings_default: {recons_image_embeddings_default.shape}\")\n",
    "\n",
    "    print(f\"recons_image_embeddings_feat_altered: {recons_image_embeddings_feat_altered}\")\n",
    "    print(f\"recons_image_embeddings_feat_altered.shape: {recons_image_embeddings_feat_altered.shape}\")\n",
    "\n",
    "    return recons_image_embeddings_feat_altered_list, recons_image_embeddings_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                            | 0/1562 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1159 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1451 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1878 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 316 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 313 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1359 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 635 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99951171875\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 638 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 2839 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 894 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 805 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 411 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1527 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.890625\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1757 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 2032 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 2491 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 2031 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.8203125\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1193 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 375 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 2202 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1814 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1461 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 756 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.9873046875\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 1765 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                    | 1/1562 [00:01<48:30,  1.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 561.3306884765625\n",
      "Feature: 696 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 561.3306884765625\n",
      "recons_image_embeddings_default: tensor([[ 0.0352,  0.0083, -0.0740,  ..., -0.0311,  0.0275,  0.0019],\n",
      "        [-0.0101, -0.0539, -0.0622,  ...,  0.0199, -0.0555, -0.0743],\n",
      "        [-0.0206,  0.0059, -0.0366,  ..., -0.0307,  0.0756, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0099, -0.0045, -0.0059,  ..., -0.0521,  0.0647, -0.0225],\n",
      "        [-0.0422,  0.0518, -0.0482,  ...,  0.0098,  0.0418,  0.0290],\n",
      "        [-0.0411, -0.0590,  0.0014,  ..., -0.0432, -0.0089, -0.0449]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_default.shape: torch.Size([32, 512])\n",
      "recons_image_embeddings_default: torch.Size([32, 512])\n",
      "recons_image_embeddings_feat_altered: tensor([[ 0.0341, -0.0319, -0.0274,  ...,  0.0371,  0.0576, -0.0055],\n",
      "        [ 0.0295, -0.0321, -0.0257,  ...,  0.0384,  0.0533, -0.0074],\n",
      "        [ 0.0305, -0.0333, -0.0251,  ...,  0.0389,  0.0590, -0.0052],\n",
      "        ...,\n",
      "        [ 0.0323, -0.0287, -0.0232,  ...,  0.0377,  0.0600, -0.0086],\n",
      "        [ 0.0295, -0.0302, -0.0263,  ...,  0.0408,  0.0563, -0.0065],\n",
      "        [ 0.0287, -0.0352, -0.0235,  ...,  0.0380,  0.0552, -0.0095]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_feat_altered.shape: torch.Size([32, 512])\n",
      "Feature: 1159 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1451 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1878 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 316 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 313 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1359 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 635 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 638 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 2839 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 894 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 805 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 411 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1527 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.9404296875\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1757 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 2032 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 2491 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 2031 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.9560546875\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1193 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 375 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.91015625\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 2202 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99853515625\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1814 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1461 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99853515625\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 756 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99951171875\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 1765 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 560.2279052734375\n",
      "Feature: 696 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 560.2279052734375\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                                                   | 2/1562 [00:03<41:59,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recons_image_embeddings_default: tensor([[ 0.0146, -0.0148, -0.0460,  ...,  0.0118,  0.0082,  0.0083],\n",
      "        [-0.0018,  0.0212, -0.0113,  ...,  0.0519, -0.0585, -0.0361],\n",
      "        [-0.0171, -0.0393, -0.0432,  ...,  0.0160,  0.0028,  0.0136],\n",
      "        ...,\n",
      "        [-0.0224, -0.0082, -0.0361,  ..., -0.0352,  0.0784,  0.0265],\n",
      "        [-0.0062,  0.0247, -0.0572,  ...,  0.0121, -0.0083,  0.0222],\n",
      "        [-0.0130,  0.0321, -0.0363,  ...,  0.0437,  0.0279, -0.0109]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_default.shape: torch.Size([32, 512])\n",
      "recons_image_embeddings_default: torch.Size([32, 512])\n",
      "recons_image_embeddings_feat_altered: tensor([[ 0.0287, -0.0333, -0.0237,  ...,  0.0385,  0.0577, -0.0079],\n",
      "        [ 0.0317, -0.0317, -0.0243,  ...,  0.0427,  0.0523, -0.0075],\n",
      "        [ 0.0327, -0.0313, -0.0280,  ...,  0.0390,  0.0565, -0.0087],\n",
      "        ...,\n",
      "        [ 0.0319, -0.0320, -0.0248,  ...,  0.0389,  0.0563, -0.0038],\n",
      "        [ 0.0312, -0.0324, -0.0245,  ...,  0.0388,  0.0559, -0.0049],\n",
      "        [ 0.0320, -0.0319, -0.0263,  ...,  0.0415,  0.0580, -0.0072]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_feat_altered.shape: torch.Size([32, 512])\n",
      "Feature: 1159 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1451 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1878 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 316 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 313 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1359 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 635 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 638 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 2839 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 894 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 805 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99853515625\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 411 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1527 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.8515625\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1757 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 2032 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 2491 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 2031 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.87939453125\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1193 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 375 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99609375\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 2202 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1814 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1461 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 756 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99658203125\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 1765 ====================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▏                                                                                                   | 3/1562 [00:04<39:57,  1.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 559.0997314453125\n",
      "Feature: 696 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 559.0997314453125\n",
      "recons_image_embeddings_default: tensor([[ 0.0294,  0.0383,  0.0048,  ..., -0.0036,  0.0256,  0.0279],\n",
      "        [ 0.0004,  0.0353, -0.0868,  ..., -0.0146,  0.0002,  0.0059],\n",
      "        [ 0.0709, -0.0185, -0.0175,  ...,  0.0050,  0.0293,  0.0257],\n",
      "        ...,\n",
      "        [-0.0168, -0.0003, -0.0274,  ..., -0.0302,  0.0601, -0.0477],\n",
      "        [ 0.0075,  0.0213, -0.0235,  ..., -0.0346,  0.0216,  0.0487],\n",
      "        [ 0.0059, -0.0119, -0.0019,  ...,  0.0249, -0.0424,  0.0157]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_default.shape: torch.Size([32, 512])\n",
      "recons_image_embeddings_default: torch.Size([32, 512])\n",
      "recons_image_embeddings_feat_altered: tensor([[ 0.0309, -0.0311, -0.0237,  ...,  0.0403,  0.0569, -0.0061],\n",
      "        [ 0.0325, -0.0306, -0.0286,  ...,  0.0384,  0.0562, -0.0070],\n",
      "        [ 0.0329, -0.0315, -0.0248,  ...,  0.0381,  0.0570, -0.0042],\n",
      "        ...,\n",
      "        [ 0.0303, -0.0356, -0.0268,  ...,  0.0410,  0.0603, -0.0096],\n",
      "        [ 0.0316, -0.0305, -0.0220,  ...,  0.0376,  0.0570, -0.0050],\n",
      "        [ 0.0295, -0.0342, -0.0245,  ...,  0.0417,  0.0556, -0.0067]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_feat_altered.shape: torch.Size([32, 512])\n",
      "Feature: 1159 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99951171875\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1451 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99755859375\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1878 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 316 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 313 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1359 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 635 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99951171875\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 638 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 2839 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 894 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 805 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 411 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1527 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.91748046875\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1757 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 2032 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 2491 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 2031 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.8740234375\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1193 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.9951171875\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 375 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.96875\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 2202 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.98486328125\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1814 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1461 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.9990234375\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 756 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99072265625\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 1765 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 564.427001953125\n",
      "Feature: 696 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.990234375\n",
      "error.norm(): 564.427001953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|▎                                                                                                   | 4/1562 [00:06<39:03,  1.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recons_image_embeddings_default: tensor([[ 0.0495,  0.0061, -0.0375,  ..., -0.0073, -0.0049,  0.0464],\n",
      "        [ 0.0656,  0.0185, -0.0169,  ..., -0.0542,  0.0806,  0.0280],\n",
      "        [ 0.0439,  0.0136,  0.0194,  ..., -0.0279,  0.0640, -0.0370],\n",
      "        ...,\n",
      "        [ 0.0259,  0.0402, -0.0065,  ..., -0.0289,  0.0129,  0.0450],\n",
      "        [ 0.0245,  0.0248, -0.0074,  ..., -0.0344,  0.0273, -0.0038],\n",
      "        [ 0.0167,  0.0346, -0.0975,  ...,  0.0074,  0.0849, -0.0346]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_default.shape: torch.Size([32, 512])\n",
      "recons_image_embeddings_default: torch.Size([32, 512])\n",
      "recons_image_embeddings_feat_altered: tensor([[ 0.0344, -0.0303, -0.0264,  ...,  0.0367,  0.0553, -0.0050],\n",
      "        [ 0.0326, -0.0307, -0.0253,  ...,  0.0359,  0.0585, -0.0066],\n",
      "        [ 0.0306, -0.0328, -0.0233,  ...,  0.0398,  0.0623, -0.0072],\n",
      "        ...,\n",
      "        [ 0.0313, -0.0296, -0.0232,  ...,  0.0374,  0.0557, -0.0046],\n",
      "        [ 0.0333, -0.0295, -0.0278,  ...,  0.0384,  0.0572, -0.0048],\n",
      "        [ 0.0314, -0.0317, -0.0276,  ...,  0.0382,  0.0585, -0.0054]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_feat_altered.shape: torch.Size([32, 512])\n",
      "Feature: 1159 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1451 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.9912109375\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1878 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 316 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 313 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1359 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 635 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 638 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 2839 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 894 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 805 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 411 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1527 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.85791015625\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1757 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 2032 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 2491 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 2031 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.91015625\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1193 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 375 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.98681640625\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 2202 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1814 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1461 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.0\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 756 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.9970703125\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 1765 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 6000.00048828125\n",
      "error.norm(): 563.367431640625\n",
      "Feature: 696 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 5999.99951171875\n",
      "error.norm(): 563.367431640625\n",
      "recons_image_embeddings_default: tensor([[-0.0659, -0.0776, -0.0139,  ..., -0.0386,  0.0279,  0.0018],\n",
      "        [ 0.0148, -0.0243,  0.0026,  ..., -0.0218,  0.0321,  0.0376],\n",
      "        [-0.0408, -0.0001, -0.0266,  ..., -0.0062,  0.0039, -0.0037],\n",
      "        ...,\n",
      "        [-0.0287,  0.0508, -0.0474,  ...,  0.0316,  0.0009,  0.0108],\n",
      "        [-0.0258, -0.0096,  0.0075,  ..., -0.0291, -0.0626, -0.0089],\n",
      "        [ 0.0060, -0.0028, -0.0319,  ..., -0.0128,  0.0170, -0.0358]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_default.shape: torch.Size([32, 512])\n",
      "recons_image_embeddings_default: torch.Size([32, 512])\n",
      "recons_image_embeddings_feat_altered: tensor([[ 0.0288, -0.0347, -0.0240,  ...,  0.0369,  0.0594, -0.0068],\n",
      "        [ 0.0318, -0.0329, -0.0235,  ...,  0.0378,  0.0562, -0.0048],\n",
      "        [ 0.0302, -0.0324, -0.0258,  ...,  0.0395,  0.0563, -0.0052],\n",
      "        ...,\n",
      "        [ 0.0309, -0.0300, -0.0278,  ...,  0.0383,  0.0558, -0.0048],\n",
      "        [ 0.0302, -0.0315, -0.0251,  ...,  0.0399,  0.0551, -0.0088],\n",
      "        [ 0.0329, -0.0321, -0.0251,  ...,  0.0383,  0.0563, -0.0076]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_feat_altered.shape: torch.Size([32, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|▎                                                                                                   | 4/1562 [00:07<50:31,  1.95s/it]\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "max_samples = cfg.eval_max\n",
    "\n",
    "# top_activations = {i: (None, None) for i in interesting_features_indices}\n",
    "encoder_biases = sparse_autoencoder.b_enc#[interesting_features_indices]\n",
    "encoder_weights = sparse_autoencoder.W_enc#[:, interesting_features_indices]\n",
    "\n",
    "# positive = -1 * np.array([-50.0, -20.0, -10.0, -5.0, -2.5, -1.5, -1.0, -.75, -.5, -.25, -.1])\n",
    "# steering_strengths = np.array([-50.0, -20.0, -10.0, -5.0, -2.5, -1.5, -1.0, -.75, -.5, -.25, -.1, 0])\n",
    "# steering_strengths = np.concatenate((steering_strengths, positive))\n",
    "# print(steering_strengths)\n",
    "# strengths = defaultdict(list)\n",
    "# for steering_strength in steering_strengths:\n",
    "steering_strength = 150.0\n",
    "\n",
    "top_k=10\n",
    "processed_samples = 0\n",
    "default_embeds_list = []\n",
    "feature_steered_embeds = defaultdict(list)\n",
    "l = 0\n",
    "for batch_images, _, batch_indices in tqdm(val_dataloader, total=max_samples // cfg.batch_size):\n",
    "    batch_images = batch_images.to(cfg.device)\n",
    "    batch_indices = batch_indices.to(cfg.device)\n",
    "    batch_size = batch_images.shape[0]\n",
    "\n",
    "    altered_embeds_list, default_embeds = compute_feature_activations_set_feat(\n",
    "        batch_images, model, sparse_autoencoder, encoder_weights, encoder_biases,\n",
    "        None, None, top_k, steering_strength\n",
    "    )\n",
    "    default_embeds_list.append(default_embeds)\n",
    "    for j, altered_embeds in enumerate(altered_embeds_list):\n",
    "        feature_steered_embeds[random_feat_idxs[j]].extend(altered_embeds)\n",
    "    # either label embeds or optimize to maximal token in text transformer embedding face\n",
    "    l += 1\n",
    "    if l >= 5:\n",
    "        break    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "160"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_steered_embeds[random_feat_idxs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([160, 512])"
      ]
     },
     "execution_count": 392,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "default_embeds.shape\n",
    "len(default_embeds_list)\n",
    "default_embeds = torch.cat(default_embeds_list)\n",
    "default_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, torch.Size([32, 512]), torch.Size([160, 512]))"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "len(altered_embeds_list), altered_embeds_list[0].shape, default_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 394,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"/workspace/clip_dissect_raw.txt\", \"r\") as f:\n",
    "    larger_vocab = [line[:-1] for line in f.readlines()][:5000]\n",
    "\n",
    "# with open(\"/workspace/better_img_desc.txt\", \"r\") as f:\n",
    "#     larger_vocab = [line[:-1] for line in f.readlines()][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "1159\n",
      "1451\n",
      "1878\n",
      "316\n",
      "313\n",
      "1359\n",
      "635\n",
      "638\n",
      "2839\n",
      "894\n",
      "805\n",
      "411\n",
      "1527\n",
      "1757\n",
      "2032\n",
      "2491\n",
      "2031\n",
      "1193\n",
      "375\n",
      "2202\n",
      "1814\n",
      "1461\n",
      "756\n",
      "1765\n",
      "696\n",
      "Label probs altered: torch.Size([160, 5000])\n",
      "Label probs default: torch.Size([160, 5000])\n"
     ]
    }
   ],
   "source": [
    "# use clip vocab here and compare embeds\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "text = tokenizer(larger_vocab)\n",
    "text_features = og_model.encode_text(text.cuda())\n",
    "text_features_normed = text_features/text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "print(f\"text_features_normed.shape: {text_features_normed.shape}\")\n",
    "text_probs_altered_list = []\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    for key in feature_steered_embeds:\n",
    "        print(key)\n",
    "        # embeds already have L2 norm of 1\n",
    "        text_probs_altered = (100.0 * torch.stack(feature_steered_embeds[key]) @ text_features_normed.T).softmax(dim=-1)\n",
    "        text_probs_altered_list.append(text_probs_altered)\n",
    "    text_probs_default = (100.0 * default_embeds @ text_features_normed.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs altered:\", text_probs_altered.shape)  # prints: [[1., 0., 0.]]\n",
    "print(\"Label probs default:\", text_probs_default.shape)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summed Logit Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================================================================\n",
      "\n",
      "For Feature 1159\n",
      "actual image content:\n",
      "tensor([0.4668, 0.2499, 0.0294, 0.0247, 0.0181, 0.0160, 0.0128, 0.0117, 0.0060,\n",
      "        0.0043], device='cuda:0') \n",
      " ['guinea' 'hairy' 'wildlife' 'seal' 'rolling' 'fucking' 'cock' 'african'\n",
      " 'leg' 'milfhunter']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['tiny' 'utility' 'smaller' ... 'installed' 'matrix' 'pst']\n",
      " ['tiny' 'utility' 'smaller' ... 'matrix' 'pst' 'tool']\n",
      " ['tiny' 'utility' 'smaller' ... 'installed' 'twiki' 'matrix']\n",
      " ...\n",
      " ['tiny' 'utility' 'smaller' ... 'installed' 'pet' 'outdoor']\n",
      " ['tiny' 'utility' 'smaller' ... 'matrix' 'tool' 'pen']\n",
      " ['tiny' 'utility' 'smaller' ... 'matrix' 'tool' 'pst']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['tiny' 'utility' 'smaller' 'treat' 'outdoor' 'zip' 'pet' 'installed'\n",
      " 'matrix' 'pst']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([25.5987,  9.2884,  3.7629,  2.5320,  2.0389,  1.9798,  1.6968,  1.6639,\n",
      "         1.4246,  1.3740], device='cuda:0')\n",
      "['tiny' 'utility' 'smaller' 'treat' 'outdoor' 'zip' 'matrix' 'pet' 'tool'\n",
      " 'pst']\n",
      "tensor([-2.3863, -2.0201, -1.7595, -1.5536, -1.4860, -1.2850, -1.2352, -1.1994,\n",
      "        -1.1904, -1.1447], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([506456.4062, 385876.3125, 348181.4062, 276946.7500, 264530.0938,\n",
      "        173317.8750, 141699.5469, 117270.6797,  74389.9922,  74274.2500],\n",
      "       device='cuda:0')\n",
      "['zealand' 'philadelphia' 'nebraska' 'matrix' 'kansas' 'nz' 'tennessee'\n",
      " 'mountains' 'street' 'dolls']\n",
      "tensor([-2.3863, -2.0201, -1.7595, -1.5536, -1.4860, -1.2850, -1.2352, -1.1994,\n",
      "        -1.1904, -1.1447], device='cuda:0')\n",
      "['acceptance' 'advertise' 'recording' 'slide' 'fighting' 'absence'\n",
      " 'conflict' 'anyone' 'around' 'accordance']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1451\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['overall' 'eastern' 'assumes' ... 'tab' 'formats' 'tabs']\n",
      " ['overall' 'eastern' 'assumes' ... 'tab' 'pants' 'formats']\n",
      " ['overall' 'eastern' 'beastiality' ... 'bestiality' 'tabs' 'storage']\n",
      " ...\n",
      " ['overall' 'eastern' 'assumes' ... 'east' 'formats' 'storage']\n",
      " ['overall' 'eastern' 'assumes' ... 'tab' 'pants' 'tabs']\n",
      " ['overall' 'eastern' 'assumes' ... 'storage' 'formats' 'tabs']]\n",
      "tensor([0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['overall' 'eastern' 'assumes' 'beastiality' 'east' 'measure' 'pants'\n",
      " 'tab' 'formats' 'tabs']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([41.6169,  6.9023,  3.8361,  3.2897,  2.7491,  2.7287,  2.3599,  2.2916,\n",
      "         2.2610,  2.2428], device='cuda:0')\n",
      "['overall' 'eastern' 'assumes' 'beastiality' 'east' 'measure' 'tabs'\n",
      " 'formats' 'tab' 'storage']\n",
      "tensor([-2.3859, -2.0350, -1.7581, -1.5803, -1.4887, -1.3150, -1.2773, -1.2032,\n",
      "        -1.1934, -1.1558], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1948348.2500, 1279658.8750,  520495.4062,  303954.7812,  229880.4531,\n",
      "         210817.8594,  196331.3906,  159443.6250,  143210.0469,  127354.4141],\n",
      "       device='cuda:0')\n",
      "['overall' 'pants' 'lingerie' 'bedroom' 'hospitals' 'clothing' 'clothes'\n",
      " 'breakfast' 'farmers' 'properties']\n",
      "tensor([-2.3859, -2.0350, -1.7581, -1.5803, -1.4887, -1.3150, -1.2773, -1.2032,\n",
      "        -1.1934, -1.1558], device='cuda:0')\n",
      "['nelson' 'nikon' 'wilson' 'mike' 'miller' 'nick' 'hilton' 'milfs' 'nice'\n",
      " 'million']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1878\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['spectrum' 'stock' 'presentations' ... 'or' 'ss' 'progressive']\n",
      " ['spectrum' 'presentations' 'nh' ... 'commercial' 'aim' 'ss']\n",
      " ['presentations' 'spectrum' 'nh' ... 'commercial' 'chairman' 'ss']\n",
      " ...\n",
      " ['stock' 'presentations' 'spectrum' ... 'ss' 'aim' 'thin']\n",
      " ['presentations' 'nh' 'spectrum' ... 'properties' 'contractors' 'ss']\n",
      " ['presentations' 'spectrum' 'nh' ... 'aim' 'ss' 'commercial']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['spectrum' 'stock' 'presentations' 'nh' 'thin' 'commercial' 'php' 'or'\n",
      " 'ss' 'progressive']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([2.0294, 1.6768, 1.5672, 1.3651, 1.3353, 1.2323, 1.2150, 1.1227, 1.0439,\n",
      "        1.0335], device='cuda:0')\n",
      "['presentations' 'spectrum' 'nh' 'thin' 'stock' 'commercial' 'progressive'\n",
      " 'ss' 'or' 'submitted']\n",
      "tensor([-2.3870, -2.0356, -1.7349, -1.5861, -1.4839, -1.3154, -1.2844, -1.2055,\n",
      "        -1.1962, -1.1592], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1100601.0000,  993502.5000,  385818.0312,  348624.8438,  216993.1094,\n",
      "         187978.9531,  167609.9219,  165151.5469,  154759.6094,  150789.3906],\n",
      "       device='cuda:0')\n",
      "['contractors' 'businesses' 'posters' 'charts' 'presentations' 'shirts'\n",
      " 'properties' 'apparel' 'bedroom' 'citysearch']\n",
      "tensor([-2.3870, -2.0356, -1.7349, -1.5861, -1.4839, -1.3154, -1.2844, -1.2055,\n",
      "        -1.1962, -1.1592], device='cuda:0')\n",
      "['viewing' 'traveler' 'arrived' 'bible' 'massage' 'towards' 'modules'\n",
      " 'module' 'november' 'conversation']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 316\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['ftp' 'ap' 'arthur' ... 'a' 'actor' 'citysearch']\n",
      " ['ftp' 'ap' 'arthur' ... 'a' 'associate' 'citysearch']\n",
      " ['ftp' 'ap' 'arthur' ... 'a' 'actor' 'associate']\n",
      " ...\n",
      " ['ftp' 'ap' 'arthur' ... 'a' 'citysearch' 'actor']\n",
      " ['ftp' 'ap' 'arthur' ... 'a' 'associate' 'actor']\n",
      " ['ftp' 'ap' 'arthur' ... 'et' 'agriculture' 'associate']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['ftp' 'ap' 'arthur' 'posting' 'rom' 'et' 'patrick' 'a' 'actor'\n",
      " 'citysearch']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([9.3142, 8.3959, 5.7553, 3.4534, 3.1692, 2.1286, 2.1206, 1.5747, 1.2897,\n",
      "        1.2185], device='cuda:0')\n",
      "['ftp' 'ap' 'arthur' 'posting' 'rom' 'patrick' 'et' 'a' 'associate'\n",
      " 'actor']\n",
      "tensor([-2.3869, -1.9773, -1.7580, -1.5320, -1.4882, -1.2891, -1.2804, -1.2062,\n",
      "        -1.1962, -1.1632], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1710908.6250, 1223909.7500,  989940.6875,  973966.6250,  885680.1875,\n",
      "         560438.6250,  422271.7500,  326591.9688,  237312.2031,  234489.5000],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'citysearch' 'et' 'pubmed' 'farm' 'cincinnati' 'arthur'\n",
      " 'attorneys' 'bluetooth' 'ftp']\n",
      "tensor([-2.3869, -1.9773, -1.7580, -1.5320, -1.4882, -1.2891, -1.2804, -1.2062,\n",
      "        -1.1962, -1.1632], device='cuda:0')\n",
      "['korea' 'smaller' 'model' 'combination' 'photo' 'opened' 'breaks'\n",
      " 'similar' 'details' 'shemale']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 313\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['and' 'on' 'shirts' ... 'ds' 'prepared' 'set']\n",
      " ['and' 'on' 'shirts' ... 'fucking' 'shirt' 'our']\n",
      " ['and' 'on' 'shirts' ... 'prepared' 'ds' 'plates']\n",
      " ...\n",
      " ['and' 'shirts' 'on' ... 'ds' 'gun' 'prepared']\n",
      " ['and' 'shirts' 'on' ... 'fucking' 'ds' 'set']\n",
      " ['and' 'on' 'proceedings' ... 'prepared' 'our' 'presented']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['and' 'on' 'shirts' 'proceedings' 'fucking' 'shirt' 'plates' 'ds'\n",
      " 'prepared' 'set']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([4.8725, 2.6700, 2.6014, 1.9881, 1.6239, 1.4924, 1.4552, 1.3222, 1.2798,\n",
      "        1.2204], device='cuda:0')\n",
      "['and' 'on' 'shirts' 'proceedings' 'shirt' 'plates' 'prepared' 'ds'\n",
      " 'clean' 'presented']\n",
      "tensor([-2.3851, -2.0274, -1.5844, -1.4876, -1.3011, -1.2268, -1.2060, -1.1943,\n",
      "        -1.1636, -1.1358], device='cuda:0')\n",
      "['guinea' 'dog' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail' 'male'\n",
      " 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([2716348.0000,  665010.3750,  291076.3750,  281249.9375,  175167.2500,\n",
      "         158849.9375,  109025.5547,  106912.0781,  103075.3047,   99647.6484],\n",
      "       device='cuda:0')\n",
      "['shirts' 'shirt' 'sky' 'cincinnati' 'clothes' 'companies' 'recipes'\n",
      " 'proceedings' 'catalogue' 'businesses']\n",
      "tensor([-2.3851, -2.0274, -1.5844, -1.4876, -1.3011, -1.2268, -1.2060, -1.1943,\n",
      "        -1.1636, -1.1358], device='cuda:0')\n",
      "['tourist' 'beast' 'tall' 'fantastic' 'beastiality' 'damages' 'lesbian'\n",
      " 'reflect' 'cancer' 'territory']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1359\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['patches' 'patch' 'shown' ... 'mesh' 'jersey' 'proposed']\n",
      " ['patches' 'shown' 'front' ... 'jersey' 'mesh' 'proposed']\n",
      " ['patches' 'patch' 'shown' ... 'trailer' 'trailers' 'clinton']\n",
      " ...\n",
      " ['patches' 'shown' 'front' ... 'jersey' 'mesh' 'clinton']\n",
      " ['patches' 'shown' 'front' ... 'mesh' 'proposed' 'jersey']\n",
      " ['patches' 'patch' 'shown' ... 'mesh' 'proposed' 'jersey']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['patches' 'patch' 'shown' 'front' 'trailer' 'trailers' 'filters' 'mesh'\n",
      " 'jersey' 'proposed']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([8.5789, 5.8899, 5.3314, 4.9307, 3.5902, 2.9807, 2.9798, 2.7110, 2.4623,\n",
      "        1.9388], device='cuda:0')\n",
      "['patches' 'patch' 'shown' 'front' 'filters' 'trailer' 'trailers' 'mesh'\n",
      " 'jersey' 'clinton']\n",
      "tensor([-2.3863, -2.0315, -1.7592, -1.5905, -1.4820, -1.3095, -1.2023, -1.1780,\n",
      "        -1.1387, -1.1347], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'eagle' 'detail' 'male'\n",
      " 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([2438950.5000, 1993564.8750, 1693109.2500,  480454.0938,  401447.2812,\n",
      "         399178.2500,  366458.6562,  360349.0938,  314072.9062,  273745.0938],\n",
      "       device='cuda:0')\n",
      "['connecticut' 'philadelphia' 'maine' 'patches' 'shirts' 'trailers'\n",
      " 'laptops' 'ea' 'vermont' 'pennsylvania']\n",
      "tensor([-2.3863, -2.0315, -1.7592, -1.5905, -1.4820, -1.3095, -1.2023, -1.1780,\n",
      "        -1.1387, -1.1347], device='cuda:0')\n",
      "['smile' 'split' 'until' 'forever' 'nine' 'sit' 'feeling' 'experience'\n",
      " 'forward' 'step']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 635\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['title' 'front' 'publisher' ... 'paperback' 'postage' 'trailer']\n",
      " ['front' 'publisher' 'newsletter' ... 'paperback' 'encyclopedia'\n",
      "  'header']\n",
      " ['front' 'publisher' 'title' ... 'shown' 'encyclopedia' 'postage']\n",
      " ...\n",
      " ['publisher' 'front' 'title' ... 'paperback' 'postage' 'header']\n",
      " ['front' 'publisher' 'title' ... 'paperback' 'encyclopedia' 'trailer']\n",
      " ['publisher' 'front' 'title' ... 'smaller' 'header' 'encyclopedia']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['title' 'front' 'publisher' 'newsletter' 'smaller' 'newsletters' 'shown'\n",
      " 'paperback' 'postage' 'trailer']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([8.3828, 7.6496, 7.1334, 6.4682, 3.7396, 2.9803, 2.4945, 2.4227, 2.1493,\n",
      "        2.0467], device='cuda:0')\n",
      "['publisher' 'front' 'title' 'newsletter' 'newsletters' 'smaller'\n",
      " 'paperback' 'shown' 'postage' 'encyclopedia']\n",
      "tensor([-2.3840, -2.0319, -1.7170, -1.5904, -1.4827, -1.3136, -1.2417, -1.2049,\n",
      "        -1.1954, -1.1624], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([610534.1875, 375436.7188, 334142.8125, 281355.0938, 234783.7031,\n",
      "        213062.6094, 149517.8594, 134980.8125, 121060.4609, 114807.3672],\n",
      "       device='cuda:0')\n",
      "['lingerie' 'logo' 'publisher' 'logos' 'header' 'publishing' 'franchise'\n",
      " 'colleges' 'newsletter' 'encyclopedia']\n",
      "tensor([-2.3840, -2.0319, -1.7170, -1.5904, -1.4827, -1.3136, -1.2417, -1.2049,\n",
      "        -1.1954, -1.1624], device='cuda:0')\n",
      "['fred' 'ahead' 'searching' 'neck' 'common' 'dead' 'targets' 'lee'\n",
      " 'penalty' 'seems']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 638\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['row' 'pipe' 'concentration' ... 'completed' 'certificates'\n",
      "  'newsletter']\n",
      " ['row' 'pipe' 'concentration' ... 'been' 'from' 'truck']\n",
      " ['row' 'pipe' 'concentration' ... 'been' 'truck' 'from']\n",
      " ...\n",
      " ['row' 'pipe' 'magazine' ... 'rf' 'completed' 'been']\n",
      " ['row' 'pipe' 'concentration' ... 'completed' 'newsletter' 'after']\n",
      " ['row' 'pipe' 'concentration' ... 'certificates' 'truck' 'from']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['row' 'pipe' 'concentration' 'bb' 'magazine' 'been' 'truck' 'completed'\n",
      " 'certificates' 'newsletter']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([6.8237, 4.5454, 3.4526, 2.6245, 2.2189, 1.8321, 1.6970, 1.4671, 1.3289,\n",
      "        1.2883], device='cuda:0')\n",
      "['row' 'pipe' 'concentration' 'magazine' 'bb' 'newsletter' 'been'\n",
      " 'certificates' 'from' 'rf']\n",
      "tensor([-2.3857, -2.0235, -1.6439, -1.5608, -1.4859, -1.2722, -1.2039, -1.1919,\n",
      "        -1.1604, -1.1355], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'pair' 'eagle' 'detail' 'male'\n",
      " 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1271379.2500,  555763.6250,  441293.0938,  415757.9688,  399346.9375,\n",
      "         387899.2188,  367371.3125,  231055.0469,  181423.0625,  177083.7031],\n",
      "       device='cuda:0')\n",
      "['boats' 'bedroom' 'trees' 'recipes' 'nancy' 'trucks' 'certificates'\n",
      " 'breakfast' 'posters' 'restaurants']\n",
      "tensor([-2.3857, -2.0235, -1.6439, -1.5608, -1.4859, -1.2722, -1.2039, -1.1919,\n",
      "        -1.1604, -1.1355], device='cuda:0')\n",
      "['mercury' 'medium' 'minute' 'scheduled' 'scale' 'permitted' 'particular'\n",
      " 'cancel' 'optional' 'pst']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2839\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['covers' 'harris' 'william' ... 'papers' 'hurricane' 'drives']\n",
      " ['covers' 'harris' 'william' ... 'flash' 'virgin' 'drives']\n",
      " ['covers' 'harris' 'william' ... 'virgin' 'scott' 'hurricane']\n",
      " ...\n",
      " ['covers' 'harris' 'william' ... 'drives' 'virgin' 'scott']\n",
      " ['covers' 'harris' 'william' ... 'virgin' 'drives' 'scott']\n",
      " ['covers' 'harris' 'william' ... 'flash' 'drives' 'hurricane']]\n",
      "tensor([0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['covers' 'harris' 'william' 'denmark' 'nl' 'flash' 'virgin' 'papers'\n",
      " 'hurricane' 'drives']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([53.8458,  9.9414,  2.9407,  2.3535,  2.1134,  2.0638,  2.0431,  2.0195,\n",
      "         1.5355,  1.3926], device='cuda:0')\n",
      "['covers' 'harris' 'william' 'nl' 'flash' 'virgin' 'papers' 'denmark'\n",
      " 'drives' 'hurricane']\n",
      "tensor([-2.3866, -2.0359, -1.7594, -1.5890, -1.4884, -1.3152, -1.2818, -1.2033,\n",
      "        -1.1963, -1.1622], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([3276223.5000, 3084399.5000, 1276858.2500,  751188.8125,  644941.3125,\n",
      "         601339.9375,  425907.5625,  400519.1562,  371000.5625,  236295.8281],\n",
      "       device='cuda:0')\n",
      "['norway' 'papers' 'rob' 'covers' 'finland' 'scotland' 'recipes'\n",
      " 'maryland' 'denmark' 'logos']\n",
      "tensor([-2.3866, -2.0359, -1.7594, -1.5890, -1.4884, -1.3152, -1.2818, -1.2033,\n",
      "        -1.1963, -1.1622], device='cuda:0')\n",
      "['fat' 'viewing' 'few' 'side' 'inspection' 'shower' 'offering'\n",
      " 'satisfaction' 'reflect' 'foto']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 894\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['range' 'targets' 'smoking' ... 'bang' 'four' 'seven']\n",
      " ['range' 'targets' 'smoking' ... 'xx' 'dean' 'four']\n",
      " ['range' 'smoking' 'targets' ... 'ar' 'r' 'ear']\n",
      " ...\n",
      " ['range' 'targets' 'smoking' ... 'ar' 'smoke' 'magazine']\n",
      " ['range' 'targets' 'smoking' ... 'bang' 'ar' 'dean']\n",
      " ['range' 'targets' 'smoking' ... 'ar' 'seven' 'bang']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['range' 'targets' 'smoking' 'thumbnail' 'black' 'smoke' 'r' 'bang' 'four'\n",
      " 'seven']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([15.3193,  4.0856,  3.9853,  2.8188,  2.2601,  2.1117,  1.8082,  1.7844,\n",
      "         1.6132,  1.5150], device='cuda:0')\n",
      "['range' 'smoking' 'targets' 'thumbnail' 'black' 'smoke' 'r' 'bang' 'ar'\n",
      " 'seven']\n",
      "tensor([-2.3871, -2.0282, -1.7588, -1.5402, -1.4860, -1.3151, -1.2450, -1.1959,\n",
      "        -1.1772, -1.1208], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'detail' 'eagle'\n",
      " 'fox']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1530483.3750,  347352.0938,  312642.8125,  298043.8750,  237712.8750,\n",
      "         229687.6250,  212605.8594,  198516.6406,  189082.4062,  169122.5000],\n",
      "       device='cuda:0')\n",
      "['anonymous' 'editors' 'black' 'ear' 'range' 'saw' 'bears' 'dean'\n",
      " 'cumshot' 'targets']\n",
      "tensor([-2.3871, -2.0282, -1.7588, -1.5402, -1.4860, -1.3151, -1.2450, -1.1959,\n",
      "        -1.1772, -1.1208], device='cuda:0')\n",
      "['flood' 'gulf' 'web' 'visits' 'perl' 'pregnancy' 'link' 'wet' 'html'\n",
      " 'seek']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 805\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['groups' 'pair' 'amp' ... 'adobe' 'dance' 'square']\n",
      " ['pair' 'groups' 'amp' ... 'adobe' 'dance' 'gcc']\n",
      " ['amp' 'pair' 'groups' ... 'hop' 'dance' 'square']\n",
      " ...\n",
      " ['amp' 'pair' 'groups' ... 'asp' 'partnership' 'xml']\n",
      " ['pair' 'groups' 'amp' ... 'dance' 'partnership' 'hop']\n",
      " ['groups' 'amp' 'pair' ... 'square' 'dance' 'partnership']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['groups' 'pair' 'amp' 'panasonic' 'bass' 'group' 'partnership' 'adobe'\n",
      " 'dance' 'square']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([6.3895, 5.8668, 4.2406, 3.3146, 2.9767, 2.9731, 2.2819, 1.7330, 1.5782,\n",
      "        1.5527], device='cuda:0')\n",
      "['groups' 'amp' 'pair' 'panasonic' 'group' 'bass' 'adobe' 'partnership'\n",
      " 'dance' 'asp']\n",
      "tensor([-2.2902, -2.0356, -1.7596, -1.5879, -1.4777, -1.3146, -1.2056, -1.1960,\n",
      "        -1.1439, -1.1328], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'eagle' 'detail' 'male'\n",
      " 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([875409.6875, 453456.5000, 439962.8125, 303126.8438, 229457.4844,\n",
      "        194795.5469, 163343.6719, 157527.6719, 144363.9688, 142594.7500],\n",
      "       device='cuda:0')\n",
      "['appliances' 'groups' 'brands' 'adobe' 'philadelphia' 'tripadvisor'\n",
      " 'payments' 'owners' 'recipes' 'apartments']\n",
      "tensor([-2.2902, -2.0356, -1.7596, -1.5879, -1.4777, -1.3146, -1.2056, -1.1960,\n",
      "        -1.1439, -1.1328], device='cuda:0')\n",
      "['fell' 'feeling' 'negative' 'evening' 'telling' 'kent' 'voyeur' 'mercury'\n",
      " 'execution' 'nelson']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 411\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['photo' 'bed' 'led' ... 'installed' 'panasonic' 'lighting']\n",
      " ['photo' 'led' 'display' ... 'beds' 'lighting' 'install']\n",
      " ['photo' 'led' 'bed' ... 'lighting' 'panasonic' 'beds']\n",
      " ...\n",
      " ['photo' 'led' 'bed' ... 'belt' 'install' 'foto']\n",
      " ['photo' 'bed' 'display' ... 'lighting' 'belt' 'panasonic']\n",
      " ['photo' 'led' 'bed' ... 'foto' 'beds' 'panasonic']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['photo' 'bed' 'led' 'display' 'lamp' 'beds' 'belt' 'installed'\n",
      " 'panasonic' 'lighting']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([11.0378,  5.3934,  4.3640,  3.3773,  2.7492,  2.2233,  2.1288,  2.1000,\n",
      "         2.0981,  1.9367], device='cuda:0')\n",
      "['photo' 'led' 'bed' 'display' 'lamp' 'lighting' 'beds' 'panasonic'\n",
      " 'installed' 'belt']\n",
      "tensor([-2.3838, -2.0235, -1.7437, -1.4884, -1.3463, -1.3023, -1.2607, -1.2014,\n",
      "        -1.1771, -1.1357], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'python' 'ray' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([8018859.5000,  696965.1875,  628625.3125,  466404.9062,  348867.7500,\n",
      "         283445.8438,  238364.3594,  237634.9844,  221555.3281,  197647.7812],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'led' 'lamp' 'bedrooms' 'tripadvisor' 'bed' 'beds' 'platform'\n",
      " 'displays' 'hotels']\n",
      "tensor([-2.3838, -2.0235, -1.7437, -1.4884, -1.3463, -1.3023, -1.2607, -1.2014,\n",
      "        -1.1771, -1.1357], device='cuda:0')\n",
      "['archive' 'promote' 'provisions' 'returned' 'revenue' 'severe' 'viewed'\n",
      " 'forward' 'anywhere' 'davis']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1527\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['protected' 'inspection' 'warranty' ... 'detection' 'moore' 'programs']\n",
      " ['protected' 'inspection' 'warranty' ... 'detection' 'programs' 'moore']\n",
      " ['inspection' 'protected' 'warranty' ... 'detection' 'programs' 'orders']\n",
      " ...\n",
      " ['inspection' 'warranty' 'protected' ... 'detection' 'moore' 'programs']\n",
      " ['protected' 'warranty' 'inspection' ... 'detection' 'programs' 'moore']\n",
      " ['inspection' 'protected' 'warranty' ... 'detection' 'moore' 'programs']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['protected' 'inspection' 'warranty' 'investigation' 'protection'\n",
      " 'protect' 'prevent' 'detection' 'moore' 'programs']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([7.3992, 6.6650, 6.4823, 4.1313, 3.1226, 2.6824, 2.4802, 1.7119, 1.3365,\n",
      "        1.2491], device='cuda:0')\n",
      "['protected' 'warranty' 'inspection' 'investigation' 'protection'\n",
      " 'protect' 'prevent' 'detection' 'programs' 'moore']\n",
      "tensor([-2.3870, -2.0360, -1.7530, -1.5895, -1.4886, -1.3154, -1.2065, -1.2037,\n",
      "        -1.1956, -1.1632], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'eagle' 'pair' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1615435.3750,  665781.1250,  554635.9375,  301087.0625,  183699.4062,\n",
      "         141567.1094,  121933.4609,  100620.5000,   83743.6562,   71160.7031],\n",
      "       device='cuda:0')\n",
      "['warranty' 'officials' 'var' 'appliances' 'philadelphia' 'programs'\n",
      " 'disclosure' 'investigation' 'noted' 'inspection']\n",
      "tensor([-2.3870, -2.0360, -1.7530, -1.5895, -1.4886, -1.3154, -1.2065, -1.2037,\n",
      "        -1.1956, -1.1632], device='cuda:0')\n",
      "['hop' 'perl' 'kerry' 'sole' 'jerry' 'pearl' 'apple' 'php' 'debian'\n",
      " 'hairy']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1757\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['chair' 'layout' 'type' ... 'book' 'pet' 'paperback']\n",
      " ['layout' 'chair' 'type' ... 'supplies' 'paperback' 'craft']\n",
      " ['chair' 'type' 'pet' ... 'section' 'supplies' 'paperback']\n",
      " ...\n",
      " ['type' 'chair' 'supplies' ... 'shape' 'paperback' 'paper']\n",
      " ['chair' 'section' 'type' ... 'paper' 'paperback' 'craft']\n",
      " ['chair' 'section' 'type' ... 'supplies' 'paperback' 'wheel']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['chair' 'layout' 'type' 'shape' 'supplies' 'paper' 'section' 'book' 'pet'\n",
      " 'paperback']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([3.7663, 3.6269, 2.7902, 2.7497, 2.7347, 2.7294, 2.6967, 2.6825, 2.2175,\n",
      "        2.2101], device='cuda:0')\n",
      "['chair' 'type' 'supplies' 'book' 'section' 'shape' 'layout' 'paper'\n",
      " 'paperback' 'pet']\n",
      "tensor([-2.3851, -1.7579, -1.5828, -1.4807, -1.3153, -1.2170, -1.2028, -1.1652,\n",
      "        -1.1301, -1.1039], device='cuda:0')\n",
      "['guinea' 'fucking' 'ray' 'python' 'fish' 'dog' 'eagle' 'detail' 'seal'\n",
      " 'fox']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([2261220.5000,  726776.3750,  470033.5938,  466272.0625,  317278.0938,\n",
      "         260355.6562,  246773.5469,  232957.3594,  216775.3281,  201269.6250],\n",
      "       device='cuda:0')\n",
      "['recipes' 'crafts' 'stores' 'jacket' 'supplies' 'foods' 'label'\n",
      " 'appliances' 'chair' 'brands']\n",
      "tensor([-2.3851, -1.7579, -1.5828, -1.4807, -1.3153, -1.2170, -1.2028, -1.1652,\n",
      "        -1.1301, -1.1039], device='cuda:0')\n",
      "['remaining' 'identified' 'penalty' 'immediately' 'permit' 'ended'\n",
      " 'federation' 'ending' 'permission' 'potential']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2032\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['belt' 'lower' 'sheets' ... 'rear' 'beds' 'turkey']\n",
      " ['belt' 'lower' 'sheets' ... 'breast' 'womens' 'reserve']\n",
      " ['lower' 'belt' 'sheets' ... 'turkey' 'rear' 'member']\n",
      " ...\n",
      " ['lower' 'belt' 'arm' ... 'breast' 'cisco' 'womens']\n",
      " ['lower' 'belt' 'sheets' ... 'beds' 'breast' 'womens']\n",
      " ['lower' 'belt' 'sheets' ... 'breast' 'reserve' 'upper']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['belt' 'lower' 'sheets' 'bed' 'arm' 'property' 'breast' 'rear' 'beds'\n",
      " 'turkey']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([5.8163, 5.2425, 4.4238, 3.8344, 3.0186, 2.5658, 2.2809, 1.9434, 1.8798,\n",
      "        1.7833], device='cuda:0')\n",
      "['belt' 'lower' 'sheets' 'arm' 'bed' 'property' 'breast' 'rear' 'womens'\n",
      " 'upper']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.3486, -2.0307, -1.7565, -1.5905, -1.4866, -1.3110, -1.2832, -1.2044,\n",
      "        -1.1955, -1.1590], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1758879.6250, 1468774.6250,  744968.4375,  558639.9375,  353410.6562,\n",
      "         341461.4688,  298794.2500,  277450.7188,  261955.2969,  203105.8750],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'kitchen' 'sheets' 'cincinnati' 'belt' 'appliances'\n",
      " 'pittsburgh' 'adopted' 'hat' 'bed']\n",
      "tensor([-2.3486, -2.0307, -1.7565, -1.5905, -1.4866, -1.3110, -1.2832, -1.2044,\n",
      "        -1.1955, -1.1590], device='cuda:0')\n",
      "['indeed' 'approach' 'him' 'spyware' 'particular' 'speaking' 'indicate'\n",
      " 'miles' 'driving' 'calculated']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2491\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['cards' 'button' 'pair' ... 'buttons' 'kits' 'balls']\n",
      " ['cards' 'button' 'pair' ... 'card' 'tags' 'buttons']\n",
      " ['cards' 'button' 'indian' ... 'buttons' 'kits' 'balls']\n",
      " ...\n",
      " ['cards' 'button' 'card' ... 'hat' 'buttons' 'goes']\n",
      " ['cards' 'button' 'pair' ... 'buttons' 'tags' 'goes']\n",
      " ['cards' 'button' 'card' ... 'tags' 'indian' 'goes']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['cards' 'button' 'pair' 'hat' 'tags' 'indian' 'card' 'buttons' 'kits'\n",
      " 'balls']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([12.7845,  9.7408,  4.5673,  4.3160,  4.0569,  3.8271,  3.7521,  3.0737,\n",
      "         2.8444,  2.8360], device='cuda:0')\n",
      "['cards' 'button' 'card' 'hat' 'indian' 'tags' 'buttons' 'kits' 'pair'\n",
      " 'goes']\n",
      "tensor([-2.3836, -2.0349, -1.7595, -1.4873, -1.3937, -1.3134, -1.1962, -1.1893,\n",
      "        -1.1583, -1.1177], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'python' 'ray' 'fish' 'detail' 'eagle' 'male'\n",
      " 'fox']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1183113.3750,  603947.3125,  389757.3125,  228976.6094,  196772.1719,\n",
      "         196165.7344,  196038.2812,  192056.0938,  170727.8438,  166069.2812],\n",
      "       device='cuda:0')\n",
      "['hat' 'cards' 'sponsors' 'shorts' 'leaves' 'motorcycle' 'tags' 'laptops'\n",
      " 'balls' 'tampa']\n",
      "tensor([-2.3836, -2.0349, -1.7595, -1.4873, -1.3937, -1.3134, -1.1962, -1.1893,\n",
      "        -1.1583, -1.1177], device='cuda:0')\n",
      "['privacy' 'viewing' 'filed' 'watching' 'blind' 'model' 'inside' 'opinion'\n",
      " 'hunt' 'difficult']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2031\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['font' 'foundation' 'wooden' ... 'wood' 'ancient' 'bottle']\n",
      " ['font' 'wooden' 'championship' ... 'gcc' 'wood' 'ancient']\n",
      " ['font' 'wooden' 'foundation' ... 'wood' 'bottle' 'ancient']\n",
      " ...\n",
      " ['font' 'wooden' 'championship' ... 'wood' 'bottle' 'citizen']\n",
      " ['font' 'wooden' 'foundation' ... 'thumbnail' 'bottle' 'ancient']\n",
      " ['font' 'wooden' 'foundation' ... 'wood' 'ancient' 'arena']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['font' 'foundation' 'wooden' 'championship' 'forum' 'tel' 'thumbnail'\n",
      " 'wood' 'ancient' 'bottle']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([30.0229,  7.6008,  6.1366,  6.0971,  4.1348,  3.6551,  2.6240,  1.8646,\n",
      "         1.5229,  1.5174], device='cuda:0')\n",
      "['font' 'wooden' 'foundation' 'championship' 'forum' 'tel' 'thumbnail'\n",
      " 'wood' 'bottle' 'ancient']\n",
      "tensor([-2.3866, -1.8407, -1.7574, -1.5902, -1.4822, -1.3146, -1.2827, -1.1917,\n",
      "        -1.1541, -1.1146], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'detail' 'eagle'\n",
      " 'fox']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([2769219.7500,  920616.8125,  723990.0000,  550368.8125,  403180.4688,\n",
      "         307563.4375,  296369.9375,  233209.8594,  191544.4219,  158687.9062],\n",
      "       device='cuda:0')\n",
      "['ministry' 'cities' 'papers' 'wooden' 'font' 'desert' 'anonymous'\n",
      " 'gardens' 'foundation' 'garden']\n",
      "tensor([-2.3866, -1.8407, -1.7574, -1.5902, -1.4822, -1.3146, -1.2827, -1.1917,\n",
      "        -1.1541, -1.1146], device='cuda:0')\n",
      "['short' 'zip' 'smart' 'shaved' 'permit' 'edit' 'editing' 'watching'\n",
      " 'remote' 'pictures']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1193\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0003, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['table' 'pottery' 'bottle' ... 'thumbnail' 'bowl' 'printable']\n",
      " ['table' 'pottery' 'bottle' ... 'thumbnail' 'printable' 'bowl']\n",
      " ['table' 'pottery' 'bottle' ... 'tables' 'printable' 'bowl']\n",
      " ...\n",
      " ['table' 'pottery' 'bottle' ... 'tables' 'printable' 'holder']\n",
      " ['table' 'pottery' 'bottle' ... 'thumbnail' 'bowl' 'printable']\n",
      " ['table' 'pottery' 'flowers' ... 'thumbnail' 'bowl' 'printable']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['table' 'pottery' 'bottle' 'flowers' 'arrangements' 'antique' 'tables'\n",
      " 'thumbnail' 'bowl' 'printable']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([25.5751, 20.8400, 16.3987, 16.3394,  6.7605,  3.0863,  2.1094,  1.8381,\n",
      "         1.6121,  0.9574], device='cuda:0')\n",
      "['table' 'pottery' 'flowers' 'bottle' 'arrangements' 'antique' 'thumbnail'\n",
      " 'tables' 'printable' 'bowl']\n",
      "tensor([-2.3868, -2.0344, -1.7588, -1.5902, -1.4869, -1.3133, -1.2059, -1.1874,\n",
      "        -1.1684, -1.1582], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'eagle' 'detail' 'pair'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([73979896.0000,  4270597.5000,  1860388.3750,  1026102.1875,\n",
      "          777349.3125,   588410.6250,   467080.0000,   435091.5938,\n",
      "          390979.0938,   364585.3438], device='cuda:0')\n",
      "['flowers' 'pottery' 'arrangements' 'table' 'bowl' 'crafts' 'recipes'\n",
      " 'tables' 'bottle' 'flower']\n",
      "tensor([-2.3868, -2.0344, -1.7588, -1.5902, -1.4869, -1.3133, -1.2059, -1.1874,\n",
      "        -1.1684, -1.1582], device='cuda:0')\n",
      "['seat' 'red' 'debian' 'virgin' 'chile' 'nancy' 'tel' 'transmission'\n",
      " 'fell' 'alert']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 375\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['sheet' 'branch' 'table' ... 'stars' 'extension' 'product']\n",
      " ['sheet' 'branch' 'board' ... 'extension' 'brand' 'snow']\n",
      " ['sheet' 'branch' 'table' ... 'extension' 'brand' 'listing']\n",
      " ...\n",
      " ['branch' 'sheet' 'shown' ... 'listing' 'product' 'extension']\n",
      " ['sheet' 'branch' 'table' ... 'listing' 'stars' 'product']\n",
      " ['sheet' 'branch' 'game' ... 'stars' 'extension' 'plant']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['sheet' 'branch' 'table' 'game' 'board' 'brand' 'shown' 'stars'\n",
      " 'extension' 'product']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([11.1957,  9.5593,  3.3130,  3.2298,  3.1520,  2.9528,  2.5812,  2.3075,\n",
      "         2.1697,  2.0527], device='cuda:0')\n",
      "['sheet' 'branch' 'table' 'game' 'board' 'shown' 'brand' 'extension'\n",
      " 'stars' 'product']\n",
      "tensor([-2.3870, -1.9223, -1.7573, -1.5904, -1.4866, -1.3078, -1.2586, -1.1963,\n",
      "        -1.1866, -1.1493], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'detail' 'eagle'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1179577.7500,  592148.3125,  303082.2500,  286738.4688,  195406.0938,\n",
      "         162666.7969,  153171.0625,  132994.1875,  132891.6094,   96289.6641],\n",
      "       device='cuda:0')\n",
      "['branch' 'stars' 'beach' 'trees' 'purple' 'sheet' 'plant' 'table' 'snow'\n",
      " 'flowers']\n",
      "tensor([-2.3870, -1.9223, -1.7573, -1.5904, -1.4866, -1.3078, -1.2586, -1.1963,\n",
      "        -1.1866, -1.1493], device='cuda:0')\n",
      "['churches' 'church' 'matthew' 'mary' 'catholic' 'anne' 'constitutes'\n",
      " 'daniel' 'jesus' 'charlotte']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2202\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['front' 'thumbnail' 'shown' ... 'watch' 'issue' 'these']\n",
      " ['front' 'shown' 'pair' ... 'issue' 'huge' 'these']\n",
      " ['front' 'thumbnail' 'shown' ... 'sizes' 'watch' 'huge']\n",
      " ...\n",
      " ['front' 'thumbnail' 'shown' ... 'issue' 'these' 'panasonic']\n",
      " ['front' 'shown' 'pair' ... 'issue' 'these' 'watch']\n",
      " ['front' 'thumbnail' 'shown' ... 'cover' 'sizes' 'image']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['front' 'thumbnail' 'shown' 'pair' 'size' 'hardcover' 'sizes' 'watch'\n",
      " 'issue' 'these']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([10.4516,  7.7456,  6.4626,  4.5432,  4.0590,  3.2404,  2.2597,  2.0661,\n",
      "         1.8852,  1.6554], device='cuda:0')\n",
      "['front' 'thumbnail' 'shown' 'size' 'pair' 'hardcover' 'sizes' 'issue'\n",
      " 'watch' 'these']\n",
      "tensor([-2.3859, -2.0236, -1.7585, -1.5904, -1.4877, -1.3142, -1.1990, -1.1933,\n",
      "        -1.1584, -1.1338], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'eagle' 'detail' 'male'\n",
      " 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1832882.6250, 1265688.7500,  624990.6250,  613301.6875,  425343.7188,\n",
      "         299274.2500,  178504.9219,  156293.3125,  153098.8281,  149573.6250],\n",
      "       device='cuda:0')\n",
      "['philadelphia' 'kitchen' 'college' 'universities' 'apparel' 'colleges'\n",
      " 'library' 'bedroom' 'garage' 'notebooks']\n",
      "tensor([-2.3859, -2.0236, -1.7585, -1.5904, -1.4877, -1.3142, -1.1990, -1.1933,\n",
      "        -1.1584, -1.1338], device='cuda:0')\n",
      "['spyware' 'luck' 'reply' 'cruise' 'finder' 'oz' 'wells' 'profiles'\n",
      " 'replies' 'defence']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1814\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['rear' 'tiffany' 'cooling' ... 'lingerie' 'product' 'belt']\n",
      " ['rear' 'tiffany' 'cooling' ... 'lingerie' 'product' 'mens']\n",
      " ['rear' 'tiffany' 'cooling' ... 'usc' 'bookmark' 'lingerie']\n",
      " ...\n",
      " ['rear' 'tiffany' 'cooling' ... 'product' 'bookmark' 'lingerie']\n",
      " ['rear' 'tiffany' 'cooling' ... 'lingerie' 'product' 'bookmark']\n",
      " ['rear' 'tiffany' 'cooling' ... 'usc' 'bookmark' 'product']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['rear' 'tiffany' 'cooling' 'glass' 'cap' 'screen' 'back' 'lingerie'\n",
      " 'product' 'belt']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([16.5797, 11.8626,  5.8147,  3.7826,  3.6531,  3.4998,  2.8919,  1.8516,\n",
      "         1.7758,  1.7663], device='cuda:0')\n",
      "['rear' 'tiffany' 'cooling' 'glass' 'screen' 'cap' 'back' 'lingerie'\n",
      " 'bookmark' 'product']\n",
      "tensor([-2.3805, -2.0267, -1.7473, -1.5336, -1.4886, -1.2895, -1.2720, -1.1817,\n",
      "        -1.1613, -1.1336], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'male'\n",
      " 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([1441231.3750, 1365838.8750, 1302292.0000,  790266.3125,  545541.4375,\n",
      "         488547.9688,  396106.2500,  391379.9062,  373169.3438,  282842.4375],\n",
      "       device='cuda:0')\n",
      "['lingerie' 'beach' 'casinos' 'colleges' 'ocean' 'tiffany' 'cincinnati'\n",
      " 'gardens' 'casino' 'garden']\n",
      "tensor([-2.3805, -2.0267, -1.7473, -1.5336, -1.4886, -1.2895, -1.2720, -1.1817,\n",
      "        -1.1613, -1.1336], device='cuda:0')\n",
      "['ordinary' 'recorder' 'indicate' 'bob' 'middle' 'ak' 'edit' 'him'\n",
      " 'nobody' 'persons']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1461\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['pair' 'bottom' 'both' ... 'date' 'cartridge' 'bin']\n",
      " ['pair' 'bottom' 'both' ... 'date' 'cartridge' 'ram']\n",
      " ['pair' 'bottom' 'both' ... 'date' 'bin' 'cartridge']\n",
      " ...\n",
      " ['pair' 'bottom' 'usr' ... 'joint' 'arm' 'ram']\n",
      " ['pair' 'bottom' 'both' ... 'date' 'cartridge' 'bin']\n",
      " ['pair' 'bottom' 'both' ... 'joint' 'cartridge' 'oct']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['pair' 'bottom' 'both' 'unit' 'usr' 'joint' 'units' 'date' 'cartridge'\n",
      " 'bin']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([7.9174, 7.4429, 5.8756, 5.8729, 5.7475, 4.5330, 3.7780, 3.7391, 3.0834,\n",
      "        2.5611], device='cuda:0')\n",
      "['pair' 'bottom' 'usr' 'unit' 'both' 'units' 'joint' 'date' 'cartridge'\n",
      " 'bin']\n",
      "tensor([-2.0456, -2.0283, -1.7595, -1.5890, -1.4882, -1.3000, -1.2063, -1.1958,\n",
      "        -1.1358, -1.1105], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'eagle' 'detail' 'seal'\n",
      " 'fox']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([205508.5312, 196331.2031, 172065.0469,  91951.4922,  80010.7344,\n",
      "         73006.4219,  68785.8750,  67045.9922,  60962.0078,  57372.0000],\n",
      "       device='cuda:0')\n",
      "['papers' 'bedroom' 'bottom' 'joint' 'visitors' 'units' 'toronto' 'bin'\n",
      " 'ontario' 'ukraine']\n",
      "tensor([-2.0456, -2.0283, -1.7595, -1.5890, -1.4882, -1.3000, -1.2063, -1.1958,\n",
      "        -1.1358, -1.1105], device='cuda:0')\n",
      "['shaved' 'knowing' 'blogger' 'searching' 'plaza' 'spread' 'bruce'\n",
      " 'thread' 'viewing' 'presence']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 756\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['si' 'row' 'lighting' ... 'floor' 'board' 'flash']\n",
      " ['row' 'si' 'lighting' ... 'guide' 'ct' 'tripadvisor']\n",
      " ['si' 'lighting' 'row' ... 'flash' 'circle' 'board']\n",
      " ...\n",
      " ['si' 'row' 'lighting' ... 'suites' 'bond' 'scale']\n",
      " ['row' 'lighting' 'si' ... 'slow' 'ct' 'floor']\n",
      " ['row' 'si' 'lighting' ... 'tripadvisor' 'slow' 'board']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['si' 'row' 'lighting' 'wall' 'score' 'circle' 'slow' 'floor' 'board'\n",
      " 'flash']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([4.0570, 3.3835, 3.3594, 1.9156, 1.5605, 1.4217, 1.3569, 1.3252, 1.2613,\n",
      "        1.2443], device='cuda:0')\n",
      "['si' 'lighting' 'row' 'wall' 'score' 'slow' 'guide' 'flash' 'board'\n",
      " 'suites']\n",
      "tensor([-2.3817, -2.0354, -1.6338, -1.5105, -1.4751, -1.2788, -1.2003, -1.1962,\n",
      "        -1.0981, -1.0932], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'pair' 'eagle' 'detail' 'fox'\n",
      " 'fish']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([2260881.0000, 1562090.5000,  536425.9375,  509973.8125,  441979.5938,\n",
      "         440977.3438,  343578.1562,  288774.8438,  283399.3438,  239110.7500],\n",
      "       device='cuda:0')\n",
      "['cincinnati' 'tripadvisor' 'restaurant' 'tampa' 'restaurants' 'nj'\n",
      " 'ocean' 'lighting' 'pittsburgh' 'vancouver']\n",
      "tensor([-2.3817, -2.0354, -1.6338, -1.5105, -1.4751, -1.2788, -1.2003, -1.1962,\n",
      "        -1.0981, -1.0932], device='cuda:0')\n",
      "['ak' 'tourist' 'milfhunter' 'tranny' 'materials' 'hundreds' 'william'\n",
      " 'mill' 'franklin' 'early']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1765\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['huge' 'sets' 'neck' ... 'emerging' 'font' 'elected']\n",
      " ['huge' 'sets' 'itself' ... 'neck' 'sterling' 'emerging']\n",
      " ['huge' 'biography' 'neck' ... 'font' 'scripts' 'emerging']\n",
      " ...\n",
      " ['huge' 'biography' 'sets' ... 'elected' 'font' 'seen']\n",
      " ['huge' 'sets' 'neck' ... 'scripts' 'font' 'emerging']\n",
      " ['huge' 'sets' 'biography' ... 'sterling' 'scripts' 'emerging']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['huge' 'sets' 'neck' 'itself' 'sterling' 'biography' 'scripts' 'emerging'\n",
      " 'font' 'elected']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([5.6904, 2.7709, 2.7156, 2.2974, 2.2593, 2.0059, 1.8712, 1.6160, 1.5088,\n",
      "        1.4720], device='cuda:0')\n",
      "['huge' 'sets' 'biography' 'itself' 'neck' 'elected' 'sterling' 'scripts'\n",
      " 'emerging' 'font']\n",
      "tensor([-2.3871, -2.0072, -1.7334, -1.5906, -1.4860, -1.3115, -1.2757, -1.1786,\n",
      "        -1.1651, -1.1433], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([187586.7969, 143224.6406, 126519.3281,  97561.6094,  80519.5547,\n",
      "         79799.5000,  70704.9609,  62053.8711,  61769.2148,  61477.2305],\n",
      "       device='cuda:0')\n",
      "['biography' 'college' 'employee' 'arrival' 'logos' 'black' 'elected'\n",
      " 'cats' 'sql' 'jobs']\n",
      "tensor([-2.3871, -2.0072, -1.7334, -1.5906, -1.4860, -1.3115, -1.2757, -1.1786,\n",
      "        -1.1651, -1.1433], device='cuda:0')\n",
      "['ground' 'penalty' 'try' 'blind' 'province' 'cooling' 'provisions'\n",
      " 'shaved' 'nov' 'rw']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 696\n",
      "actual image content:\n",
      "tensor([0.5584, 0.1575, 0.0111, 0.0099, 0.0095, 0.0085, 0.0056, 0.0055, 0.0047,\n",
      "        0.0047], device='cuda:0') \n",
      " ['python' 'debian' 's' 'epinions' 'pair' 'sand' 'links' 'rubber' 'male'\n",
      " 'rolling']\n",
      "text_probs_altered.softmax(): torch.Size([160, 5000])\n",
      "\n",
      "Softmax Over 160 Images:\n",
      "tensor([[0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        ...,\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002],\n",
      "        [0.0002, 0.0002, 0.0002,  ..., 0.0002, 0.0002, 0.0002]],\n",
      "       device='cuda:0')\n",
      "[['presentations' 'templates' 'maine' ... 'golf' 'shown' 'outdoor']\n",
      " ['presentations' 'maine' 'templates' ... 'shown' 'outdoor' 'sitemap']\n",
      " ['presentations' 'maine' 'templates' ... 'webmaster' 'sitemap' 'shown']\n",
      " ...\n",
      " ['presentations' 'templates' 'maine' ... 'ireland' 'webmaster' 'sitemap']\n",
      " ['presentations' 'templates' 'maine' ... 'massachusetts' 'posters'\n",
      "  'golf']\n",
      " ['presentations' 'templates' 'maine' ... 'printable' 'outdoor' 'shown']]\n",
      "tensor([0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0') \n",
      " ['presentations' 'templates' 'maine' 'sitemap' 'printable' 'ireland'\n",
      " 'washington' 'golf' 'shown' 'outdoor']\n",
      "\n",
      "Most Changed, by Absolute Diff Over 160 Images:\n",
      "tensor([7.4095, 4.9528, 4.8849, 2.7674, 2.4955, 2.2021, 2.0966, 1.9888, 1.9081,\n",
      "        1.7871], device='cuda:0')\n",
      "['presentations' 'maine' 'templates' 'printable' 'washington' 'ireland'\n",
      " 'sitemap' 'golf' 'shown' 'posters']\n",
      "tensor([-2.3855, -1.9993, -1.7596, -1.5904, -1.4874, -1.3070, -1.2852, -1.2064,\n",
      "        -1.1698, -1.1612], device='cuda:0')\n",
      "['guinea' 'dog' 'fucking' 'ray' 'python' 'fish' 'pair' 'eagle' 'detail'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 160 Images:\n",
      "tensor([30134762.0000,  4470488.0000,  2617652.0000,  2292973.0000,\n",
      "         1237195.0000,   915835.8125,   823788.4375,   763971.3125,\n",
      "          713988.1250,   685164.6875], device='cuda:0')\n",
      "['maine' 'quotes' 'ireland' 'colleges' 'posters' 'businesses'\n",
      " 'presentations' 'citysearch' 'massachusetts' 'connecticut']\n",
      "tensor([-2.3855, -1.9993, -1.7596, -1.5904, -1.4874, -1.3070, -1.2852, -1.2064,\n",
      "        -1.1698, -1.1612], device='cuda:0')\n",
      "['lock' 'scale' 'millions' 'million' 'chip' 'twiki' 'neck' 'catch'\n",
      " 'rolling' 'thousand']\n"
     ]
    }
   ],
   "source": [
    "# subtract from default, label, and print trends\n",
    "text_probs_altered.shape\n",
    "\n",
    "# selected_vocab = all_imagenet_class_names\n",
    "selected_vocab = larger_vocab\n",
    "\n",
    "top_concept_per_feat = {}\n",
    "top_val_per_feat = {}\n",
    "top_diff_per_feat = {}\n",
    "top_ratio_per_feat = {}\n",
    "# run this for sampled features over all of imagenet eval\n",
    "for j, text_probs_altered in enumerate(text_probs_altered_list):\n",
    "    print(f\"{'============================================'*2}\\n\\nFor Feature {random_feat_idxs[j]}\")\n",
    "    print(\"actual image content:\")\n",
    "    default_vals_softmax, default_idxs_softmax = torch.topk(text_probs_default,k=10)\n",
    "    print(default_vals_softmax[i], \"\\n\", np.array(selected_vocab)[default_idxs_softmax.cpu()][i])\n",
    "    \n",
    "    \n",
    "    logit_diff = text_probs_altered - text_probs_default\n",
    "    logit_diff_aggregate = logit_diff.sum(dim=0)\n",
    "    \n",
    "    logit_ratio = text_probs_altered/text_probs_default\n",
    "    logit_ratio_aggregate = logit_ratio.mean(dim=0)\n",
    "    \n",
    "    print(f\"text_probs_altered.softmax(): {text_probs_altered.softmax(1).shape}\")\n",
    "    text_probs_altered_softmax = text_probs_altered.softmax(1)\n",
    "    vals_softmax, idxs_softmax = torch.topk(text_probs_altered_softmax,k=10)\n",
    "    \n",
    "#     print(f\"text_probs_altered.softmax(): {text_probs_altered.sum(0).softmax(0).shape}\")\n",
    "#     text_probs_altered_softmax_agg = text_probs_altered.sum(0).softmax(0)\n",
    "#     vals_softmax_agg, idxs_softmax_agg = torch.topk(text_probs_altered_softmax_agg,k=10)\n",
    "    \n",
    "    print(f\"\\nSoftmax Over {text_probs_altered.shape[0]} Images:\\n{vals_softmax}\")\n",
    "    print(np.array(selected_vocab)[idxs_softmax.cpu()])\n",
    "    for i in range(vals_softmax.shape[0]):\n",
    "        print(vals_softmax[i], \"\\n\", np.array(selected_vocab)[idxs_softmax.cpu()][i])\n",
    "        break\n",
    "        \n",
    "#     print(f\"\\nAgg Softmax Over {text_probs_altered.shape[0]} Images:\\n{vals_softmax_agg}\")\n",
    "#     print(np.array(selected_vocab)[idxs_softmax_agg.cpu()])\n",
    "    \n",
    "    vals_agg, idxs_agg = torch.topk(logit_diff_aggregate,k=10)\n",
    "    vals_least_agg, idxs_least_agg = torch.topk(logit_diff_aggregate,k=10,largest=False)\n",
    "    \n",
    "    ratios_agg, ratios_idxs_agg = torch.topk(logit_ratio_aggregate,k=10)\n",
    "    ratios_least_agg, ratios_idxs_least_agg = torch.topk(logit_ratio_aggregate,k=10,largest=False)\n",
    "    \n",
    "    vals, idxs = torch.topk(logit_diff,k=5)\n",
    "    vals_least, idxs_least = torch.topk(logit_diff,k=5,largest=False)\n",
    "    \n",
    "    ratios, ratios_idxs = torch.topk(logit_ratio,k=5)\n",
    "    ratios_least, ratios_idxs_least = torch.topk(logit_ratio,k=5,largest=False)\n",
    "    \n",
    "    top_concept_per_feat[random_feat_idxs[j]] = np.array(selected_vocab)[idxs_softmax.cpu()][0][0]\n",
    "    top_val_per_feat[random_feat_idxs[j]] = vals_softmax[0][0]\n",
    "    top_diff_per_feat[random_feat_idxs[j]] = vals_agg[0]\n",
    "    top_ratio_per_feat[random_feat_idxs[j]] = ratios_agg[0]\n",
    "    \n",
    "    \n",
    "    print(f\"\\nMost Changed, by Absolute Diff Over {logit_diff.shape[0]} Images:\\n{vals_agg}\")\n",
    "    print(np.array(selected_vocab)[idxs_agg.cpu()])\n",
    "    print(vals_least_agg)\n",
    "    print(np.array(selected_vocab)[idxs_least_agg.cpu()])\n",
    "    \n",
    "    print(f\"\\nMost Changed, by Ratio Over {logit_diff.shape[0]} Images:\")\n",
    "    print(ratios_agg)\n",
    "    print(np.array(selected_vocab)[ratios_idxs_agg.cpu()])\n",
    "    print(vals_least_agg)\n",
    "    print(np.array(selected_vocab)[ratios_idxs_least_agg.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({1159: 'tiny',\n",
       "  1451: 'overall',\n",
       "  1878: 'spectrum',\n",
       "  316: 'ftp',\n",
       "  313: 'and',\n",
       "  1359: 'patches',\n",
       "  635: 'title',\n",
       "  638: 'row',\n",
       "  2839: 'covers',\n",
       "  894: 'range',\n",
       "  805: 'groups',\n",
       "  411: 'photo',\n",
       "  1527: 'protected',\n",
       "  1757: 'chair',\n",
       "  2032: 'belt',\n",
       "  2491: 'cards',\n",
       "  2031: 'font',\n",
       "  1193: 'table',\n",
       "  375: 'sheet',\n",
       "  2202: 'front',\n",
       "  1814: 'rear',\n",
       "  1461: 'pair',\n",
       "  756: 'si',\n",
       "  1765: 'huge',\n",
       "  696: 'presentations'},\n",
       " {1159: tensor(0.0002, device='cuda:0'),\n",
       "  1451: tensor(0.0003, device='cuda:0'),\n",
       "  1878: tensor(0.0002, device='cuda:0'),\n",
       "  316: tensor(0.0002, device='cuda:0'),\n",
       "  313: tensor(0.0002, device='cuda:0'),\n",
       "  1359: tensor(0.0002, device='cuda:0'),\n",
       "  635: tensor(0.0002, device='cuda:0'),\n",
       "  638: tensor(0.0002, device='cuda:0'),\n",
       "  2839: tensor(0.0003, device='cuda:0'),\n",
       "  894: tensor(0.0002, device='cuda:0'),\n",
       "  805: tensor(0.0002, device='cuda:0'),\n",
       "  411: tensor(0.0002, device='cuda:0'),\n",
       "  1527: tensor(0.0002, device='cuda:0'),\n",
       "  1757: tensor(0.0002, device='cuda:0'),\n",
       "  2032: tensor(0.0002, device='cuda:0'),\n",
       "  2491: tensor(0.0002, device='cuda:0'),\n",
       "  2031: tensor(0.0002, device='cuda:0'),\n",
       "  1193: tensor(0.0002, device='cuda:0'),\n",
       "  375: tensor(0.0002, device='cuda:0'),\n",
       "  2202: tensor(0.0002, device='cuda:0'),\n",
       "  1814: tensor(0.0002, device='cuda:0'),\n",
       "  1461: tensor(0.0002, device='cuda:0'),\n",
       "  756: tensor(0.0002, device='cuda:0'),\n",
       "  1765: tensor(0.0002, device='cuda:0'),\n",
       "  696: tensor(0.0002, device='cuda:0')},\n",
       " {1159: tensor(506456.4062, device='cuda:0'),\n",
       "  1451: tensor(1948348.2500, device='cuda:0'),\n",
       "  1878: tensor(1100601., device='cuda:0'),\n",
       "  316: tensor(1710908.6250, device='cuda:0'),\n",
       "  313: tensor(2716348., device='cuda:0'),\n",
       "  1359: tensor(2438950.5000, device='cuda:0'),\n",
       "  635: tensor(610534.1875, device='cuda:0'),\n",
       "  638: tensor(1271379.2500, device='cuda:0'),\n",
       "  2839: tensor(3276223.5000, device='cuda:0'),\n",
       "  894: tensor(1530483.3750, device='cuda:0'),\n",
       "  805: tensor(875409.6875, device='cuda:0'),\n",
       "  411: tensor(8018859.5000, device='cuda:0'),\n",
       "  1527: tensor(1615435.3750, device='cuda:0'),\n",
       "  1757: tensor(2261220.5000, device='cuda:0'),\n",
       "  2032: tensor(1758879.6250, device='cuda:0'),\n",
       "  2491: tensor(1183113.3750, device='cuda:0'),\n",
       "  2031: tensor(2769219.7500, device='cuda:0'),\n",
       "  1193: tensor(73979896., device='cuda:0'),\n",
       "  375: tensor(1179577.7500, device='cuda:0'),\n",
       "  2202: tensor(1832882.6250, device='cuda:0'),\n",
       "  1814: tensor(1441231.3750, device='cuda:0'),\n",
       "  1461: tensor(205508.5312, device='cuda:0'),\n",
       "  756: tensor(2260881., device='cuda:0'),\n",
       "  1765: tensor(187586.7969, device='cuda:0'),\n",
       "  696: tensor(30134762., device='cuda:0')})"
      ]
     },
     "execution_count": 398,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_concept_per_feat,top_val_per_feat,top_ratio_per_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [],
   "source": [
    "# steering_strength_info = {}\n",
    "steering_strength_info[steering_strength] = (top_concept_per_feat,top_val_per_feat,top_ratio_per_feat,top_diff_per_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1159, 1451, 1878, 316, 313, 1359, 635, 638, 2839, 894, 805, 411, 1527, 1757, 2032, 2491, 2031, 1193, 375, 2202, 1814, 1461, 756, 1765, 696])"
      ]
     },
     "execution_count": 400,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_strength_info[steering_strength][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{50.0: ({1159: 'tiny',\n",
       "   1451: 'overall',\n",
       "   1878: 'dry',\n",
       "   316: 'tape',\n",
       "   313: 'set',\n",
       "   1359: 'patches',\n",
       "   635: 'foundation',\n",
       "   638: 'cooling',\n",
       "   2839: 'covers',\n",
       "   894: 'targets',\n",
       "   805: 'pair',\n",
       "   411: 'border',\n",
       "   1527: 'investigation',\n",
       "   1757: 'pet',\n",
       "   2032: 'arm',\n",
       "   2491: 'cds',\n",
       "   2031: 'tel',\n",
       "   1193: 'pottery',\n",
       "   375: 'sheet',\n",
       "   2202: 'apparel',\n",
       "   1814: 'rear',\n",
       "   1461: 'joint',\n",
       "   756: 'board',\n",
       "   1765: 'sets',\n",
       "   696: 'sitemap'},\n",
       "  {1159: tensor(0.0002, device='cuda:0'),\n",
       "   1451: tensor(0.0002, device='cuda:0'),\n",
       "   1878: tensor(0.0002, device='cuda:0'),\n",
       "   316: tensor(0.0002, device='cuda:0'),\n",
       "   313: tensor(0.0002, device='cuda:0'),\n",
       "   1359: tensor(0.0002, device='cuda:0'),\n",
       "   635: tensor(0.0002, device='cuda:0'),\n",
       "   638: tensor(0.0002, device='cuda:0'),\n",
       "   2839: tensor(0.0002, device='cuda:0'),\n",
       "   894: tensor(0.0002, device='cuda:0'),\n",
       "   805: tensor(0.0002, device='cuda:0'),\n",
       "   411: tensor(0.0002, device='cuda:0'),\n",
       "   1527: tensor(0.0002, device='cuda:0'),\n",
       "   1757: tensor(0.0002, device='cuda:0'),\n",
       "   2032: tensor(0.0002, device='cuda:0'),\n",
       "   2491: tensor(0.0002, device='cuda:0'),\n",
       "   2031: tensor(0.0002, device='cuda:0'),\n",
       "   1193: tensor(0.0002, device='cuda:0'),\n",
       "   375: tensor(0.0002, device='cuda:0'),\n",
       "   2202: tensor(0.0002, device='cuda:0'),\n",
       "   1814: tensor(0.0002, device='cuda:0'),\n",
       "   1461: tensor(0.0002, device='cuda:0'),\n",
       "   756: tensor(0.0002, device='cuda:0'),\n",
       "   1765: tensor(0.0002, device='cuda:0'),\n",
       "   696: tensor(0.0002, device='cuda:0')},\n",
       "  {1159: tensor(82921.8906, device='cuda:0'),\n",
       "   1451: tensor(873247.8125, device='cuda:0'),\n",
       "   1878: tensor(636502.8750, device='cuda:0'),\n",
       "   316: tensor(2861998., device='cuda:0'),\n",
       "   313: tensor(443298.4062, device='cuda:0'),\n",
       "   1359: tensor(407512.4375, device='cuda:0'),\n",
       "   635: tensor(146862.5938, device='cuda:0'),\n",
       "   638: tensor(444934.4062, device='cuda:0'),\n",
       "   2839: tensor(668226.5625, device='cuda:0'),\n",
       "   894: tensor(229430.2500, device='cuda:0'),\n",
       "   805: tensor(432180.4062, device='cuda:0'),\n",
       "   411: tensor(599445.9375, device='cuda:0'),\n",
       "   1527: tensor(261227.1250, device='cuda:0'),\n",
       "   1757: tensor(189381.1094, device='cuda:0'),\n",
       "   2032: tensor(2110965.2500, device='cuda:0'),\n",
       "   2491: tensor(213519.1719, device='cuda:0'),\n",
       "   2031: tensor(347706.4688, device='cuda:0'),\n",
       "   1193: tensor(11602280., device='cuda:0'),\n",
       "   375: tensor(258025.4062, device='cuda:0'),\n",
       "   2202: tensor(1240898.6250, device='cuda:0'),\n",
       "   1814: tensor(374992.8750, device='cuda:0'),\n",
       "   1461: tensor(72226.6016, device='cuda:0'),\n",
       "   756: tensor(265670., device='cuda:0'),\n",
       "   1765: tensor(108451.7734, device='cuda:0'),\n",
       "   696: tensor(3050768.7500, device='cuda:0')},\n",
       "  {1159: tensor(13.7445, device='cuda:0'),\n",
       "   1451: tensor(36.6489, device='cuda:0'),\n",
       "   1878: tensor(2.1309, device='cuda:0'),\n",
       "   316: tensor(4.8306, device='cuda:0'),\n",
       "   313: tensor(4.0304, device='cuda:0'),\n",
       "   1359: tensor(3.4963, device='cuda:0'),\n",
       "   635: tensor(4.6018, device='cuda:0'),\n",
       "   638: tensor(5.9433, device='cuda:0'),\n",
       "   2839: tensor(12.6299, device='cuda:0'),\n",
       "   894: tensor(9.1344, device='cuda:0'),\n",
       "   805: tensor(6.6465, device='cuda:0'),\n",
       "   411: tensor(4.6652, device='cuda:0'),\n",
       "   1527: tensor(4.1432, device='cuda:0'),\n",
       "   1757: tensor(17.0372, device='cuda:0'),\n",
       "   2032: tensor(6.1750, device='cuda:0'),\n",
       "   2491: tensor(3.8144, device='cuda:0'),\n",
       "   2031: tensor(6.9686, device='cuda:0'),\n",
       "   1193: tensor(14.6646, device='cuda:0'),\n",
       "   375: tensor(10.8271, device='cuda:0'),\n",
       "   2202: tensor(6.6133, device='cuda:0'),\n",
       "   1814: tensor(12.7285, device='cuda:0'),\n",
       "   1461: tensor(9.4401, device='cuda:0'),\n",
       "   756: tensor(2.7718, device='cuda:0'),\n",
       "   1765: tensor(3.7814, device='cuda:0'),\n",
       "   696: tensor(5.3315, device='cuda:0')}),\n",
       " 10.0: ({1159: 'python',\n",
       "   1451: 'debian',\n",
       "   1878: 'python',\n",
       "   316: 'python',\n",
       "   313: 'python',\n",
       "   1359: 'python',\n",
       "   635: 'python',\n",
       "   638: 'python',\n",
       "   2839: 'python',\n",
       "   894: 'sand',\n",
       "   805: 'python',\n",
       "   411: 'python',\n",
       "   1527: 'installation',\n",
       "   1757: 'python',\n",
       "   2032: 'python',\n",
       "   2491: 'python',\n",
       "   2031: 'python',\n",
       "   1193: 'python',\n",
       "   375: 'sand',\n",
       "   2202: 'debian',\n",
       "   1814: 'python',\n",
       "   1461: 'python',\n",
       "   756: 's',\n",
       "   1765: 'python',\n",
       "   696: 'python'},\n",
       "  {1159: tensor(0.0003, device='cuda:0'),\n",
       "   1451: tensor(0.0003, device='cuda:0'),\n",
       "   1878: tensor(0.0003, device='cuda:0'),\n",
       "   316: tensor(0.0002, device='cuda:0'),\n",
       "   313: tensor(0.0002, device='cuda:0'),\n",
       "   1359: tensor(0.0004, device='cuda:0'),\n",
       "   635: tensor(0.0004, device='cuda:0'),\n",
       "   638: tensor(0.0004, device='cuda:0'),\n",
       "   2839: tensor(0.0003, device='cuda:0'),\n",
       "   894: tensor(0.0002, device='cuda:0'),\n",
       "   805: tensor(0.0003, device='cuda:0'),\n",
       "   411: tensor(0.0003, device='cuda:0'),\n",
       "   1527: tensor(0.0002, device='cuda:0'),\n",
       "   1757: tensor(0.0003, device='cuda:0'),\n",
       "   2032: tensor(0.0003, device='cuda:0'),\n",
       "   2491: tensor(0.0003, device='cuda:0'),\n",
       "   2031: tensor(0.0003, device='cuda:0'),\n",
       "   1193: tensor(0.0003, device='cuda:0'),\n",
       "   375: tensor(0.0002, device='cuda:0'),\n",
       "   2202: tensor(0.0002, device='cuda:0'),\n",
       "   1814: tensor(0.0003, device='cuda:0'),\n",
       "   1461: tensor(0.0002, device='cuda:0'),\n",
       "   756: tensor(0.0002, device='cuda:0'),\n",
       "   1765: tensor(0.0002, device='cuda:0'),\n",
       "   696: tensor(0.0003, device='cuda:0')},\n",
       "  {1159: tensor(47.5403, device='cuda:0'),\n",
       "   1451: tensor(504.3872, device='cuda:0'),\n",
       "   1878: tensor(88.9558, device='cuda:0'),\n",
       "   316: tensor(167.4874, device='cuda:0'),\n",
       "   313: tensor(356.7000, device='cuda:0'),\n",
       "   1359: tensor(81.3518, device='cuda:0'),\n",
       "   635: tensor(182.1362, device='cuda:0'),\n",
       "   638: tensor(117.1417, device='cuda:0'),\n",
       "   2839: tensor(396.8828, device='cuda:0'),\n",
       "   894: tensor(84.4430, device='cuda:0'),\n",
       "   805: tensor(112.0011, device='cuda:0'),\n",
       "   411: tensor(83.6769, device='cuda:0'),\n",
       "   1527: tensor(68.0621, device='cuda:0'),\n",
       "   1757: tensor(137.0617, device='cuda:0'),\n",
       "   2032: tensor(46.8650, device='cuda:0'),\n",
       "   2491: tensor(47.4444, device='cuda:0'),\n",
       "   2031: tensor(141.2540, device='cuda:0'),\n",
       "   1193: tensor(681.4331, device='cuda:0'),\n",
       "   375: tensor(2505.1147, device='cuda:0'),\n",
       "   2202: tensor(191.0231, device='cuda:0'),\n",
       "   1814: tensor(190.9388, device='cuda:0'),\n",
       "   1461: tensor(149.7675, device='cuda:0'),\n",
       "   756: tensor(55.0159, device='cuda:0'),\n",
       "   1765: tensor(259.5427, device='cuda:0'),\n",
       "   696: tensor(309.0431, device='cuda:0')},\n",
       "  {1159: tensor(1.2220, device='cuda:0'),\n",
       "   1451: tensor(2.3727, device='cuda:0'),\n",
       "   1878: tensor(2.3305, device='cuda:0'),\n",
       "   316: tensor(1.4641, device='cuda:0'),\n",
       "   313: tensor(1.1297, device='cuda:0'),\n",
       "   1359: tensor(3.8106, device='cuda:0'),\n",
       "   635: tensor(1.3288, device='cuda:0'),\n",
       "   638: tensor(1.4980, device='cuda:0'),\n",
       "   2839: tensor(1.1295, device='cuda:0'),\n",
       "   894: tensor(5.2233, device='cuda:0'),\n",
       "   805: tensor(1.9308, device='cuda:0'),\n",
       "   411: tensor(1.5314, device='cuda:0'),\n",
       "   1527: tensor(2.4524, device='cuda:0'),\n",
       "   1757: tensor(4.8626, device='cuda:0'),\n",
       "   2032: tensor(1.0105, device='cuda:0'),\n",
       "   2491: tensor(1.0734, device='cuda:0'),\n",
       "   2031: tensor(4.8733, device='cuda:0'),\n",
       "   1193: tensor(3.4223, device='cuda:0'),\n",
       "   375: tensor(1.5300, device='cuda:0'),\n",
       "   2202: tensor(4.7799, device='cuda:0'),\n",
       "   1814: tensor(2.7228, device='cuda:0'),\n",
       "   1461: tensor(3.0599, device='cuda:0'),\n",
       "   756: tensor(3.2117, device='cuda:0'),\n",
       "   1765: tensor(1.0890, device='cuda:0'),\n",
       "   696: tensor(2.0276, device='cuda:0')}),\n",
       " 25.0: ({1159: 'sand',\n",
       "   1451: 'chinese',\n",
       "   1878: 'dry',\n",
       "   316: 'sand',\n",
       "   313: 'set',\n",
       "   1359: 'set',\n",
       "   635: 'sand',\n",
       "   638: 'python',\n",
       "   2839: 'sand',\n",
       "   894: 'd',\n",
       "   805: 'python',\n",
       "   411: 'desert',\n",
       "   1527: 'finds',\n",
       "   1757: 'pet',\n",
       "   2032: 'sand',\n",
       "   2491: 'sand',\n",
       "   2031: 'sand',\n",
       "   1193: 'pottery',\n",
       "   375: 'religious',\n",
       "   2202: 'beach',\n",
       "   1814: 'configuration',\n",
       "   1461: 'dust',\n",
       "   756: 'sand',\n",
       "   1765: 'set',\n",
       "   696: 'python'},\n",
       "  {1159: tensor(0.0002, device='cuda:0'),\n",
       "   1451: tensor(0.0002, device='cuda:0'),\n",
       "   1878: tensor(0.0002, device='cuda:0'),\n",
       "   316: tensor(0.0002, device='cuda:0'),\n",
       "   313: tensor(0.0002, device='cuda:0'),\n",
       "   1359: tensor(0.0002, device='cuda:0'),\n",
       "   635: tensor(0.0003, device='cuda:0'),\n",
       "   638: tensor(0.0002, device='cuda:0'),\n",
       "   2839: tensor(0.0002, device='cuda:0'),\n",
       "   894: tensor(0.0002, device='cuda:0'),\n",
       "   805: tensor(0.0002, device='cuda:0'),\n",
       "   411: tensor(0.0002, device='cuda:0'),\n",
       "   1527: tensor(0.0002, device='cuda:0'),\n",
       "   1757: tensor(0.0002, device='cuda:0'),\n",
       "   2032: tensor(0.0002, device='cuda:0'),\n",
       "   2491: tensor(0.0002, device='cuda:0'),\n",
       "   2031: tensor(0.0002, device='cuda:0'),\n",
       "   1193: tensor(0.0002, device='cuda:0'),\n",
       "   375: tensor(0.0002, device='cuda:0'),\n",
       "   2202: tensor(0.0002, device='cuda:0'),\n",
       "   1814: tensor(0.0002, device='cuda:0'),\n",
       "   1461: tensor(0.0002, device='cuda:0'),\n",
       "   756: tensor(0.0002, device='cuda:0'),\n",
       "   1765: tensor(0.0002, device='cuda:0'),\n",
       "   696: tensor(0.0002, device='cuda:0')},\n",
       "  {1159: tensor(8352.3271, device='cuda:0'),\n",
       "   1451: tensor(60492.2617, device='cuda:0'),\n",
       "   1878: tensor(35487.5898, device='cuda:0'),\n",
       "   316: tensor(686049.1875, device='cuda:0'),\n",
       "   313: tensor(52725.5625, device='cuda:0'),\n",
       "   1359: tensor(95980.8750, device='cuda:0'),\n",
       "   635: tensor(16005.7129, device='cuda:0'),\n",
       "   638: tensor(32342.2949, device='cuda:0'),\n",
       "   2839: tensor(53671.1211, device='cuda:0'),\n",
       "   894: tensor(15822.9268, device='cuda:0'),\n",
       "   805: tensor(109989.4531, device='cuda:0'),\n",
       "   411: tensor(12297.3066, device='cuda:0'),\n",
       "   1527: tensor(32035.1621, device='cuda:0'),\n",
       "   1757: tensor(14089.3516, device='cuda:0'),\n",
       "   2032: tensor(111352.9141, device='cuda:0'),\n",
       "   2491: tensor(19821.1641, device='cuda:0'),\n",
       "   2031: tensor(91728.7266, device='cuda:0'),\n",
       "   1193: tensor(404824.0938, device='cuda:0'),\n",
       "   375: tensor(52496.0742, device='cuda:0'),\n",
       "   2202: tensor(138515.2344, device='cuda:0'),\n",
       "   1814: tensor(75063.1875, device='cuda:0'),\n",
       "   1461: tensor(91612.6172, device='cuda:0'),\n",
       "   756: tensor(16635.1719, device='cuda:0'),\n",
       "   1765: tensor(18641.4590, device='cuda:0'),\n",
       "   696: tensor(99293.1172, device='cuda:0')},\n",
       "  {1159: tensor(3.3455, device='cuda:0'),\n",
       "   1451: tensor(9.8456, device='cuda:0'),\n",
       "   1878: tensor(1.4993, device='cuda:0'),\n",
       "   316: tensor(3.2026, device='cuda:0'),\n",
       "   313: tensor(3.6249, device='cuda:0'),\n",
       "   1359: tensor(2.2599, device='cuda:0'),\n",
       "   635: tensor(3.4744, device='cuda:0'),\n",
       "   638: tensor(4.4619, device='cuda:0'),\n",
       "   2839: tensor(4.2369, device='cuda:0'),\n",
       "   894: tensor(4.8141, device='cuda:0'),\n",
       "   805: tensor(5.5801, device='cuda:0'),\n",
       "   411: tensor(5.8552, device='cuda:0'),\n",
       "   1527: tensor(6.0901, device='cuda:0'),\n",
       "   1757: tensor(13.6722, device='cuda:0'),\n",
       "   2032: tensor(4.1264, device='cuda:0'),\n",
       "   2491: tensor(3.1193, device='cuda:0'),\n",
       "   2031: tensor(11.3685, device='cuda:0'),\n",
       "   1193: tensor(3.1932, device='cuda:0'),\n",
       "   375: tensor(4.3168, device='cuda:0'),\n",
       "   2202: tensor(4.3112, device='cuda:0'),\n",
       "   1814: tensor(2.3145, device='cuda:0'),\n",
       "   1461: tensor(4.6668, device='cuda:0'),\n",
       "   756: tensor(2.1322, device='cuda:0'),\n",
       "   1765: tensor(4.9622, device='cuda:0'),\n",
       "   696: tensor(1.6437, device='cuda:0')}),\n",
       " 100.0: ({1159: 'tiny',\n",
       "   1451: 'overall',\n",
       "   1878: 'php',\n",
       "   316: 'ftp',\n",
       "   313: 'and',\n",
       "   1359: 'patches',\n",
       "   635: 'title',\n",
       "   638: 'row',\n",
       "   2839: 'covers',\n",
       "   894: 'range',\n",
       "   805: 'amp',\n",
       "   411: 'photo',\n",
       "   1527: 'investigation',\n",
       "   1757: 'chair',\n",
       "   2032: 'belt',\n",
       "   2491: 'cards',\n",
       "   2031: 'font',\n",
       "   1193: 'pottery',\n",
       "   375: 'sheet',\n",
       "   2202: 'front',\n",
       "   1814: 'rear',\n",
       "   1461: 'pair',\n",
       "   756: 'si',\n",
       "   1765: 'sets',\n",
       "   696: 'presentations'},\n",
       "  {1159: tensor(0.0002, device='cuda:0'),\n",
       "   1451: tensor(0.0003, device='cuda:0'),\n",
       "   1878: tensor(0.0002, device='cuda:0'),\n",
       "   316: tensor(0.0002, device='cuda:0'),\n",
       "   313: tensor(0.0002, device='cuda:0'),\n",
       "   1359: tensor(0.0002, device='cuda:0'),\n",
       "   635: tensor(0.0002, device='cuda:0'),\n",
       "   638: tensor(0.0002, device='cuda:0'),\n",
       "   2839: tensor(0.0003, device='cuda:0'),\n",
       "   894: tensor(0.0002, device='cuda:0'),\n",
       "   805: tensor(0.0002, device='cuda:0'),\n",
       "   411: tensor(0.0002, device='cuda:0'),\n",
       "   1527: tensor(0.0002, device='cuda:0'),\n",
       "   1757: tensor(0.0002, device='cuda:0'),\n",
       "   2032: tensor(0.0002, device='cuda:0'),\n",
       "   2491: tensor(0.0002, device='cuda:0'),\n",
       "   2031: tensor(0.0002, device='cuda:0'),\n",
       "   1193: tensor(0.0002, device='cuda:0'),\n",
       "   375: tensor(0.0002, device='cuda:0'),\n",
       "   2202: tensor(0.0002, device='cuda:0'),\n",
       "   1814: tensor(0.0002, device='cuda:0'),\n",
       "   1461: tensor(0.0002, device='cuda:0'),\n",
       "   756: tensor(0.0002, device='cuda:0'),\n",
       "   1765: tensor(0.0002, device='cuda:0'),\n",
       "   696: tensor(0.0002, device='cuda:0')},\n",
       "  {1159: tensor(296810.9375, device='cuda:0'),\n",
       "   1451: tensor(1703155.6250, device='cuda:0'),\n",
       "   1878: tensor(1211910.2500, device='cuda:0'),\n",
       "   316: tensor(949004.6875, device='cuda:0'),\n",
       "   313: tensor(1989698.3750, device='cuda:0'),\n",
       "   1359: tensor(1585325.8750, device='cuda:0'),\n",
       "   635: tensor(339119.9062, device='cuda:0'),\n",
       "   638: tensor(1092552.3750, device='cuda:0'),\n",
       "   2839: tensor(2851988.7500, device='cuda:0'),\n",
       "   894: tensor(961512., device='cuda:0'),\n",
       "   805: tensor(581763.3125, device='cuda:0'),\n",
       "   411: tensor(5112115.5000, device='cuda:0'),\n",
       "   1527: tensor(1191788.2500, device='cuda:0'),\n",
       "   1757: tensor(1475359.6250, device='cuda:0'),\n",
       "   2032: tensor(1037495., device='cuda:0'),\n",
       "   2491: tensor(838461.6250, device='cuda:0'),\n",
       "   2031: tensor(2083986., device='cuda:0'),\n",
       "   1193: tensor(49167404., device='cuda:0'),\n",
       "   375: tensor(787487.6875, device='cuda:0'),\n",
       "   2202: tensor(1587391.8750, device='cuda:0'),\n",
       "   1814: tensor(1114922., device='cuda:0'),\n",
       "   1461: tensor(172324.8906, device='cuda:0'),\n",
       "   756: tensor(1487050.1250, device='cuda:0'),\n",
       "   1765: tensor(127342.9531, device='cuda:0'),\n",
       "   696: tensor(20306896., device='cuda:0')},\n",
       "  {1159: tensor(25.4872, device='cuda:0'),\n",
       "   1451: tensor(42.0177, device='cuda:0'),\n",
       "   1878: tensor(1.9053, device='cuda:0'),\n",
       "   316: tensor(10.9967, device='cuda:0'),\n",
       "   313: tensor(2.8183, device='cuda:0'),\n",
       "   1359: tensor(6.9416, device='cuda:0'),\n",
       "   635: tensor(7.1856, device='cuda:0'),\n",
       "   638: tensor(5.3187, device='cuda:0'),\n",
       "   2839: tensor(43.1626, device='cuda:0'),\n",
       "   894: tensor(16.0035, device='cuda:0'),\n",
       "   805: tensor(7.3298, device='cuda:0'),\n",
       "   411: tensor(8.6894, device='cuda:0'),\n",
       "   1527: tensor(7.0758, device='cuda:0'),\n",
       "   1757: tensor(4.6081, device='cuda:0'),\n",
       "   2032: tensor(5.3889, device='cuda:0'),\n",
       "   2491: tensor(11.0425, device='cuda:0'),\n",
       "   2031: tensor(22.2788, device='cuda:0'),\n",
       "   1193: tensor(23.7651, device='cuda:0'),\n",
       "   375: tensor(13.2648, device='cuda:0'),\n",
       "   2202: tensor(8.3711, device='cuda:0'),\n",
       "   1814: tensor(17.9898, device='cuda:0'),\n",
       "   1461: tensor(7.1044, device='cuda:0'),\n",
       "   756: tensor(3.4434, device='cuda:0'),\n",
       "   1765: tensor(4.1899, device='cuda:0'),\n",
       "   696: tensor(7.7187, device='cuda:0')}),\n",
       " 17.5: ({1159: 'sand',\n",
       "   1451: 'sand',\n",
       "   1878: 'sand',\n",
       "   316: 'sand',\n",
       "   313: 'sand',\n",
       "   1359: 'python',\n",
       "   635: 'sand',\n",
       "   638: 'python',\n",
       "   2839: 'sand',\n",
       "   894: 'desert',\n",
       "   805: 'python',\n",
       "   411: 'desert',\n",
       "   1527: 'installation',\n",
       "   1757: 'python',\n",
       "   2032: 'python',\n",
       "   2491: 'sand',\n",
       "   2031: 'sand',\n",
       "   1193: 'comparison',\n",
       "   375: 'religious',\n",
       "   2202: 'beach',\n",
       "   1814: 'installation',\n",
       "   1461: 'desert',\n",
       "   756: 's',\n",
       "   1765: 'set',\n",
       "   696: 'python'},\n",
       "  {1159: tensor(0.0002, device='cuda:0'),\n",
       "   1451: tensor(0.0002, device='cuda:0'),\n",
       "   1878: tensor(0.0002, device='cuda:0'),\n",
       "   316: tensor(0.0002, device='cuda:0'),\n",
       "   313: tensor(0.0002, device='cuda:0'),\n",
       "   1359: tensor(0.0002, device='cuda:0'),\n",
       "   635: tensor(0.0003, device='cuda:0'),\n",
       "   638: tensor(0.0003, device='cuda:0'),\n",
       "   2839: tensor(0.0002, device='cuda:0'),\n",
       "   894: tensor(0.0002, device='cuda:0'),\n",
       "   805: tensor(0.0003, device='cuda:0'),\n",
       "   411: tensor(0.0002, device='cuda:0'),\n",
       "   1527: tensor(0.0002, device='cuda:0'),\n",
       "   1757: tensor(0.0002, device='cuda:0'),\n",
       "   2032: tensor(0.0002, device='cuda:0'),\n",
       "   2491: tensor(0.0002, device='cuda:0'),\n",
       "   2031: tensor(0.0002, device='cuda:0'),\n",
       "   1193: tensor(0.0002, device='cuda:0'),\n",
       "   375: tensor(0.0002, device='cuda:0'),\n",
       "   2202: tensor(0.0002, device='cuda:0'),\n",
       "   1814: tensor(0.0002, device='cuda:0'),\n",
       "   1461: tensor(0.0002, device='cuda:0'),\n",
       "   756: tensor(0.0002, device='cuda:0'),\n",
       "   1765: tensor(0.0002, device='cuda:0'),\n",
       "   696: tensor(0.0003, device='cuda:0')},\n",
       "  {1159: tensor(1382.5858, device='cuda:0'),\n",
       "   1451: tensor(16635.8379, device='cuda:0'),\n",
       "   1878: tensor(3556.4705, device='cuda:0'),\n",
       "   316: tensor(21358.5723, device='cuda:0'),\n",
       "   313: tensor(10758.8613, device='cuda:0'),\n",
       "   1359: tensor(21257.7344, device='cuda:0'),\n",
       "   635: tensor(2420.3022, device='cuda:0'),\n",
       "   638: tensor(4301.4585, device='cuda:0'),\n",
       "   2839: tensor(7396.1680, device='cuda:0'),\n",
       "   894: tensor(870.6409, device='cuda:0'),\n",
       "   805: tensor(7261.1953, device='cuda:0'),\n",
       "   411: tensor(4550.9141, device='cuda:0'),\n",
       "   1527: tensor(1996.3665, device='cuda:0'),\n",
       "   1757: tensor(1876.3889, device='cuda:0'),\n",
       "   2032: tensor(1544.7622, device='cuda:0'),\n",
       "   2491: tensor(2709.7253, device='cuda:0'),\n",
       "   2031: tensor(6683.9258, device='cuda:0'),\n",
       "   1193: tensor(34635.8672, device='cuda:0'),\n",
       "   375: tensor(46652.2031, device='cuda:0'),\n",
       "   2202: tensor(8941.8506, device='cuda:0'),\n",
       "   1814: tensor(12812.0420, device='cuda:0'),\n",
       "   1461: tensor(3053.7148, device='cuda:0'),\n",
       "   756: tensor(2287.3184, device='cuda:0'),\n",
       "   1765: tensor(4851.7881, device='cuda:0'),\n",
       "   696: tensor(7457.6011, device='cuda:0')},\n",
       "  {1159: tensor(1.9890, device='cuda:0'),\n",
       "   1451: tensor(4.4615, device='cuda:0'),\n",
       "   1878: tensor(3.9146, device='cuda:0'),\n",
       "   316: tensor(1.7704, device='cuda:0'),\n",
       "   313: tensor(2.1182, device='cuda:0'),\n",
       "   1359: tensor(3.4827, device='cuda:0'),\n",
       "   635: tensor(2.9207, device='cuda:0'),\n",
       "   638: tensor(2.9227, device='cuda:0'),\n",
       "   2839: tensor(2.8623, device='cuda:0'),\n",
       "   894: tensor(7.6060, device='cuda:0'),\n",
       "   805: tensor(3.7051, device='cuda:0'),\n",
       "   411: tensor(2.8237, device='cuda:0'),\n",
       "   1527: tensor(6.2494, device='cuda:0'),\n",
       "   1757: tensor(11.1306, device='cuda:0'),\n",
       "   2032: tensor(2.1905, device='cuda:0'),\n",
       "   2491: tensor(2.5544, device='cuda:0'),\n",
       "   2031: tensor(10.4619, device='cuda:0'),\n",
       "   1193: tensor(2.7390, device='cuda:0'),\n",
       "   375: tensor(4.9620, device='cuda:0'),\n",
       "   2202: tensor(6.8981, device='cuda:0'),\n",
       "   1814: tensor(4.2953, device='cuda:0'),\n",
       "   1461: tensor(4.7866, device='cuda:0'),\n",
       "   756: tensor(4.4559, device='cuda:0'),\n",
       "   1765: tensor(2.4907, device='cuda:0'),\n",
       "   696: tensor(2.8489, device='cuda:0')}),\n",
       " 5.0: ({1159: 'python',\n",
       "   1451: 'python',\n",
       "   1878: 'python',\n",
       "   316: 'python',\n",
       "   313: 'python',\n",
       "   1359: 'python',\n",
       "   635: 'python',\n",
       "   638: 'python',\n",
       "   2839: 'python',\n",
       "   894: 'python',\n",
       "   805: 'python',\n",
       "   411: 'python',\n",
       "   1527: 'python',\n",
       "   1757: 'python',\n",
       "   2032: 'python',\n",
       "   2491: 'python',\n",
       "   2031: 'python',\n",
       "   1193: 'python',\n",
       "   375: 'python',\n",
       "   2202: 'python',\n",
       "   1814: 'python',\n",
       "   1461: 'python',\n",
       "   756: 'python',\n",
       "   1765: 'debian',\n",
       "   696: 'python'},\n",
       "  {1159: tensor(0.0004, device='cuda:0'),\n",
       "   1451: tensor(0.0003, device='cuda:0'),\n",
       "   1878: tensor(0.0004, device='cuda:0'),\n",
       "   316: tensor(0.0003, device='cuda:0'),\n",
       "   313: tensor(0.0003, device='cuda:0'),\n",
       "   1359: tensor(0.0004, device='cuda:0'),\n",
       "   635: tensor(0.0004, device='cuda:0'),\n",
       "   638: tensor(0.0004, device='cuda:0'),\n",
       "   2839: tensor(0.0004, device='cuda:0'),\n",
       "   894: tensor(0.0003, device='cuda:0'),\n",
       "   805: tensor(0.0003, device='cuda:0'),\n",
       "   411: tensor(0.0003, device='cuda:0'),\n",
       "   1527: tensor(0.0003, device='cuda:0'),\n",
       "   1757: tensor(0.0003, device='cuda:0'),\n",
       "   2032: tensor(0.0004, device='cuda:0'),\n",
       "   2491: tensor(0.0003, device='cuda:0'),\n",
       "   2031: tensor(0.0003, device='cuda:0'),\n",
       "   1193: tensor(0.0004, device='cuda:0'),\n",
       "   375: tensor(0.0003, device='cuda:0'),\n",
       "   2202: tensor(0.0003, device='cuda:0'),\n",
       "   1814: tensor(0.0004, device='cuda:0'),\n",
       "   1461: tensor(0.0003, device='cuda:0'),\n",
       "   756: tensor(0.0003, device='cuda:0'),\n",
       "   1765: tensor(0.0003, device='cuda:0'),\n",
       "   696: tensor(0.0004, device='cuda:0')},\n",
       "  {1159: tensor(8.2793, device='cuda:0'),\n",
       "   1451: tensor(21.7744, device='cuda:0'),\n",
       "   1878: tensor(6.5077, device='cuda:0'),\n",
       "   316: tensor(7.0213, device='cuda:0'),\n",
       "   313: tensor(12.2403, device='cuda:0'),\n",
       "   1359: tensor(5.1146, device='cuda:0'),\n",
       "   635: tensor(10.8177, device='cuda:0'),\n",
       "   638: tensor(10.2655, device='cuda:0'),\n",
       "   2839: tensor(16.0017, device='cuda:0'),\n",
       "   894: tensor(6.1552, device='cuda:0'),\n",
       "   805: tensor(7.6425, device='cuda:0'),\n",
       "   411: tensor(6.6892, device='cuda:0'),\n",
       "   1527: tensor(5.8340, device='cuda:0'),\n",
       "   1757: tensor(6.5336, device='cuda:0'),\n",
       "   2032: tensor(4.8654, device='cuda:0'),\n",
       "   2491: tensor(5.7913, device='cuda:0'),\n",
       "   2031: tensor(7.4659, device='cuda:0'),\n",
       "   1193: tensor(14.2988, device='cuda:0'),\n",
       "   375: tensor(42.2598, device='cuda:0'),\n",
       "   2202: tensor(10.6296, device='cuda:0'),\n",
       "   1814: tensor(6.1232, device='cuda:0'),\n",
       "   1461: tensor(8.3755, device='cuda:0'),\n",
       "   756: tensor(5.5016, device='cuda:0'),\n",
       "   1765: tensor(9.2651, device='cuda:0'),\n",
       "   696: tensor(9.8623, device='cuda:0')},\n",
       "  {1159: tensor(0.6428, device='cuda:0'),\n",
       "   1451: tensor(1.0800, device='cuda:0'),\n",
       "   1878: tensor(0.7500, device='cuda:0'),\n",
       "   316: tensor(0.6281, device='cuda:0'),\n",
       "   313: tensor(0.5731, device='cuda:0'),\n",
       "   1359: tensor(1.6151, device='cuda:0'),\n",
       "   635: tensor(1.1261, device='cuda:0'),\n",
       "   638: tensor(1.1524, device='cuda:0'),\n",
       "   2839: tensor(0.4348, device='cuda:0'),\n",
       "   894: tensor(1.6912, device='cuda:0'),\n",
       "   805: tensor(1.2116, device='cuda:0'),\n",
       "   411: tensor(0.6742, device='cuda:0'),\n",
       "   1527: tensor(0.9123, device='cuda:0'),\n",
       "   1757: tensor(1.4702, device='cuda:0'),\n",
       "   2032: tensor(0.4156, device='cuda:0'),\n",
       "   2491: tensor(0.9554, device='cuda:0'),\n",
       "   2031: tensor(1.3765, device='cuda:0'),\n",
       "   1193: tensor(1.5901, device='cuda:0'),\n",
       "   375: tensor(0.4424, device='cuda:0'),\n",
       "   2202: tensor(1.6484, device='cuda:0'),\n",
       "   1814: tensor(1.0755, device='cuda:0'),\n",
       "   1461: tensor(1.2467, device='cuda:0'),\n",
       "   756: tensor(1.2376, device='cuda:0'),\n",
       "   1765: tensor(0.9867, device='cuda:0'),\n",
       "   696: tensor(0.7061, device='cuda:0')}),\n",
       " 1.0: ({1159: 'python',\n",
       "   1451: 'python',\n",
       "   1878: 'python',\n",
       "   316: 'python',\n",
       "   313: 'python',\n",
       "   1359: 'python',\n",
       "   635: 'python',\n",
       "   638: 'python',\n",
       "   2839: 'python',\n",
       "   894: 'python',\n",
       "   805: 'python',\n",
       "   411: 'python',\n",
       "   1527: 'python',\n",
       "   1757: 'python',\n",
       "   2032: 'python',\n",
       "   2491: 'python',\n",
       "   2031: 'python',\n",
       "   1193: 'python',\n",
       "   375: 'python',\n",
       "   2202: 'python',\n",
       "   1814: 'python',\n",
       "   1461: 'python',\n",
       "   756: 'python',\n",
       "   1765: 'python',\n",
       "   696: 'python'},\n",
       "  {1159: tensor(0.0004, device='cuda:0'),\n",
       "   1451: tensor(0.0003, device='cuda:0'),\n",
       "   1878: tensor(0.0004, device='cuda:0'),\n",
       "   316: tensor(0.0003, device='cuda:0'),\n",
       "   313: tensor(0.0003, device='cuda:0'),\n",
       "   1359: tensor(0.0004, device='cuda:0'),\n",
       "   635: tensor(0.0004, device='cuda:0'),\n",
       "   638: tensor(0.0004, device='cuda:0'),\n",
       "   2839: tensor(0.0004, device='cuda:0'),\n",
       "   894: tensor(0.0003, device='cuda:0'),\n",
       "   805: tensor(0.0003, device='cuda:0'),\n",
       "   411: tensor(0.0003, device='cuda:0'),\n",
       "   1527: tensor(0.0003, device='cuda:0'),\n",
       "   1757: tensor(0.0003, device='cuda:0'),\n",
       "   2032: tensor(0.0003, device='cuda:0'),\n",
       "   2491: tensor(0.0003, device='cuda:0'),\n",
       "   2031: tensor(0.0003, device='cuda:0'),\n",
       "   1193: tensor(0.0003, device='cuda:0'),\n",
       "   375: tensor(0.0003, device='cuda:0'),\n",
       "   2202: tensor(0.0003, device='cuda:0'),\n",
       "   1814: tensor(0.0004, device='cuda:0'),\n",
       "   1461: tensor(0.0004, device='cuda:0'),\n",
       "   756: tensor(0.0003, device='cuda:0'),\n",
       "   1765: tensor(0.0003, device='cuda:0'),\n",
       "   696: tensor(0.0004, device='cuda:0')},\n",
       "  {1159: tensor(1.5492, device='cuda:0'),\n",
       "   1451: tensor(1.7601, device='cuda:0'),\n",
       "   1878: tensor(1.4104, device='cuda:0'),\n",
       "   316: tensor(1.3898, device='cuda:0'),\n",
       "   313: tensor(1.4877, device='cuda:0'),\n",
       "   1359: tensor(1.3467, device='cuda:0'),\n",
       "   635: tensor(1.4977, device='cuda:0'),\n",
       "   638: tensor(1.5426, device='cuda:0'),\n",
       "   2839: tensor(1.6409, device='cuda:0'),\n",
       "   894: tensor(1.2997, device='cuda:0'),\n",
       "   805: tensor(1.4514, device='cuda:0'),\n",
       "   411: tensor(1.4209, device='cuda:0'),\n",
       "   1527: tensor(1.3788, device='cuda:0'),\n",
       "   1757: tensor(1.3930, device='cuda:0'),\n",
       "   2032: tensor(1.3351, device='cuda:0'),\n",
       "   2491: tensor(1.3781, device='cuda:0'),\n",
       "   2031: tensor(1.3879, device='cuda:0'),\n",
       "   1193: tensor(1.6034, device='cuda:0'),\n",
       "   375: tensor(1.6769, device='cuda:0'),\n",
       "   2202: tensor(1.5183, device='cuda:0'),\n",
       "   1814: tensor(1.3640, device='cuda:0'),\n",
       "   1461: tensor(1.4580, device='cuda:0'),\n",
       "   756: tensor(1.3852, device='cuda:0'),\n",
       "   1765: tensor(1.4003, device='cuda:0'),\n",
       "   696: tensor(1.4860, device='cuda:0')},\n",
       "  {1159: tensor(0.1878, device='cuda:0'),\n",
       "   1451: tensor(0.1222, device='cuda:0'),\n",
       "   1878: tensor(0.1932, device='cuda:0'),\n",
       "   316: tensor(0.1060, device='cuda:0'),\n",
       "   313: tensor(0.1137, device='cuda:0'),\n",
       "   1359: tensor(0.2447, device='cuda:0'),\n",
       "   635: tensor(0.2675, device='cuda:0'),\n",
       "   638: tensor(0.2923, device='cuda:0'),\n",
       "   2839: tensor(0.1192, device='cuda:0'),\n",
       "   894: tensor(0.1957, device='cuda:0'),\n",
       "   805: tensor(0.2397, device='cuda:0'),\n",
       "   411: tensor(0.1024, device='cuda:0'),\n",
       "   1527: tensor(0.1995, device='cuda:0'),\n",
       "   1757: tensor(0.1624, device='cuda:0'),\n",
       "   2032: tensor(0.0969, device='cuda:0'),\n",
       "   2491: tensor(0.2390, device='cuda:0'),\n",
       "   2031: tensor(0.1487, device='cuda:0'),\n",
       "   1193: tensor(0.2440, device='cuda:0'),\n",
       "   375: tensor(0.1488, device='cuda:0'),\n",
       "   2202: tensor(0.1719, device='cuda:0'),\n",
       "   1814: tensor(0.1791, device='cuda:0'),\n",
       "   1461: tensor(0.2166, device='cuda:0'),\n",
       "   756: tensor(0.1555, device='cuda:0'),\n",
       "   1765: tensor(0.2946, device='cuda:0'),\n",
       "   696: tensor(0.1113, device='cuda:0')}),\n",
       " 150.0: ({1159: 'tiny',\n",
       "   1451: 'overall',\n",
       "   1878: 'spectrum',\n",
       "   316: 'ftp',\n",
       "   313: 'and',\n",
       "   1359: 'patches',\n",
       "   635: 'title',\n",
       "   638: 'row',\n",
       "   2839: 'covers',\n",
       "   894: 'range',\n",
       "   805: 'groups',\n",
       "   411: 'photo',\n",
       "   1527: 'protected',\n",
       "   1757: 'chair',\n",
       "   2032: 'belt',\n",
       "   2491: 'cards',\n",
       "   2031: 'font',\n",
       "   1193: 'table',\n",
       "   375: 'sheet',\n",
       "   2202: 'front',\n",
       "   1814: 'rear',\n",
       "   1461: 'pair',\n",
       "   756: 'si',\n",
       "   1765: 'huge',\n",
       "   696: 'presentations'},\n",
       "  {1159: tensor(0.0002, device='cuda:0'),\n",
       "   1451: tensor(0.0003, device='cuda:0'),\n",
       "   1878: tensor(0.0002, device='cuda:0'),\n",
       "   316: tensor(0.0002, device='cuda:0'),\n",
       "   313: tensor(0.0002, device='cuda:0'),\n",
       "   1359: tensor(0.0002, device='cuda:0'),\n",
       "   635: tensor(0.0002, device='cuda:0'),\n",
       "   638: tensor(0.0002, device='cuda:0'),\n",
       "   2839: tensor(0.0003, device='cuda:0'),\n",
       "   894: tensor(0.0002, device='cuda:0'),\n",
       "   805: tensor(0.0002, device='cuda:0'),\n",
       "   411: tensor(0.0002, device='cuda:0'),\n",
       "   1527: tensor(0.0002, device='cuda:0'),\n",
       "   1757: tensor(0.0002, device='cuda:0'),\n",
       "   2032: tensor(0.0002, device='cuda:0'),\n",
       "   2491: tensor(0.0002, device='cuda:0'),\n",
       "   2031: tensor(0.0002, device='cuda:0'),\n",
       "   1193: tensor(0.0002, device='cuda:0'),\n",
       "   375: tensor(0.0002, device='cuda:0'),\n",
       "   2202: tensor(0.0002, device='cuda:0'),\n",
       "   1814: tensor(0.0002, device='cuda:0'),\n",
       "   1461: tensor(0.0002, device='cuda:0'),\n",
       "   756: tensor(0.0002, device='cuda:0'),\n",
       "   1765: tensor(0.0002, device='cuda:0'),\n",
       "   696: tensor(0.0002, device='cuda:0')},\n",
       "  {1159: tensor(506456.4062, device='cuda:0'),\n",
       "   1451: tensor(1948348.2500, device='cuda:0'),\n",
       "   1878: tensor(1100601., device='cuda:0'),\n",
       "   316: tensor(1710908.6250, device='cuda:0'),\n",
       "   313: tensor(2716348., device='cuda:0'),\n",
       "   1359: tensor(2438950.5000, device='cuda:0'),\n",
       "   635: tensor(610534.1875, device='cuda:0'),\n",
       "   638: tensor(1271379.2500, device='cuda:0'),\n",
       "   2839: tensor(3276223.5000, device='cuda:0'),\n",
       "   894: tensor(1530483.3750, device='cuda:0'),\n",
       "   805: tensor(875409.6875, device='cuda:0'),\n",
       "   411: tensor(8018859.5000, device='cuda:0'),\n",
       "   1527: tensor(1615435.3750, device='cuda:0'),\n",
       "   1757: tensor(2261220.5000, device='cuda:0'),\n",
       "   2032: tensor(1758879.6250, device='cuda:0'),\n",
       "   2491: tensor(1183113.3750, device='cuda:0'),\n",
       "   2031: tensor(2769219.7500, device='cuda:0'),\n",
       "   1193: tensor(73979896., device='cuda:0'),\n",
       "   375: tensor(1179577.7500, device='cuda:0'),\n",
       "   2202: tensor(1832882.6250, device='cuda:0'),\n",
       "   1814: tensor(1441231.3750, device='cuda:0'),\n",
       "   1461: tensor(205508.5312, device='cuda:0'),\n",
       "   756: tensor(2260881., device='cuda:0'),\n",
       "   1765: tensor(187586.7969, device='cuda:0'),\n",
       "   696: tensor(30134762., device='cuda:0')},\n",
       "  {1159: tensor(25.5987, device='cuda:0'),\n",
       "   1451: tensor(41.6169, device='cuda:0'),\n",
       "   1878: tensor(2.0294, device='cuda:0'),\n",
       "   316: tensor(9.3142, device='cuda:0'),\n",
       "   313: tensor(4.8725, device='cuda:0'),\n",
       "   1359: tensor(8.5789, device='cuda:0'),\n",
       "   635: tensor(8.3828, device='cuda:0'),\n",
       "   638: tensor(6.8237, device='cuda:0'),\n",
       "   2839: tensor(53.8458, device='cuda:0'),\n",
       "   894: tensor(15.3193, device='cuda:0'),\n",
       "   805: tensor(6.3895, device='cuda:0'),\n",
       "   411: tensor(11.0378, device='cuda:0'),\n",
       "   1527: tensor(7.3992, device='cuda:0'),\n",
       "   1757: tensor(3.7663, device='cuda:0'),\n",
       "   2032: tensor(5.8163, device='cuda:0'),\n",
       "   2491: tensor(12.7845, device='cuda:0'),\n",
       "   2031: tensor(30.0229, device='cuda:0'),\n",
       "   1193: tensor(25.5751, device='cuda:0'),\n",
       "   375: tensor(11.1957, device='cuda:0'),\n",
       "   2202: tensor(10.4516, device='cuda:0'),\n",
       "   1814: tensor(16.5797, device='cuda:0'),\n",
       "   1461: tensor(7.9174, device='cuda:0'),\n",
       "   756: tensor(4.0570, device='cuda:0'),\n",
       "   1765: tensor(5.6904, device='cuda:0'),\n",
       "   696: tensor(7.4095, device='cuda:0')})}"
      ]
     },
     "execution_count": 401,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_strength_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "feat_num: 1159\n",
      "50.0 tiny\n",
      "50.0 tensor(0.0002, device='cuda:0')\n",
      "50.0 tensor(82921.8906, device='cuda:0')\n",
      "10.0 python\n",
      "10.0 tensor(0.0003, device='cuda:0')\n",
      "10.0 tensor(47.5403, device='cuda:0')\n",
      "25.0 sand\n",
      "25.0 tensor(0.0002, device='cuda:0')\n",
      "25.0 tensor(8352.3271, device='cuda:0')\n",
      "100.0 tiny\n",
      "100.0 tensor(0.0002, device='cuda:0')\n",
      "100.0 tensor(296810.9375, device='cuda:0')\n",
      "17.5 sand\n",
      "17.5 tensor(0.0002, device='cuda:0')\n",
      "17.5 tensor(1382.5858, device='cuda:0')\n",
      "5.0 python\n",
      "5.0 tensor(0.0004, device='cuda:0')\n",
      "5.0 tensor(8.2793, device='cuda:0')\n",
      "1.0 python\n",
      "1.0 tensor(0.0004, device='cuda:0')\n",
      "1.0 tensor(1.5492, device='cuda:0')\n",
      "150.0 tiny\n",
      "150.0 tensor(0.0002, device='cuda:0')\n",
      "150.0 tensor(506456.4062, device='cuda:0')\n",
      "=====================\n",
      "feat_num: 1451\n",
      "50.0 overall\n",
      "50.0 tensor(0.0002, device='cuda:0')\n",
      "50.0 tensor(873247.8125, device='cuda:0')\n",
      "10.0 debian\n",
      "10.0 tensor(0.0003, device='cuda:0')\n",
      "10.0 tensor(504.3872, device='cuda:0')\n",
      "25.0 chinese\n",
      "25.0 tensor(0.0002, device='cuda:0')\n",
      "25.0 tensor(60492.2617, device='cuda:0')\n",
      "100.0 overall\n",
      "100.0 tensor(0.0003, device='cuda:0')\n",
      "100.0 tensor(1703155.6250, device='cuda:0')\n",
      "17.5 sand\n",
      "17.5 tensor(0.0002, device='cuda:0')\n",
      "17.5 tensor(16635.8379, device='cuda:0')\n",
      "5.0 python\n",
      "5.0 tensor(0.0003, device='cuda:0')\n",
      "5.0 tensor(21.7744, device='cuda:0')\n",
      "1.0 python\n",
      "1.0 tensor(0.0003, device='cuda:0')\n",
      "1.0 tensor(1.7601, device='cuda:0')\n",
      "150.0 overall\n",
      "150.0 tensor(0.0003, device='cuda:0')\n",
      "150.0 tensor(1948348.2500, device='cuda:0')\n",
      "=====================\n",
      "feat_num: 1878\n",
      "50.0 dry\n",
      "50.0 tensor(0.0002, device='cuda:0')\n",
      "50.0 tensor(636502.8750, device='cuda:0')\n",
      "10.0 python\n",
      "10.0 tensor(0.0003, device='cuda:0')\n",
      "10.0 tensor(88.9558, device='cuda:0')\n",
      "25.0 dry\n",
      "25.0 tensor(0.0002, device='cuda:0')\n",
      "25.0 tensor(35487.5898, device='cuda:0')\n",
      "100.0 php\n",
      "100.0 tensor(0.0002, device='cuda:0')\n",
      "100.0 tensor(1211910.2500, device='cuda:0')\n",
      "17.5 sand\n",
      "17.5 tensor(0.0002, device='cuda:0')\n",
      "17.5 tensor(3556.4705, device='cuda:0')\n",
      "5.0 python\n",
      "5.0 tensor(0.0004, device='cuda:0')\n",
      "5.0 tensor(6.5077, device='cuda:0')\n",
      "1.0 python\n",
      "1.0 tensor(0.0004, device='cuda:0')\n",
      "1.0 tensor(1.4104, device='cuda:0')\n",
      "150.0 spectrum\n",
      "150.0 tensor(0.0002, device='cuda:0')\n",
      "150.0 tensor(1100601., device='cuda:0')\n",
      "=====================\n",
      "feat_num: 316\n",
      "50.0 tape\n",
      "50.0 tensor(0.0002, device='cuda:0')\n",
      "50.0 tensor(2861998., device='cuda:0')\n",
      "10.0 python\n",
      "10.0 tensor(0.0002, device='cuda:0')\n",
      "10.0 tensor(167.4874, device='cuda:0')\n",
      "25.0 sand\n",
      "25.0 tensor(0.0002, device='cuda:0')\n",
      "25.0 tensor(686049.1875, device='cuda:0')\n",
      "100.0 ftp\n",
      "100.0 tensor(0.0002, device='cuda:0')\n",
      "100.0 tensor(949004.6875, device='cuda:0')\n",
      "17.5 sand\n",
      "17.5 tensor(0.0002, device='cuda:0')\n",
      "17.5 tensor(21358.5723, device='cuda:0')\n",
      "5.0 python\n",
      "5.0 tensor(0.0003, device='cuda:0')\n",
      "5.0 tensor(7.0213, device='cuda:0')\n",
      "1.0 python\n",
      "1.0 tensor(0.0003, device='cuda:0')\n",
      "1.0 tensor(1.3898, device='cuda:0')\n",
      "150.0 ftp\n",
      "150.0 tensor(0.0002, device='cuda:0')\n",
      "150.0 tensor(1710908.6250, device='cuda:0')\n",
      "=====================\n",
      "feat_num: 313\n",
      "50.0 set\n",
      "50.0 tensor(0.0002, device='cuda:0')\n",
      "50.0 tensor(443298.4062, device='cuda:0')\n",
      "10.0 python\n",
      "10.0 tensor(0.0002, device='cuda:0')\n",
      "10.0 tensor(356.7000, device='cuda:0')\n",
      "25.0 set\n",
      "25.0 tensor(0.0002, device='cuda:0')\n",
      "25.0 tensor(52725.5625, device='cuda:0')\n",
      "100.0 and\n",
      "100.0 tensor(0.0002, device='cuda:0')\n",
      "100.0 tensor(1989698.3750, device='cuda:0')\n",
      "17.5 sand\n",
      "17.5 tensor(0.0002, device='cuda:0')\n",
      "17.5 tensor(10758.8613, device='cuda:0')\n",
      "5.0 python\n",
      "5.0 tensor(0.0003, device='cuda:0')\n",
      "5.0 tensor(12.2403, device='cuda:0')\n",
      "1.0 python\n",
      "1.0 tensor(0.0003, device='cuda:0')\n",
      "1.0 tensor(1.4877, device='cuda:0')\n",
      "150.0 and\n",
      "150.0 tensor(0.0002, device='cuda:0')\n",
      "150.0 tensor(2716348., device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for feat_num in steering_strength_info[steering_strength][0].keys():\n",
    "    print(f\"=====================\\nfeat_num: {feat_num}\")\n",
    "    feat_num_concept_arr = []\n",
    "    feat_num_prob_arr = []\n",
    "    feat_num_ratio_arr = []\n",
    "    for key in steering_strength_info:\n",
    "        print(key, steering_strength_info[key][0][feat_num])\n",
    "        feat_num_concept_arr.append((key, steering_strength_info[key][0][feat_num]))\n",
    "        print(key, steering_strength_info[key][1][feat_num])\n",
    "        feat_num_prob_arr.append((key, steering_strength_info[key][1][feat_num].item()))\n",
    "        print(key, steering_strength_info[key][2][feat_num])\n",
    "        feat_num_ratio_arr.append((key, steering_strength_info[key][2][feat_num].item()))\n",
    "    i += 1\n",
    "    if i > 4:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([(1.0, 'python'),\n",
       "  (5.0, 'python'),\n",
       "  (10.0, 'python'),\n",
       "  (17.5, 'sand'),\n",
       "  (25.0, 'set'),\n",
       "  (50.0, 'set'),\n",
       "  (100.0, 'and'),\n",
       "  (150.0, 'and')],\n",
       " [(1.0, 0.00034924683859571815),\n",
       "  (5.0, 0.000306995352730155),\n",
       "  (10.0, 0.00023485180281568319),\n",
       "  (17.5, 0.00020870310254395008),\n",
       "  (25.0, 0.0002112043439410627),\n",
       "  (50.0, 0.00021079735597595572),\n",
       "  (100.0, 0.00020442830282263458),\n",
       "  (150.0, 0.00020695585408248007)],\n",
       " [(1.0, 1.4876837730407715),\n",
       "  (5.0, 12.240269660949707),\n",
       "  (10.0, 356.7000427246094),\n",
       "  (17.5, 10758.861328125),\n",
       "  (25.0, 52725.5625),\n",
       "  (50.0, 443298.40625),\n",
       "  (100.0, 1989698.375),\n",
       "  (150.0, 2716348.0)])"
      ]
     },
     "execution_count": 406,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted(feat_num_concept_arr),sorted(feat_num_prob_arr),sorted(feat_num_ratio_arr),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "x = [tup[0] for tup in sorted(feat_num_concept_arr)]\n",
    "y1 = [tup[1] for tup in sorted(feat_num_concept_arr)]\n",
    "y2 = [tup[1] for tup in sorted(feat_num_prob_arr)]\n",
    "# y3 = [tup[1] for tup in sorted(feat_num_ratio_arr)]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each line with different colors and markers\n",
    "# plt.plot(x, y1, 'bo-', label='Series 1')  # Blue line with circles\n",
    "plt.plot(np.array(x), y2, 'rs-', label='Series 2')  # Red line with squares\n",
    "# plt.plot(x, y3, 'gd-', label='Series 3')  # Green line with diamonds\n",
    "\n",
    "# Label each point for all three series\n",
    "for i in range(len(x)):\n",
    "#     # Labels for series 1\n",
    "#     plt.annotate(f'({x[i]}, {y1[i]})', \n",
    "#                 (x[i], y1[i]), \n",
    "#                 textcoords=\"offset points\", \n",
    "#                 xytext=(0,10),\n",
    "#                 ha='center')\n",
    "    \n",
    "    # Labels for series 2\n",
    "    plt.annotate(f'({y2[i]:01f}, {y1[i]})', \n",
    "                (x[i], y2[i]), \n",
    "                textcoords=\"offset points\", \n",
    "                xytext=(0,-15),\n",
    "                ha='center')\n",
    "    \n",
    "#     # Labels for series 3\n",
    "#     plt.annotate(f'({x[i]}, {y3[i]})', \n",
    "#                 (x[i], y3[i]), \n",
    "#                 textcoords=\"offset points\", \n",
    "#                 xytext=(0,10),\n",
    "#                 ha='center')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title('Line Chart with Labeled Points')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to prevent label overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Covariance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract from default, label, and print trends\n",
    "text_probs_altered.shape\n",
    "\n",
    "# selected_vocab = all_imagenet_class_names\n",
    "selected_vocab = larger_vocab\n",
    "\n",
    "cov_stuff_avgs = []\n",
    "\n",
    "# switch to datacomp eval??\n",
    "# we run this for each feature over all of imagenet eval and create average absolute/ratio\n",
    "# difference vectors\n",
    "per_feat_avg_vectors = []\n",
    "for j, text_probs_altered in enumerate(text_probs_altered_list):\n",
    "    print(f\"\\n\\nFor Feature {random_feat_idxs[j]}\")\n",
    "    print(f\"\\n\\nFor Feature {random_feat_idxs[j]}\")\n",
    "    logit_diff = text_probs_altered - text_probs_default\n",
    "    logit_ratio = text_probs_altered/text_probs_default\n",
    "    \n",
    "    vals, idxs = torch.topk(logit_diff,k=5)\n",
    "    vals_least, idxs_least = torch.topk(logit_diff,k=5,largest=False)\n",
    "    \n",
    "    ratios, ratios_idxs = torch.topk(logit_ratio,k=5)\n",
    "    ratios_least, ratios_idxs_least = torch.topk(logit_ratio,k=5,largest=False)\n",
    "    \n",
    "    feat_avg_vectors = []\n",
    "    for i in range(logit_diff.shape[0]):\n",
    "#         print(f\"\\nImage {i} ========================\\nMost Changed, by Absolute Diff\\n:{vals[i]}\")\n",
    "#         print(np.array(all_imagenet_class_names)[idxs.cpu()][i])\n",
    "#         print(vals_least[i])\n",
    "#         print(np.array(all_imagenet_class_names)[idxs_least.cpu()][i])\n",
    "        \n",
    "        print(\"\\nMost Changed, by Ratio:\")\n",
    "        print(ratios[i])\n",
    "        print(np.array(selected_vocab)[ratios_idxs.cpu()][i])\n",
    "#         print(ratios_least[i])\n",
    "#         print(np.array(selected_vocab)[ratios_idxs_least.cpu()][i])\n",
    "        \n",
    "        text = tokenizer(np.array(selected_vocab)[ratios_idxs.cpu()][i])\n",
    "#         text_least = tokenizer(np.array(selected_vocab)[ratios_idxs_least.cpu()][i])\n",
    "        text_features = og_model.encode_text(text.cuda())\n",
    "        cov_over_images.append(text_features)\n",
    "#         text_features_least = og_model.encode_text(text_least.cuda())\n",
    "        print(torch.tril(torch.cov(text_features), diagonal=-1))\n",
    "        print(torch.tril(torch.cov(text_features), diagonal=-1).sum()/10)\n",
    "#         cov_stuff = torch.tril(torch.cov(text_features), diagonal=-1).sum()/10\n",
    "#         cov_stuff_least = torch.tril(torch.cov(text_features_least), diagonal=-1).sum()/10\n",
    "    print(torch.tril(torch.cov(torch.cat(cov_over_images)), diagonal=-1).shape)\n",
    "    n = torch.tril(torch.cov(torch.cat(cov_over_images)), diagonal=-1).shape[0]\n",
    "    num_elements = (n**2)/2 - n\n",
    "    cov_stuff = torch.tril(torch.cov(torch.cat(cov_over_images)), diagonal=-1).sum()/num_elements\n",
    "    cov_stuff_avgs.append(cov_stuff)\n",
    "#         cov_stuff_avgs_least.append(cov_stuff_least)\n",
    "    if j > 10:\n",
    "        break\n",
    "print(torch.tensor(cov_stuff_avgs).mean())\n",
    "# print(torch.tensor(cov_stuff_avgs_least).mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_imgnet_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "feat_autolabels_default = defaultdict(Counter)\n",
    "for i in range(text_probs_default.shape[0]):\n",
    "    vals, idxs = torch.topk(text_probs_default[i],k=top_k_imgnet_labels)\n",
    "    print(i)\n",
    "    for k, idx in enumerate(idxs):\n",
    "        feat_autolabels_default[i][all_imagenet_class_names[idx]] += vals[k]\n",
    "        print(\"\\t\", all_imagenet_class_names[idx])\n",
    "feat_autolabels_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract from default, label, and print trends\n",
    "text_probs_altered.shape\n",
    "\n",
    "for text_probs_altered in text_probs_altered_list:\n",
    "    logit_diff = text_probs_altered - text_probs_default\n",
    "    print(logit_diff)\n",
    "    vals, idxs = torch.topk(logit_diff,k=5)\n",
    "    print(vals, np.array(all_imagenet_class_names[idxs])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imagenet_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "feat_autolabels_altered_list = []\n",
    "for text_probs_altered in text_probs_altered_list:\n",
    "    feat_autolabels_altered = defaultdict(Counter)\n",
    "    for i in range(text_probs_altered.shape[0]):\n",
    "        vals, idxs = torch.topk(text_probs_altered[i],k=top_k_imgnet_labels)\n",
    "#         print(i)\n",
    "        for k, idx in enumerate(idxs):\n",
    "            feat_autolabels_altered[i][all_imagenet_class_names[idx]] += vals[k]\n",
    "#             print(\"\\t\", all_imagenet_class_names[idx])\n",
    "    feat_autolabels_altered_list.append(feat_autolabels_altered)\n",
    "\n",
    "start_idx = 9\n",
    "end_idx = 10\n",
    "    \n",
    "h = 0\n",
    "for key in feat_autolabels_default:\n",
    "    print(f\"\\nfeat_autolabels_default img {key}:\\n {feat_autolabels_default[key]}\\n\")\n",
    "    h += 1\n",
    "    if h > end_idx:\n",
    "        break\n",
    "for i, f_a_a in enumerate(feat_autolabels_altered_list):\n",
    "    print(\"============= feature number \", i, \"====================\")\n",
    "    h = 0\n",
    "    for key in range(start_idx, end_idx):\n",
    "#         print(\"\\n\", key)\n",
    "#         for item in f_a_a[key]:\n",
    "#             print(\"\\t\", item, f_a_a[key][item].cpu().item())\n",
    "        print(f\"\\nf_a_a img {key}:\\n {f_a_a[key]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(text_probs_default.shape[0]):\n",
    "    vals, idxs = torch.topk(text_probs_default[i],k=1000)\n",
    "    print(i, ind_to_name[str(idxs[0].cpu().item())][1])\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "#     ax.xaxis.set_ticks((1000))\n",
    "#     ax.set_xticks(list(range(1000)), [ind_to_name[str(idxs[idx].cpu().item())][1] for idx in idxs])\n",
    "    plt.bar(idxs.cpu(), vals.cpu(), width=5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch_images[2].cpu().permute((1,2,0)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def get_heatmap(\n",
    "          image,\n",
    "          model,\n",
    "          sparse_autoencoder,\n",
    "          feature_id,\n",
    "): \n",
    "    image = image.to(cfg.device)\n",
    "    _, cache = model.run_with_cache(image.unsqueeze(0))\n",
    "\n",
    "    post_reshaped = einops.rearrange(cache[sparse_autoencoder.cfg.hook_point], \"batch seq d_mlp -> (batch seq) d_mlp\")\n",
    "    # Compute activations (not from a fwd pass, but explicitly, by taking only the feature we want)\n",
    "    # This code is copied from the first part of the 'forward' method of the AutoEncoder class\n",
    "    sae_in =  post_reshaped - sparse_autoencoder.b_dec # Remove decoder bias as per Anthropic\n",
    "    print(f\"sae_in.shape: {sae_in.shape}\")\n",
    "    acts = einops.einsum(\n",
    "            sae_in,\n",
    "            sparse_autoencoder.W_enc[:, feature_id],\n",
    "            \"x d_in, d_in -> x\",\n",
    "        )\n",
    "    return acts \n",
    "     \n",
    "def image_patch_heatmap(activation_values,image_size=224, pixel_num=14):\n",
    "    activation_values = activation_values.detach().cpu().numpy()\n",
    "    activation_values = activation_values[1:]\n",
    "    activation_values = activation_values.reshape(pixel_num, pixel_num)\n",
    "\n",
    "    # Create a heatmap overlay\n",
    "    heatmap = np.zeros((image_size, image_size))\n",
    "    patch_size = image_size // pixel_num\n",
    "\n",
    "    for i in range(pixel_num):\n",
    "        for j in range(pixel_num):\n",
    "            heatmap[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = activation_values[i, j]\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "grid_size = 1\n",
    "fig, axs = plt.subplots(int(np.ceil(len(images)/grid_size)), grid_size, figsize=(15, 15))\n",
    "name=  f\"Category: uhh,  Feature: {0}\"\n",
    "fig.suptitle(name)#, y=0.95)\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')\n",
    "complete_bid = []\n",
    "\n",
    "heatmap = get_heatmap(batch_images[2], model,sparse_autoencoder, 10000)\n",
    "heatmap = image_patch_heatmap(heatmap, pixel_num=224//cfg.patch_size)\n",
    "\n",
    "display = batch_images[2].cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "has_zero = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(display)\n",
    "plt.imshow(heatmap, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(display)\n",
    "plt.imshow(heatmap, alpha=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
