{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating your SAE\n",
    "\n",
    "Code based off Rob Graham's ([themachinefan](https://github.com/themachinefan)) SAE evaluation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/ViT-Prisma/src/vit_prisma/sae/evals'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_per_buffer (millions): 0.032\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 158691\n",
      "Total training images: 13000000\n",
      "Total wandb updates: 15869\n",
      "Expansion factor: 16\n",
      "n_tokens_per_feature_sampling_window (millions): 204.8\n",
      "n_tokens_per_dead_feature_window (millions): 1024.0\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 158 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Gradient clipping with max_norm=1.0\n",
      "Using SAE initialization method: encoder_transpose_decoder\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from vit_prisma.sae.config import VisionModelSAERunnerConfig\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EvalConfig(VisionModelSAERunnerConfig):\n",
    "    sae_path: str = '/workspace/sae_checkpoints/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-0.0001/n_images_2600058.pt'\n",
    "    model_name: str = \"open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "    model_type: str =  \"clip\"\n",
    "    patch_size: str = 32\n",
    "\n",
    "    dataset_path = \"/workspace\"\n",
    "    dataset_train_path: str = \"/workspace/ILSVRC/Data/CLS-LOC/train\"\n",
    "    dataset_val_path: str = \"/workspace/ILSVRC/Data/CLS-LOC/val\"\n",
    "\n",
    "    verbose: bool = True\n",
    "\n",
    "    device: bool = 'cuda'\n",
    "\n",
    "    eval_max: int = 50_000 # 50_000\n",
    "    batch_size: int = 32\n",
    "\n",
    "    # make the max image output folder a subfolder of the sae path\n",
    "\n",
    "\n",
    "    @property\n",
    "    def max_image_output_folder(self) -> str:\n",
    "        # Get the base directory of sae_checkpoints\n",
    "        sae_base_dir = os.path.dirname(os.path.dirname(self.sae_path))\n",
    "        \n",
    "        # Get the name of the original SAE checkpoint folder\n",
    "        sae_folder_name = os.path.basename(os.path.dirname(self.sae_path))\n",
    "        \n",
    "        # Create a new folder path in sae_checkpoints/images with the original name\n",
    "        output_folder = os.path.join(sae_base_dir, 'max_images', sae_folder_name)\n",
    "        output_folder = os.path.join(output_folder, f\"layer_{self.hook_point_layer}\") # Add layer number\n",
    "\n",
    "        \n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        return output_folder\n",
    "\n",
    "cfg = EvalConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7c86f0ea7c40>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "Official model name open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "Converting OpenCLIP weights\n",
      "model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "visual projection shape torch.Size([768, 512])\n",
      "Setting center_writing_weights to False for OpenCLIP\n",
      "Setting fold_ln to False for OpenCLIP\n",
      "Loaded pretrained model open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from vit_prisma.models.base_vit import HookedViT\n",
    "\n",
    "model_name = \"open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "model = HookedViT.from_pretrained(model_name, is_timm=False, is_clip=True).to(cfg.device)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import vit_prisma\n",
    "# importlib.reload(vit_prisma.dataloaders.imagenet_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation data length: 50000\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "import open_clip\n",
    "from vit_prisma.utils.data_utils.imagenet_utils import setup_imagenet_paths\n",
    "from vit_prisma.dataloaders.imagenet_dataset import get_imagenet_transforms_clip, ImageNetValidationDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPProcessor\n",
    "\n",
    "og_model_name = \"hf-hub:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "og_model, _, preproc = open_clip.create_model_and_transforms(og_model_name)\n",
    "processor = preproc\n",
    "\n",
    "size=224\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                     std=[0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "    \n",
    "imagenet_paths = setup_imagenet_paths(cfg.dataset_path)\n",
    "imagenet_paths[\"train\"] = \"/workspace/ILSVRC/Data/CLS-LOC/train\"\n",
    "imagenet_paths[\"val\"] = \"/workspace/ILSVRC/Data/CLS-LOC/val\"\n",
    "imagenet_paths[\"val_labels\"] = \"/workspace/LOC_val_solution.csv\"\n",
    "imagenet_paths[\"label_strings\"] = \"/workspace/LOC_synset_mapping.txt\"\n",
    "print()\n",
    "train_data = torchvision.datasets.ImageFolder(cfg.dataset_train_path, transform=data_transforms)\n",
    "val_data = ImageNetValidationDataset(cfg.dataset_val_path, \n",
    "                                imagenet_paths['label_strings'], \n",
    "                                imagenet_paths['val_labels'], \n",
    "                                data_transforms,\n",
    "                                return_index=True,\n",
    ")\n",
    "val_data_visualize = ImageNetValidationDataset(cfg.dataset_val_path, \n",
    "                                imagenet_paths['label_strings'], \n",
    "                                imagenet_paths['val_labels'],\n",
    "                                torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),]), return_index=True)\n",
    "\n",
    "print(f\"Validation data length: {len(val_data)}\") if cfg.verbose else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_prisma.sae.training.activations_store import VisionActivationsStore\n",
    "# import dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# activations_loader = VisionActivationsStore(cfg, model, train_data, eval_dataset=val_data)\n",
    "val_dataloader = DataLoader(val_data, batch_size=cfg.batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained SAE to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_activation_fn received: activation_fn=relu, kwargs={}\n",
      "n_tokens_per_buffer (millions): 0.032\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 158691\n",
      "Total training images: 13000000\n",
      "Total wandb updates: 1586\n",
      "Expansion factor: 64\n",
      "n_tokens_per_feature_sampling_window (millions): 204.8\n",
      "n_tokens_per_dead_feature_window (millions): 1024.0\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 158 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Gradient clipping with max_norm=1.0\n",
      "Using SAE initialization method: encoder_transpose_decoder\n",
      "get_activation_fn received: activation_fn=relu, kwargs={}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (hook_sae_in): HookPoint()\n",
       "  (hook_hidden_pre): HookPoint()\n",
       "  (hook_hidden_post): HookPoint()\n",
       "  (hook_sae_out): HookPoint()\n",
       "  (activation_fn): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vit_prisma.sae.sae import SparseAutoencoder\n",
    "sparse_autoencoder = SparseAutoencoder(cfg).load_from_pretrained(\"/workspace/sae_checkpoints/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-0.0001/n_images_2600058.pt\")\n",
    "sparse_autoencoder.to(cfg.device)\n",
    "sparse_autoencoder.eval()  # prevents error if we're expecting a dead neuron mask for who \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Labeling AutoInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_imagenet_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_prisma.dataloaders.imagenet_dataset import get_imagenet_index_to_name\n",
    "ind_to_name = get_imagenet_index_to_name()\n",
    "\n",
    "all_imagenet_class_names = []\n",
    "for i in range(len(ind_to_name)):\n",
    "    all_imagenet_class_names.append(ind_to_name[str(i)][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/sae_checkpoints/max_images/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-0.0001/layer_9'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.max_image_output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standard_replacement_hook_curry(feat_idx: int = 0, feat_activ: float = 1.0):\n",
    "    def standard_replacement_hook(activations: torch.Tensor, hook):\n",
    "        activations = sparse_autoencoder.forward(activations)[0].to(activations.dtype)\n",
    "        feature_acts = sparse_autoencoder.encode_standard(activations)\n",
    "\n",
    "        # in all batches and patches, set feature w idx idx to 0\n",
    "        print(f\"feature_acts[:,:,idx].shape: {feature_acts[:,:,feat_idx].shape}\")\n",
    "        print(f\"feat activ: {feature_acts[:,:,feat_idx]}\")\n",
    "        feature_acts[:,:,feat_idx] *= feat_activ\n",
    "        print(f\"feat activ: {feature_acts[:,:,feat_idx]}\")\n",
    "        print(f\"feat activ: {feature_acts.shape}\")\n",
    "        print(f\"feat activ: {feature_acts}\")\n",
    "        print(\"feature_acts[:,:,idx].sum(): (should be batch size x len seq x feat val)\", feature_acts[:,:,feat_idx].sum())\n",
    "        sae_out = sparse_autoencoder.hook_sae_out(\n",
    "            einops.einsum(\n",
    "                feature_acts,\n",
    "                sparse_autoencoder.W_dec,\n",
    "                \"... d_sae, d_sae d_in -> ... d_in\",\n",
    "            )\n",
    "            + sparse_autoencoder.b_dec\n",
    "        )\n",
    "        \n",
    "        print(f\"sae_out.shape: {sae_out.shape}\")\n",
    "        print(f\"sae_out: {sae_out}\")\n",
    "\n",
    "        # allows normalization. Possibly identity if no normalization\n",
    "        sae_out = sparse_autoencoder.run_time_activation_norm_fn_out(sae_out)\n",
    "        return sae_out\n",
    "    return standard_replacement_hook\n",
    "\n",
    "\n",
    "def steering_hook_fn(\n",
    "    activations, cfg, hook, sae, steering_indices, steering_strength=1.0, mean_ablation_values=None, include_error=False\n",
    "\n",
    "):\n",
    "    sae.to(activations.device)\n",
    "\n",
    "\n",
    "    sae_input = activations.clone()\n",
    "    sae_output, feature_activations, *data = sae(sae_input)\n",
    "    \n",
    "    steered_feature_activations = feature_activations.clone()\n",
    "    \n",
    "    steered_feature_activations[:, :, steering_indices] = steering_strength\n",
    "\n",
    "    steered_sae_out = einops.einsum(\n",
    "                steered_feature_activations,\n",
    "                sae.W_dec,\n",
    "                \"... d_sae, d_sae d_in -> ... d_in\",\n",
    "            ) + sae.b_dec\n",
    "\n",
    "    steered_sae_out = sae.run_time_activation_norm_fn_out(steered_sae_out)\n",
    "    \n",
    "    print(steered_sae_out.shape)\n",
    "    print(steered_sae_out.shape)\n",
    "    print(f\"steering norm: {(steered_sae_out - sae_output).norm()}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    if include_error:\n",
    "        error = sae_input - sae_output\n",
    "        print(f\"error.norm(): {error.norm()}\")\n",
    "        return steered_sae_out + error\n",
    "    return steered_sae_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_feat_idxs = np.random.randint(0, high=3000, size=(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given feature, set it high/low on maxim activ. imgs and high/low on non-activ images\n",
    "# hook SAE and replace desired feature with 0 or 1 \n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_feature_activations_set_feat(\n",
    "    images: torch.Tensor,\n",
    "    model: torch.nn.Module,\n",
    "    sparse_autoencoder: torch.nn.Module,\n",
    "    encoder_weights: torch.Tensor,\n",
    "    encoder_biases: torch.Tensor,\n",
    "    feature_ids: List[int],\n",
    "    feature_categories: List[str],\n",
    "    top_k: int = 10\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the highest activating tokens for given features in a batch of images.\n",
    "    \n",
    "    Args:\n",
    "        images: Input images\n",
    "        model: The main model\n",
    "        sparse_autoencoder: The sparse autoencoder\n",
    "        encoder_weights: Encoder weights for selected features\n",
    "        encoder_biases: Encoder biases for selected features\n",
    "        feature_ids: List of feature IDs to analyze\n",
    "        feature_categories: Categories of the features\n",
    "        top_k: Number of top activations to return per feature\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping feature IDs to tuples of (top_indices, top_values)\n",
    "    \"\"\"\n",
    "    _, cache = model.run_with_cache(images, names_filter=[sparse_autoencoder.cfg.hook_point])\n",
    "#     recons_image_embeddings_feat_altered = model.run_with_hooks(\n",
    "#         images,\n",
    "#         fwd_hooks=[(\"blocks.9.hook_mlp_out\", standard_replacement_hook)],\n",
    "#     )\n",
    "    recons_image_embeddings_feat_altered_list = []\n",
    "    for idx in np.array(range(sparse_autoencoder.W_dec.shape[0]))[random_feat_idxs]:\n",
    "        print(f\"Feature: {idx} ====================\")\n",
    "        \n",
    "        steering_hook = partial(\n",
    "            steering_hook_fn,\n",
    "            cfg=cfg,\n",
    "            sae=sparse_autoencoder,\n",
    "            steering_indices=[idx],\n",
    "            steering_strength=10.0,\n",
    "            mean_ablation_values = [1.0],\n",
    "            include_error=True,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        recons_image_embeddings_feat_altered = model.run_with_hooks(\n",
    "            images,\n",
    "#             fwd_hooks=[(\"blocks.9.hook_mlp_out\", standard_replacement_hook_curry(idx, 10.0))],\n",
    "            fwd_hooks=[(\"blocks.9.hook_mlp_out\", steering_hook)],\n",
    "        )\n",
    "        recons_image_embeddings_feat_altered_list.append(recons_image_embeddings_feat_altered)\n",
    "\n",
    "    \n",
    "    # output is in clip embedding space\n",
    "    recons_image_embeddings_default = model.run_with_hooks(\n",
    "        images,\n",
    "        fwd_hooks=[(\"blocks.9.hook_mlp_out\", lambda x, hook: x)],\n",
    "    )\n",
    "    \n",
    "    print(f\"recons_image_embeddings_default: {recons_image_embeddings_default}\")\n",
    "    print(f\"recons_image_embeddings_default.shape: {recons_image_embeddings_default.shape}\")\n",
    "    print(f\"recons_image_embeddings_default: {recons_image_embeddings_default.shape}\")\n",
    "\n",
    "    print(f\"recons_image_embeddings_feat_altered: {recons_image_embeddings_feat_altered}\")\n",
    "    print(f\"recons_image_embeddings_feat_altered.shape: {recons_image_embeddings_feat_altered.shape}\")\n",
    "\n",
    "    return recons_image_embeddings_feat_altered_list, recons_image_embeddings_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                        | 0/1562 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1365 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 398.1505432128906\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 998 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 399.4733581542969\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 789 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 399.6695251464844\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 1043 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 399.7071838378906\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 2263 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 399.7817077636719\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 1865 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 399.37738037109375\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 352 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 398.8123474121094\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 1008 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 399.85064697265625\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 2352 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 399.73895263671875\n",
      "error.norm(): 3214.9658203125\n",
      "Feature: 2289 ====================\n",
      "torch.Size([32, 50, 768])\n",
      "torch.Size([32, 50, 768])\n",
      "steering norm: 399.849609375\n",
      "error.norm(): 3214.9658203125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                                                                                                                                        | 0/1562 [00:01<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recons_image_embeddings_default: tensor([[ 0.0352,  0.0083, -0.0740,  ..., -0.0311,  0.0275,  0.0019],\n",
      "        [-0.0101, -0.0539, -0.0622,  ...,  0.0199, -0.0555, -0.0743],\n",
      "        [-0.0206,  0.0059, -0.0366,  ..., -0.0307,  0.0756, -0.0016],\n",
      "        ...,\n",
      "        [ 0.0099, -0.0045, -0.0059,  ..., -0.0521,  0.0647, -0.0225],\n",
      "        [-0.0422,  0.0518, -0.0482,  ...,  0.0098,  0.0418,  0.0290],\n",
      "        [-0.0411, -0.0590,  0.0014,  ..., -0.0432, -0.0089, -0.0449]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_default.shape: torch.Size([32, 512])\n",
      "recons_image_embeddings_default: torch.Size([32, 512])\n",
      "recons_image_embeddings_feat_altered: tensor([[ 0.0258, -0.0183, -0.1057,  ..., -0.0264,  0.0310,  0.0354],\n",
      "        [-0.0227, -0.0636, -0.1150,  ...,  0.0230, -0.0531, -0.0051],\n",
      "        [-0.0162, -0.0186, -0.0910,  ..., -0.0246,  0.0440,  0.0165],\n",
      "        ...,\n",
      "        [ 0.0068, -0.0125, -0.0594,  ..., -0.0320,  0.0226,  0.0075],\n",
      "        [-0.0557,  0.0367, -0.0776,  ...,  0.0264, -0.0072,  0.0243],\n",
      "        [-0.0255, -0.0497, -0.0436,  ..., -0.0319, -0.0162, -0.0117]],\n",
      "       device='cuda:0')\n",
      "recons_image_embeddings_feat_altered.shape: torch.Size([32, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "max_samples = cfg.eval_max\n",
    "\n",
    "# top_activations = {i: (None, None) for i in interesting_features_indices}\n",
    "encoder_biases = sparse_autoencoder.b_enc#[interesting_features_indices]\n",
    "encoder_weights = sparse_autoencoder.W_enc#[:, interesting_features_indices]\n",
    "\n",
    "top_k=10\n",
    "processed_samples = 0\n",
    "for batch_images, _, batch_indices in tqdm(val_dataloader, total=max_samples // cfg.batch_size):\n",
    "    batch_images = batch_images.to(cfg.device)\n",
    "    batch_indices = batch_indices.to(cfg.device)\n",
    "    batch_size = batch_images.shape[0]\n",
    "\n",
    "    altered_embeds_list, default_embeds = compute_feature_activations_set_feat(\n",
    "        batch_images, model, sparse_autoencoder, encoder_weights, encoder_biases,\n",
    "        None, None, top_k\n",
    "    )\n",
    "    # either label embeds or optimize to maximal token in text transformer embedding face\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, torch.Size([32, 512]), torch.Size([32, 512]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(altered_embeds_list), altered_embeds_list[0].shape, default_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CLIP(\n",
       "  (visual): VisionTransformer(\n",
       "    (conv1): Conv2d(3, 768, kernel_size=(32, 32), stride=(32, 32), bias=False)\n",
       "    (patch_dropout): Identity()\n",
       "    (ln_pre): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "    (transformer): Transformer(\n",
       "      (resblocks): ModuleList(\n",
       "        (0-11): 12 x ResidualAttentionBlock(\n",
       "          (ln_1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (attn): MultiheadAttention(\n",
       "            (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_1): Identity()\n",
       "          (ln_2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "          (mlp): Sequential(\n",
       "            (c_fc): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (gelu): GELU(approximate='none')\n",
       "            (c_proj): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          )\n",
       "          (ls_2): Identity()\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln_post): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
       "  )\n",
       "  (transformer): Transformer(\n",
       "    (resblocks): ModuleList(\n",
       "      (0-11): 12 x ResidualAttentionBlock(\n",
       "        (ln_1): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (attn): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_1): Identity()\n",
       "        (ln_2): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       "        (mlp): Sequential(\n",
       "          (c_fc): Linear(in_features=512, out_features=2048, bias=True)\n",
       "          (gelu): GELU(approximate='none')\n",
       "          (c_proj): Linear(in_features=2048, out_features=512, bias=True)\n",
       "        )\n",
       "        (ls_2): Identity()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (token_embedding): Embedding(49408, 512)\n",
       "  (ln_final): LayerNorm((512,), eps=1e-05, elementwise_affine=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "og_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# with open(\"/workspace/clip_dissect_raw.txt\", \"r\") as f:\n",
    "#     larger_vocab = [line[:-1] for line in f.readlines()][:5000]\n",
    "\n",
    "with open(\"/workspace/better_img_desc.txt\", \"r\") as f:\n",
    "    larger_vocab = [line[:-1] for line in f.readlines()][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label probs altered: torch.Size([32, 3498])\n",
      "Label probs default: torch.Size([32, 3498])\n"
     ]
    }
   ],
   "source": [
    "# use clip vocab here and compare embeds\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "text = tokenizer(larger_vocab)\n",
    "text_features = og_model.encode_text(text.cuda())\n",
    "text_features_normed = text_features/text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "text_probs_altered_list = []\n",
    "# can probs make this one tensor operation\n",
    "for altered_embeds in altered_embeds_list:\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        # might want to still normalize\n",
    "        \n",
    "        # already normalized\n",
    "        # altered_embeds /= altered_embeds.norm(dim=-1, keepdim=True)\n",
    "\n",
    "        text_probs_altered = (100.0 * altered_embeds @ text_features_normed.T).softmax(dim=-1)\n",
    "        text_probs_altered_list.append(text_probs_altered)\n",
    "    # default_embds_norm = default_embeds.norm(dim=-1, keepdim=True)\n",
    "    text_probs_default = (100.0 * default_embeds @ text_features_normed.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs altered:\", text_probs_altered.shape)  # prints: [[1., 0., 0.]]\n",
    "print(\"Label probs default:\", text_probs_default.shape)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3.1215e-05, 4.6859e-05, 2.4939e-04,  ..., 2.0385e-07, 3.8165e-06,\n",
       "         6.1948e-06],\n",
       "        [2.3486e-08, 2.3486e-08, 6.2493e-07,  ..., 6.2362e-08, 3.1358e-08,\n",
       "         1.2280e-08],\n",
       "        [4.1942e-05, 1.4270e-05, 1.1160e-03,  ..., 1.9576e-07, 8.2938e-04,\n",
       "         1.3068e-06],\n",
       "        ...,\n",
       "        [1.0309e-06, 8.6135e-07, 2.0184e-06,  ..., 1.6126e-05, 9.3134e-07,\n",
       "         1.5843e-06],\n",
       "        [2.5853e-06, 8.9344e-07, 1.8190e-06,  ..., 2.9981e-08, 4.0991e-06,\n",
       "         5.2523e-07],\n",
       "        [1.0282e-05, 4.3200e-06, 2.8777e-06,  ..., 1.6811e-09, 1.2670e-06,\n",
       "         1.4470e-06]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_probs_altered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "For Feature 1365\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([96.3021, 67.0273, 48.9559, 48.4807, 44.3875], device='cuda:0')\n",
      "['An image with dogs' 'misty forest path' 'Cultural tapestry' 'A dog'\n",
      " 'Coastal lighthouse beacon']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1369, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1840, 0.1215, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2826, 0.1437, 0.1743, 0.0000, 0.0000],\n",
      "        [0.1770, 0.1379, 0.1638, 0.1800, 0.0000]], device='cuda:0')\n",
      "tensor(0.1702, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([2877.3518, 1357.8948, 1281.5944,  936.5512,  832.3539],\n",
      "       device='cuda:0')\n",
      "['A dog' 'Snapshot of a marsupial' 'A paw'\n",
      " 'An image of a Veterinary Technician' 'An image with dogs']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2060, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2747, 0.1937, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2239, 0.1837, 0.2003, 0.0000, 0.0000],\n",
      "        [0.2826, 0.1979, 0.2310, 0.2265, 0.0000]], device='cuda:0')\n",
      "tensor(0.2220, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([32.1837, 21.8832, 17.6921, 17.2837, 14.6114], device='cuda:0')\n",
      "['A seal' 'Image with a donkey' 'Mystical fog'\n",
      " 'Image showing prairie grouse' 'Image with a penguin']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2023, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1429, 0.1294, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1789, 0.1600, 0.1146, 0.0000, 0.0000],\n",
      "        [0.2559, 0.2271, 0.1423, 0.1905, 0.0000]], device='cuda:0')\n",
      "tensor(0.1744, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([251.4317, 182.7909, 125.5830,  97.3339,  96.2746], device='cuda:0')\n",
      "['Image with graffiti-inspired design' 'A skirt'\n",
      " 'Striking fashion silhouette' 'Image with shattered glass sculptures'\n",
      " 'Image with shattered glass art installation']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1914, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2317, 0.2206, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2197, 0.1649, 0.2010, 0.0000, 0.0000],\n",
      "        [0.2292, 0.1821, 0.2054, 0.3017, 0.0000]], device='cuda:0')\n",
      "tensor(0.2148, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([127.4797,  36.9992,  33.1968,  32.4928,  23.3912], device='cuda:0')\n",
      "['An image with dogs' 'Image captured in the Peruvian Andes'\n",
      " 'an image of portsmouth' 'Artwork featuring barcode arrangement'\n",
      " 'A family photo']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2175, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1946, 0.2229, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1994, 0.2039, 0.1779, 0.0000, 0.0000],\n",
      "        [0.2419, 0.2118, 0.1980, 0.1946, 0.0000]], device='cuda:0')\n",
      "tensor(0.2062, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([996.2648, 127.0853, 121.6734, 110.0696, 101.9449], device='cuda:0')\n",
      "['misty forest path' 'A bracelet' 'Sunlit meadow path' 'A necklace'\n",
      " 'calming seascape']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1365, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1871, 0.1425, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1468, 0.3209, 0.1571, 0.0000, 0.0000],\n",
      "        [0.1634, 0.1955, 0.1583, 0.2086, 0.0000]], device='cuda:0')\n",
      "tensor(0.1817, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([554.2471, 496.7434, 325.7219, 305.3729, 268.0125], device='cuda:0')\n",
      "['Mystical fog' 'Soft pastel hues' 'Ethereal mist' 'Soft pastel tones'\n",
      " 'Ethereal tones']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1631, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2111, 0.1681, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1727, 0.2798, 0.1714, 0.0000, 0.0000],\n",
      "        [0.1776, 0.1893, 0.2153, 0.2051, 0.0000]], device='cuda:0')\n",
      "tensor(0.1954, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([31.4235, 21.6829, 21.2510, 20.5820, 19.0479], device='cuda:0')\n",
      "['Photograph with abstract geometric overlay' 'A bracelet'\n",
      " 'An image with dogs' 'A stick' 'A rug']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2025, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2005, 0.2239, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1677, 0.2327, 0.2021, 0.0000, 0.0000],\n",
      "        [0.2103, 0.2584, 0.2306, 0.2321, 0.0000]], device='cuda:0')\n",
      "tensor(0.2161, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 998\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([157.4010, 151.5176, 146.3900, 144.2822, 133.2788], device='cuda:0')\n",
      "['Illustration of a mythical creature'\n",
      " 'Caricature of an iconic playwright' 'Caricature of an iconic composer'\n",
      " 'An image of a Screenwriter' 'An image of a Archaeologist']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2424, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2371, 0.2845, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2352, 0.2166, 0.2145, 0.0000, 0.0000],\n",
      "        [0.2386, 0.2039, 0.2019, 0.2461, 0.0000]], device='cuda:0')\n",
      "tensor(0.2321, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([876.5818, 827.6674, 791.0773, 765.2088, 743.4205], device='cuda:0')\n",
      "['Illustration of a hidden enchanted castle'\n",
      " 'Illustration of a underwater scene' 'Image of a boat'\n",
      " 'Illustration of a hidden celestial portal' 'Tranquil lakeside pier']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2529, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2198, 0.2633, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2471, 0.2488, 0.2306, 0.0000, 0.0000],\n",
      "        [0.1634, 0.1915, 0.2273, 0.1638, 0.0000]], device='cuda:0')\n",
      "tensor(0.2209, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([100.3165,  30.1000,  24.7957,  23.1854,  23.0758], device='cuda:0')\n",
      "['A snail' 'Illustration of a hidden fantasy sanctuary'\n",
      " 'Illustration of a hidden enchanted castle'\n",
      " 'Illustration of a hidden ethereal palace'\n",
      " 'Illustration of a hidden fantasy castle']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2079, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2042, 0.2851, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2015, 0.2783, 0.2746, 0.0000, 0.0000],\n",
      "        [0.2133, 0.3028, 0.3105, 0.2866, 0.0000]], device='cuda:0')\n",
      "tensor(0.2565, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([34.4063, 30.6982, 29.5131, 25.5860, 24.1429], device='cuda:0')\n",
      "['Detailed illustration of a celestial body' 'intricate gemstone display'\n",
      " 'Illustration of a utopian society'\n",
      " 'Illustration of an astronomical phenomenon'\n",
      " 'Photo of a fireworks display']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1894, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2205, 0.1810, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2599, 0.1972, 0.2553, 0.0000, 0.0000],\n",
      "        [0.2389, 0.2229, 0.2330, 0.2697, 0.0000]], device='cuda:0')\n",
      "tensor(0.2268, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([501.8492, 254.3762, 223.9122, 154.8725, 150.8895], device='cuda:0')\n",
      "['An image of a Swimmer' 'Illustration of a mythical creature'\n",
      " 'Image of an airplane' 'Illustration of an astronomical phenomenon'\n",
      " 'An image of a Veterinary Technician']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2718, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2944, 0.2795, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2349, 0.2733, 0.2538, 0.0000, 0.0000],\n",
      "        [0.2448, 0.2248, 0.2392, 0.2016, 0.0000]], device='cuda:0')\n",
      "tensor(0.2518, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([127.8399,  94.1514,  93.3852,  92.3436,  82.7661], device='cuda:0')\n",
      "['Dynamic and high-energy music festival' 'weathered religious icon'\n",
      " 'Time-honored craftsmanship' 'Illustration of an astronomical phenomenon'\n",
      " 'Caricature of a celebrated composer']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1706, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1932, 0.1614, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2269, 0.1813, 0.1861, 0.0000, 0.0000],\n",
      "        [0.1986, 0.1858, 0.1611, 0.2035, 0.0000]], device='cuda:0')\n",
      "tensor(0.1869, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([303.5338, 190.0781, 129.8474, 119.7229, 107.4270], device='cuda:0')\n",
      "['Impressionist portrait painting' 'Illustration of a utopian society'\n",
      " 'Illustration of a historical event' 'Time-honored craftsmanship'\n",
      " 'Impressionist landscape painting']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1769, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1800, 0.2507, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1555, 0.1665, 0.1918, 0.0000, 0.0000],\n",
      "        [0.2919, 0.2096, 0.2105, 0.1773, 0.0000]], device='cuda:0')\n",
      "tensor(0.2011, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([267.2003, 181.1325, 138.1267, 133.8992, 115.5603], device='cuda:0')\n",
      "['An image of a Chiropractor' 'Antique religious icon'\n",
      " 'Illustration of a hidden enchanted castle' 'weathered religious icon'\n",
      " 'Photo featuring a lively sports match']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1878, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1723, 0.2076, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1586, 0.2938, 0.1846, 0.0000, 0.0000],\n",
      "        [0.1947, 0.1996, 0.1854, 0.1621, 0.0000]], device='cuda:0')\n",
      "tensor(0.1947, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 789\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([1603.5063, 1304.1909, 1189.8351,  880.7194,  706.1307],\n",
      "       device='cuda:0')\n",
      "['Cubist still life painting' 'Abstract oil painting'\n",
      " 'Exquisite fine art painting' 'Futuristic digital artwork' 'A painting']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2895, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2463, 0.3543, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2368, 0.3297, 0.3040, 0.0000, 0.0000],\n",
      "        [0.2454, 0.3502, 0.3377, 0.3029, 0.0000]], device='cuda:0')\n",
      "tensor(0.2997, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([1369.4069,  418.9843,  405.4342,  370.6824,  313.7024],\n",
      "       device='cuda:0')\n",
      "['An image of one subject'\n",
      " 'Detailed illustration of an advanced space exploration' 'A floral motif'\n",
      " 'An image of two subjects' 'Detailed illustration of a celestial body']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1544, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1885, 0.1960, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2787, 0.1510, 0.1820, 0.0000, 0.0000],\n",
      "        [0.1558, 0.2529, 0.2118, 0.1513, 0.0000]], device='cuda:0')\n",
      "tensor(0.1922, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([23.2142, 17.5139, 15.1041, 14.0988, 13.0495], device='cuda:0')\n",
      "['Aerial view of a vineyard' 'Aerial view of a farmland'\n",
      " 'Meticulously arranged flowerbed' 'An image of one subject'\n",
      " 'Aerial view of a desert oasis']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2724, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1884, 0.1871, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1589, 0.1584, 0.1469, 0.0000, 0.0000],\n",
      "        [0.2291, 0.2413, 0.1675, 0.1445, 0.0000]], device='cuda:0')\n",
      "tensor(0.1895, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([60.4316, 44.8986, 32.6618, 28.6510, 26.5779], device='cuda:0')\n",
      "['Image with holographic retro vaporwave aesthetics'\n",
      " 'An image of one subject' 'Artwork featuring digital glitch patterns'\n",
      " 'Image with shattered mirror effect'\n",
      " 'Image with shattered pottery fragments']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1076, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2184, 0.1660, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1682, 0.1428, 0.2281, 0.0000, 0.0000],\n",
      "        [0.1341, 0.1533, 0.1985, 0.2240, 0.0000]], device='cuda:0')\n",
      "tensor(0.1741, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([570.2523, 402.1930, 322.9167, 280.7165, 254.4939], device='cuda:0')\n",
      "['Artwork with retro pixel patterns'\n",
      " 'Image with holographic retro vaporwave aesthetics'\n",
      " 'Artwork featuring Morse code typography'\n",
      " 'Artwork featuring crossword grid pattern'\n",
      " 'Image with holographic retro synthwave aesthetics']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1924, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2018, 0.1404, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2452, 0.1553, 0.2176, 0.0000, 0.0000],\n",
      "        [0.2192, 0.2739, 0.1659, 0.1775, 0.0000]], device='cuda:0')\n",
      "tensor(0.1989, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([515.9025, 286.9026, 206.0079, 190.1076, 180.5087], device='cuda:0')\n",
      "['Cubist still life painting' 'Caricature of a celebrated composer'\n",
      " 'Quiet grazing cattle' 'Portrait of a person'\n",
      " 'Caricature of a mythological figure']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1963, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1478, 0.1388, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1841, 0.2133, 0.1526, 0.0000, 0.0000],\n",
      "        [0.2149, 0.2779, 0.1710, 0.2552, 0.0000]], device='cuda:0')\n",
      "tensor(0.1952, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([5290.4370, 3020.5986, 1993.6818, 1443.3049, 1378.9434],\n",
      "       device='cuda:0')\n",
      "['Cubist still life painting' 'Illustration of a utopian society'\n",
      " 'Image with holographic retro vaporwave aesthetics'\n",
      " 'Image with holographic retro synthwave aesthetics'\n",
      " 'Artwork featuring retro TV test patterns']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1825, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1437, 0.1640, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1631, 0.1821, 0.2739, 0.0000, 0.0000],\n",
      "        [0.1902, 0.1957, 0.1750, 0.1998, 0.0000]], device='cuda:0')\n",
      "tensor(0.1870, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([104.3882,  72.8328,  64.1682,  46.1165,  32.8737], device='cuda:0')\n",
      "['An image of one subject'\n",
      " 'Image with holographic retro vaporwave aesthetics'\n",
      " 'An image of two subjects' 'Photograph with abstract geometric overlay'\n",
      " 'A digital glitch design']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1076, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2787, 0.1153, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1824, 0.1719, 0.1786, 0.0000, 0.0000],\n",
      "        [0.1693, 0.2115, 0.1632, 0.2463, 0.0000]], device='cuda:0')\n",
      "tensor(0.1825, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 1043\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([243.9124, 189.9317, 141.5040, 135.7613, 129.1366], device='cuda:0')\n",
      "['weathered religious icon' 'Miniature diorama photography'\n",
      " 'An image with poultry' 'Antique religious icon'\n",
      " 'Aerial view of an archaeological site']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1749, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1752, 0.1851, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2938, 0.2138, 0.2073, 0.0000, 0.0000],\n",
      "        [0.1709, 0.1689, 0.1891, 0.1995, 0.0000]], device='cuda:0')\n",
      "tensor(0.1979, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([2221.2097, 1890.0846, 1885.8785, 1790.5480, 1671.8573],\n",
      "       device='cuda:0')\n",
      "['Picture taken in Galápagos Islands' 'Picture taken in Amazon Rainforest'\n",
      " 'Photo taken in Galápagos Islands' 'A lake' 'an image of samoa']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2515, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3212, 0.2449, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1670, 0.2075, 0.1624, 0.0000, 0.0000],\n",
      "        [0.1177, 0.1300, 0.1196, 0.0888, 0.0000]], device='cuda:0')\n",
      "tensor(0.1811, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([52.0369, 39.7116, 32.1240, 29.7829, 28.8529], device='cuda:0')\n",
      "['Image with a volcanic eruption' 'Image with a donkey' 'Cultural mosaic'\n",
      " 'Photo taken in Okavango Delta' 'Cultural diversity']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2011, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1883, 0.1635, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1952, 0.1599, 0.1755, 0.0000, 0.0000],\n",
      "        [0.1830, 0.1555, 0.2366, 0.1791, 0.0000]], device='cuda:0')\n",
      "tensor(0.1838, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([12.6647,  9.0087,  8.6040,  7.3705,  5.7731], device='cuda:0')\n",
      "['An image of a Software Developer' 'powerful athletic competition'\n",
      " 'Whirling carousel at a fair' 'Inviting café environment'\n",
      " 'Image with shattered pottery fragments']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2212, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1849, 0.1591, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2570, 0.2101, 0.1914, 0.0000, 0.0000],\n",
      "        [0.2000, 0.1636, 0.1457, 0.1856, 0.0000]], device='cuda:0')\n",
      "tensor(0.1918, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([139.1767,  98.0600,  91.1687,  64.4783,  58.8043], device='cuda:0')\n",
      "['An image of a Veterinary Technician'\n",
      " 'Picture with multiple domesticated animals' 'An image of a Hair Stylist'\n",
      " 'An illustration of an animal' 'An image of a Veterinarian']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1913, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2617, 0.1918, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2516, 0.2434, 0.2596, 0.0000, 0.0000],\n",
      "        [0.3180, 0.2088, 0.2721, 0.2769, 0.0000]], device='cuda:0')\n",
      "tensor(0.2475, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([325.2456, 257.2654, 221.1493, 172.8353, 171.3460], device='cuda:0')\n",
      "['Picture with boats' 'Image of a boat' 'Lively coastal fishing port'\n",
      " 'An image of a lake' 'An image of a Marine Biologist']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2829, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2077, 0.2468, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2203, 0.2996, 0.2145, 0.0000, 0.0000],\n",
      "        [0.2140, 0.2870, 0.2279, 0.2631, 0.0000]], device='cuda:0')\n",
      "tensor(0.2464, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([898.2342, 855.4041, 790.0458, 777.4547, 724.3813], device='cuda:0')\n",
      "['Image of a boat' 'Picture of a beach' 'Cultural diversity'\n",
      " 'An image of a Marine Biologist'\n",
      " 'Detailed illustration of a body of water']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2931, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2154, 0.2021, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2870, 0.2543, 0.2139, 0.0000, 0.0000],\n",
      "        [0.2639, 0.2479, 0.1771, 0.2302, 0.0000]], device='cuda:0')\n",
      "tensor(0.2385, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([36.1094, 35.1269, 27.2173, 26.8081, 23.9948], device='cuda:0')\n",
      "['Image with Native American motifs' 'Energetic music festival crowd'\n",
      " 'Image with indigenous tribal motifs'\n",
      " 'Photo featuring a vibrant cultural exhibition' 'A picture of Samoa']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2093, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3041, 0.2339, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2298, 0.2197, 0.2584, 0.0000, 0.0000],\n",
      "        [0.1621, 0.1257, 0.1782, 0.1554, 0.0000]], device='cuda:0')\n",
      "tensor(0.2076, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 2263\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([6079.9736, 5630.4932, 1335.1344, 1333.8807, 1064.5717],\n",
      "       device='cuda:0')\n",
      "['Nostalgic streetscapes' 'Nostalgic city scenes' 'Nostalgic landscapes'\n",
      " 'Cultural juxtapositions' 'Gritty urban landscapes']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2824, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2690, 0.2617, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2190, 0.2005, 0.2063, 0.0000, 0.0000],\n",
      "        [0.2758, 0.2469, 0.2455, 0.2184, 0.0000]], device='cuda:0')\n",
      "tensor(0.2426, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([6429.7593, 6133.7153, 6075.9146, 5238.0547, 4724.4512],\n",
      "       device='cuda:0')\n",
      "['Nostalgic city scenes' 'Gritty urban landscapes'\n",
      " 'Nostalgic streetscapes' 'Nostalgic city lights' 'Nostalgic landscapes']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2469, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2824, 0.2758, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2475, 0.2178, 0.2399, 0.0000, 0.0000],\n",
      "        [0.2617, 0.2455, 0.2690, 0.2410, 0.0000]], device='cuda:0')\n",
      "tensor(0.2528, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([427.6638, 331.9652, 327.0630, 273.5670, 253.0530], device='cuda:0')\n",
      "['Surreal artwork with floating elements' 'weathered religious icon'\n",
      " 'Antique religious icon' 'Image with a penguin' 'Emotional journey']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1999, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2291, 0.2938, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2111, 0.1773, 0.2102, 0.0000, 0.0000],\n",
      "        [0.2029, 0.1645, 0.1883, 0.1884, 0.0000]], device='cuda:0')\n",
      "tensor(0.2066, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([2813.7800, 1410.8691, 1222.0190,  952.3504,  897.6380],\n",
      "       device='cuda:0')\n",
      "['Weathered cityscapes' 'atmospheric cityscape'\n",
      " 'Street art-inspired design' 'Nostalgic streetscapes'\n",
      " 'Image with shattered glass sculptures']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2236, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2333, 0.2059, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2481, 0.2305, 0.2702, 0.0000, 0.0000],\n",
      "        [0.1913, 0.1589, 0.2318, 0.1927, 0.0000]], device='cuda:0')\n",
      "tensor(0.2186, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([392.0725, 295.0298, 235.1178, 191.1432, 188.1752], device='cuda:0')\n",
      "['Skyscrapers touching clouds' 'Retro-style poster design'\n",
      " 'Artwork featuring zebra stripe motifs' 'Snow-covered mountain peaks'\n",
      " 'Gritty urban landscapes']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1445, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1328, 0.2096, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1719, 0.1689, 0.1589, 0.0000, 0.0000],\n",
      "        [0.1693, 0.2266, 0.1781, 0.1705, 0.0000]], device='cuda:0')\n",
      "tensor(0.1731, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([15650.4092, 12327.7119,  9464.2148,  4648.5239,  4191.9976],\n",
      "       device='cuda:0')\n",
      "['Nostalgic city lights' 'Nostalgic city scenes' 'Nostalgic landscapes'\n",
      " 'Nostalgic scenes' 'Nostalgic streetscapes']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2475, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2410, 0.2617, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2243, 0.2715, 0.2641, 0.0000, 0.0000],\n",
      "        [0.2399, 0.2824, 0.2690, 0.2490, 0.0000]], device='cuda:0')\n",
      "tensor(0.2550, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([2824.9031, 2151.6814, 1780.5771, 1438.3735, 1395.7637],\n",
      "       device='cuda:0')\n",
      "['Nostalgic landscapes' 'Image with holographic retro arcade aesthetics'\n",
      " 'Gritty urban landscapes' 'weathered religious icon'\n",
      " 'Image with holographic retro gaming aesthetics']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1914, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2455, 0.1814, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1678, 0.1418, 0.1843, 0.0000, 0.0000],\n",
      "        [0.1989, 0.2883, 0.1892, 0.1480, 0.0000]], device='cuda:0')\n",
      "tensor(0.1937, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([1093.8634,  491.6146,  450.5883,  314.1071,  243.1618],\n",
      "       device='cuda:0')\n",
      "['Lively amusement park scene' 'Surreal artwork with floating elements'\n",
      " 'weathered religious icon' 'Playful cityscapes' 'fleeting soap bubble']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2062, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1625, 0.1999, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2070, 0.2460, 0.1614, 0.0000, 0.0000],\n",
      "        [0.1820, 0.2228, 0.1674, 0.1949, 0.0000]], device='cuda:0')\n",
      "tensor(0.1950, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 1865\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([630.6267, 335.0537, 194.8255, 176.7459, 159.8192], device='cuda:0')\n",
      "['Image with a hurricane or typhoon'\n",
      " 'Detailed illustration of a geological formation'\n",
      " 'Coastal lighthouse beacon' 'Majestic ancient structure'\n",
      " 'Dramatic volcanic eruption']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1818, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1692, 0.1756, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1561, 0.2053, 0.1758, 0.0000, 0.0000],\n",
      "        [0.2041, 0.2256, 0.1932, 0.2093, 0.0000]], device='cuda:0')\n",
      "tensor(0.1896, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([782.3193, 637.1429, 561.7076, 418.8149, 340.1487], device='cuda:0')\n",
      "['Detailed illustration of a geological formation'\n",
      " 'Detailed illustration of a futuristic quantum realm'\n",
      " 'Detailed illustration of a piece of clothing'\n",
      " 'Detailed illustration of a futuristic medical breakthrough'\n",
      " 'Image with a volcanic lava flow']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1798, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2604, 0.1597, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2251, 0.1885, 0.2283, 0.0000, 0.0000],\n",
      "        [0.2444, 0.1638, 0.2194, 0.1950, 0.0000]], device='cuda:0')\n",
      "tensor(0.2065, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([238.3829, 173.3635, 114.5909, 112.5045, 109.0714], device='cuda:0')\n",
      "['Image with a volcanic lava flow' 'Image with a volcanic eruption'\n",
      " 'Image with marbled paper texture'\n",
      " 'Abstract artwork with concentric circles'\n",
      " 'Detailed illustration of a futuristic nanotechnology']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3062, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2231, 0.2147, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2106, 0.2101, 0.2281, 0.0000, 0.0000],\n",
      "        [0.2012, 0.1980, 0.1806, 0.2006, 0.0000]], device='cuda:0')\n",
      "tensor(0.2173, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([182.8910, 167.9869, 160.6560, 156.0741, 150.1608], device='cuda:0')\n",
      "['Image with Celtic spiral designs'\n",
      " 'Image with Aboriginal dot painting style'\n",
      " 'Artwork with mosaic tile arrangement'\n",
      " 'Detailed illustration of a piece of jewelry'\n",
      " 'Artwork with mosaic arrangement']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2208, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2173, 0.2080, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2009, 0.1772, 0.1920, 0.0000, 0.0000],\n",
      "        [0.2193, 0.2060, 0.3155, 0.1953, 0.0000]], device='cuda:0')\n",
      "tensor(0.2152, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([591.6210, 217.3267, 195.9058, 181.2987, 136.3096], device='cuda:0')\n",
      "['Detailed illustration of a geological formation'\n",
      " 'Detailed illustration of a piece of clothing'\n",
      " 'Picture with multiple wild animals' 'Image with a volcanic lava flow'\n",
      " 'Snow-covered mountain peaks']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2604, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1733, 0.1614, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2444, 0.2194, 0.1817, 0.0000, 0.0000],\n",
      "        [0.1900, 0.1801, 0.1562, 0.2019, 0.0000]], device='cuda:0')\n",
      "tensor(0.1969, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([448.2052, 317.0700, 208.4399, 169.8044, 169.4430], device='cuda:0')\n",
      "['Image with a hurricane or typhoon' 'A thistle' 'Image with a cyclone'\n",
      " 'Crashing ocean waves' 'Illustration with English letters ']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1513, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2595, 0.1606, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2066, 0.1567, 0.2091, 0.0000, 0.0000],\n",
      "        [0.2033, 0.1774, 0.1960, 0.2068, 0.0000]], device='cuda:0')\n",
      "tensor(0.1927, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([4005.0742, 2997.8489, 1910.5743, 1721.5359, 1397.2545],\n",
      "       device='cuda:0')\n",
      "['Detailed illustration of a geological formation'\n",
      " 'A picture of liechtenstein' 'an image of liechtenstein'\n",
      " 'Detailed illustration of a piece of jewelry' 'Antique religious icon']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1297, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1201, 0.2435, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2463, 0.1230, 0.1136, 0.0000, 0.0000],\n",
      "        [0.2012, 0.1361, 0.1278, 0.2022, 0.0000]], device='cuda:0')\n",
      "tensor(0.1643, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([293.7007, 250.5560, 241.6649, 227.4765, 194.2595], device='cuda:0')\n",
      "['Detailed illustration of a geological formation'\n",
      " 'Detailed illustration of a futuristic energy generator'\n",
      " 'Detailed illustration of a futuristic quantum technology'\n",
      " 'Detailed illustration of a piece of clothing'\n",
      " 'Detailed illustration of a futuristic medical breakthrough']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2411, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2383, 0.2783, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2604, 0.2454, 0.2354, 0.0000, 0.0000],\n",
      "        [0.2251, 0.2494, 0.2582, 0.2283, 0.0000]], device='cuda:0')\n",
      "tensor(0.2460, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 352\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([386.4373, 301.1104, 260.5039, 259.5328, 222.0190], device='cuda:0')\n",
      "['Minimalist architectural photography' 'Antique religious icon'\n",
      " 'Ocean sunset silhouette' 'magical twilight sky'\n",
      " 'weathered religious icon']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2009, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1681, 0.1585, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1542, 0.1537, 0.2039, 0.0000, 0.0000],\n",
      "        [0.1789, 0.2938, 0.1359, 0.1283, 0.0000]], device='cuda:0')\n",
      "tensor(0.1776, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([278.0497, 222.0974, 186.4068, 178.2048, 159.4060], device='cuda:0')\n",
      "['Picture snapped in the Irish countryside' 'Cultural juxtapositions'\n",
      " 'Tranquil lakeside pier' 'Stark minimalism' 'Tranquil lakeside view']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1862, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1615, 0.1212, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1440, 0.1476, 0.1209, 0.0000, 0.0000],\n",
      "        [0.1584, 0.1260, 0.2285, 0.1150, 0.0000]], device='cuda:0')\n",
      "tensor(0.1509, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([121.7527,  96.4566,  94.8095,  81.5650,  77.1150], device='cuda:0')\n",
      "['A seal' 'Quirky street art' 'Whimsical conceptual photography'\n",
      " 'A charcoal gray color' 'A grey color']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2105, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1631, 0.2627, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1817, 0.1837, 0.1523, 0.0000, 0.0000],\n",
      "        [0.1787, 0.1666, 0.1329, 0.2558, 0.0000]], device='cuda:0')\n",
      "tensor(0.1888, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([960.1915, 865.1853, 848.3590, 745.4062, 552.4258], device='cuda:0')\n",
      "['Playful silhouettes' 'delicate soap bubble creation'\n",
      " 'delicate soap bubble display' 'delicate soap bubble play'\n",
      " 'fleeting soap bubble art']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1677, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1480, 0.2912, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1679, 0.3224, 0.2869, 0.0000, 0.0000],\n",
      "        [0.1652, 0.3170, 0.2696, 0.3059, 0.0000]], device='cuda:0')\n",
      "tensor(0.2442, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([181.9555,  97.8425,  89.7498,  85.0351,  79.5104], device='cuda:0')\n",
      "['Captivating silhouettes' 'Photo taken in Grand Canyon'\n",
      " 'Playful silhouettes' 'Ocean sunset silhouette' 'tranquil beach sunset']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1699, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2560, 0.1671, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1946, 0.1791, 0.1930, 0.0000, 0.0000],\n",
      "        [0.1229, 0.1582, 0.1281, 0.2267, 0.0000]], device='cuda:0')\n",
      "tensor(0.1796, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([918.6945, 881.8027, 838.9095, 784.4397, 721.1479], device='cuda:0')\n",
      "['delicate soap bubble display' 'Antique religious icon'\n",
      " 'weathered religious icon' 'Ocean sunset silhouette'\n",
      " 'tranquil beach sunset']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1823, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1574, 0.2938, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1385, 0.1585, 0.1359, 0.0000, 0.0000],\n",
      "        [0.1157, 0.1401, 0.1185, 0.2267, 0.0000]], device='cuda:0')\n",
      "tensor(0.1667, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([612.2481, 380.8982, 292.7288, 282.3470, 224.1888], device='cuda:0')\n",
      "['magical twilight sky' 'Enchanting  twilight sky' 'A belt' 'A necklace'\n",
      " 'A charcoal gray color']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2501, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1597, 0.1459, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1661, 0.1510, 0.3016, 0.0000, 0.0000],\n",
      "        [0.1402, 0.1323, 0.1908, 0.1882, 0.0000]], device='cuda:0')\n",
      "tensor(0.1826, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([86.6994, 66.6270, 45.6784, 31.4638, 29.8062], device='cuda:0')\n",
      "['A bracelet' 'A necklace' 'A belt' 'delicate soap bubble creation'\n",
      " 'A stick']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3209, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3120, 0.3016, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2092, 0.2138, 0.2071, 0.0000, 0.0000],\n",
      "        [0.2327, 0.2381, 0.2443, 0.1789, 0.0000]], device='cuda:0')\n",
      "tensor(0.2459, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 1008\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([592.6332, 571.8856, 549.2757, 504.7358, 482.2671], device='cuda:0')\n",
      "['Architectural symphony' 'Illustration of an ancient civilization'\n",
      " 'innovative design concept' 'Tranquil atmospheres'\n",
      " 'detailed architectural design']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1983, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2145, 0.2617, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1803, 0.1608, 0.1836, 0.0000, 0.0000],\n",
      "        [0.2488, 0.2563, 0.2740, 0.1801, 0.0000]], device='cuda:0')\n",
      "tensor(0.2158, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([886.1815, 518.8351, 362.5893, 322.2615, 311.0007], device='cuda:0')\n",
      "['Detailed illustration of a piece of jewelry'\n",
      " 'Image with a seamless white background' 'Pristine snowy landscape'\n",
      " 'cozy home interior' 'peaceful lakeside scene']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2618, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1692, 0.2476, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1947, 0.2466, 0.2026, 0.0000, 0.0000],\n",
      "        [0.1618, 0.2122, 0.2004, 0.1963, 0.0000]], device='cuda:0')\n",
      "tensor(0.2093, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([677.4009, 569.3440, 467.9563, 462.3377, 404.0011], device='cuda:0')\n",
      "['Detailed illustration of an advanced artificial intelligence'\n",
      " 'Detailed illustration of a futuristic robotics'\n",
      " 'Detailed illustration of a futuristic AI-human interface'\n",
      " 'Detailed illustration of an advanced machinery'\n",
      " 'Detailed illustration of a machinery']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3052, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3032, 0.2880, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2855, 0.2669, 0.2502, 0.0000, 0.0000],\n",
      "        [0.2829, 0.2823, 0.2600, 0.3232, 0.0000]], device='cuda:0')\n",
      "tensor(0.2847, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([77.8687, 49.1031, 47.9158, 45.1811, 42.5655], device='cuda:0')\n",
      "['Creative imagination' 'Thoughtful facial expression'\n",
      " 'weathered artistic creation' 'Illustration of an ancient civilization'\n",
      " 'inviting home interior']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2007, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2180, 0.1812, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2275, 0.1980, 0.2236, 0.0000, 0.0000],\n",
      "        [0.2330, 0.1966, 0.2102, 0.2220, 0.0000]], device='cuda:0')\n",
      "tensor(0.2111, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([126.6103,  89.7633,  85.1691,  68.7620,  67.8371], device='cuda:0')\n",
      "['Image of an airplane' 'Detailed illustration of an advanced machinery'\n",
      " 'detailed botanical macro' 'Detailed illustration of a machinery'\n",
      " 'Image with a seamless white background']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2524, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2318, 0.2259, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2688, 0.3232, 0.2328, 0.0000, 0.0000],\n",
      "        [0.3159, 0.2729, 0.2546, 0.2925, 0.0000]], device='cuda:0')\n",
      "tensor(0.2671, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([276.9948, 261.8041, 257.6543, 254.4283, 209.9278], device='cuda:0')\n",
      "['Ancient and weathered stone carving'\n",
      " 'Illustration of a hidden ancient city'\n",
      " 'Ancient and weathered stone structure'\n",
      " 'Illustration of an ancient civilization'\n",
      " 'Detailed illustration of a piece of jewelry']\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2495, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3173, 0.2511, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2658, 0.3089, 0.2543, 0.0000, 0.0000],\n",
      "        [0.2154, 0.2297, 0.2064, 0.2506, 0.0000]], device='cuda:0')\n",
      "tensor(0.2549, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([1269.8748, 1020.5385,  932.0421,  890.6186,  766.1622],\n",
      "       device='cuda:0')\n",
      "['Detailed illustration of an advanced machinery' 'Minimalist design'\n",
      " 'A polygon with many sides' 'Quiet simplicity'\n",
      " 'Image with a seamless white background']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2344, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2024, 0.2377, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1634, 0.2350, 0.1725, 0.0000, 0.0000],\n",
      "        [0.2729, 0.3134, 0.2605, 0.2169, 0.0000]], device='cuda:0')\n",
      "tensor(0.2309, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([106.3592,  76.0915,  66.6033,  63.8972,  63.8525], device='cuda:0')\n",
      "[\"Whimsical children's play\" 'Whimsical storybook scene'\n",
      " 'Ancient and weathered stone carving' \"playful children's scene\"\n",
      " 'inviting home interior']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2566, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2117, 0.2221, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2520, 0.2425, 0.2129, 0.0000, 0.0000],\n",
      "        [0.2010, 0.2255, 0.2271, 0.2117, 0.0000]], device='cuda:0')\n",
      "tensor(0.2263, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 2352\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([2724.0742, 1890.9061, 1802.1968,  686.5372,  601.1188],\n",
      "       device='cuda:0')\n",
      "['Image with a futuristic terraforming experiment'\n",
      " 'Image with a futuristic terraforming process'\n",
      " 'Image with a futuristic terraforming project' 'Majestic canyon vista'\n",
      " 'Image with a futuristic interstellar voyage']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2766, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2826, 0.2915, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1523, 0.1623, 0.1687, 0.0000, 0.0000],\n",
      "        [0.2192, 0.2313, 0.2390, 0.1757, 0.0000]], device='cuda:0')\n",
      "tensor(0.2199, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([4436.4463, 4061.8745, 3356.8120, 2480.7302, 1544.3772],\n",
      "       device='cuda:0')\n",
      "['Image with a futuristic terraforming experiment'\n",
      " 'Image with a futuristic terraforming process'\n",
      " 'Detailed illustration of an advanced space exploration'\n",
      " 'Image with a futuristic terraforming project'\n",
      " 'Illustration of an intergalactic voyage']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2766, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2095, 0.2221, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2826, 0.2915, 0.2222, 0.0000, 0.0000],\n",
      "        [0.2193, 0.2347, 0.2851, 0.2398, 0.0000]], device='cuda:0')\n",
      "tensor(0.2484, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([116.4252, 101.5153,  94.1748,  91.6015,  76.0455], device='cuda:0')\n",
      "['Artwork featuring zebra stripe motifs' 'Stark minimalism'\n",
      " 'Playful textures' 'Artwork featuring Escher-like patterns'\n",
      " 'Playful interactions']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1347, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1730, 0.1250, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1882, 0.1261, 0.1473, 0.0000, 0.0000],\n",
      "        [0.1417, 0.1171, 0.2145, 0.1260, 0.0000]], device='cuda:0')\n",
      "tensor(0.1494, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([198.1019, 178.5634, 151.1513, 133.1277, 132.0411], device='cuda:0')\n",
      "['intricate crystal arrangement'\n",
      " 'Artwork featuring shattered glass patterns'\n",
      " 'Image with shattered crystal sculptures' 'Tranquil temple courtyard'\n",
      " 'Enchanting celestial display']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2320, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2435, 0.2604, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1820, 0.1609, 0.1596, 0.0000, 0.0000],\n",
      "        [0.1803, 0.1537, 0.1490, 0.1333, 0.0000]], device='cuda:0')\n",
      "tensor(0.1855, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([103.4112,  57.9935,  56.3501,  51.8825,  44.1895], device='cuda:0')\n",
      "['Artwork featuring Morse code typography' 'Anime style image'\n",
      " 'Photo featuring a vibrant cultural exhibition' 'Stark minimalism'\n",
      " 'Minimalist composition']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1698, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1923, 0.2044, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1415, 0.1591, 0.1497, 0.0000, 0.0000],\n",
      "        [0.2077, 0.2196, 0.2350, 0.2177, 0.0000]], device='cuda:0')\n",
      "tensor(0.1897, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([305.3589, 184.8365, 173.9574, 161.2573, 144.0066], device='cuda:0')\n",
      "['misty forest path' 'Crisp autumn leaves' 'Mysterious misty forest'\n",
      " 'Remote alpine chalet' 'Mystical moonlit scenes']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1488, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2465, 0.1740, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1507, 0.1735, 0.1817, 0.0000, 0.0000],\n",
      "        [0.1507, 0.1480, 0.1872, 0.1742, 0.0000]], device='cuda:0')\n",
      "tensor(0.1735, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([3951.5522, 3401.9778, 3343.8923, 3033.7795, 2861.9780],\n",
      "       device='cuda:0')\n",
      "['Image with a warm color palette' 'Reflective  mountain view'\n",
      " 'Tranquil passages' 'Stark minimalism' 'Majestic canyon vista']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1451, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1631, 0.1197, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1697, 0.1036, 0.1108, 0.0000, 0.0000],\n",
      "        [0.1794, 0.1729, 0.1480, 0.1255, 0.0000]], device='cuda:0')\n",
      "tensor(0.1438, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([122.5009,  98.3382,  90.9343,  32.6250,  32.3018], device='cuda:0')\n",
      "['Image with a futuristic terraforming experiment'\n",
      " 'Image with a futuristic terraforming process'\n",
      " 'Image with a futuristic terraforming project' 'Tranquil contemplation'\n",
      " 'Artwork featuring cubist elements']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2766, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2826, 0.2915, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1251, 0.1273, 0.1364, 0.0000, 0.0000],\n",
      "        [0.1735, 0.1821, 0.1881, 0.1228, 0.0000]], device='cuda:0')\n",
      "tensor(0.1906, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "\n",
      "\n",
      "For Feature 2289\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([17957.6777, 15659.9785, 12021.6543,  6657.6035,  6555.0254],\n",
      "       device='cuda:0')\n",
      "['Warm home interior' 'Warm and cozy indoor scene' 'cozy home interior'\n",
      " 'Macro botanical photography'\n",
      " 'Detailed illustration of a futuristic quantum realm']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2953, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3081, 0.2882, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2235, 0.2093, 0.2208, 0.0000, 0.0000],\n",
      "        [0.1317, 0.1318, 0.1227, 0.1340, 0.0000]], device='cuda:0')\n",
      "tensor(0.2065, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([947.7662, 613.8796, 550.7979, 537.9485, 488.8575], device='cuda:0')\n",
      "['colorful procession' 'Macro botanical photography' 'Warm home interior'\n",
      " 'Timeless elegance' 'Dreamlike haze']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1612, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1613, 0.2235, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1224, 0.1628, 0.1570, 0.0000, 0.0000],\n",
      "        [0.1276, 0.1541, 0.1775, 0.1610, 0.0000]], device='cuda:0')\n",
      "tensor(0.1608, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([1242.0555,  568.7234,  464.8922,  399.4015,  362.7642],\n",
      "       device='cuda:0')\n",
      "['Striking fashion shot' 'Eccentric fashion shot'\n",
      " 'Macro botanical photography' 'colorful festival' 'colorful exhibition']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.3265, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2652, 0.2527, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2181, 0.2178, 0.1880, 0.0000, 0.0000],\n",
      "        [0.2228, 0.2259, 0.2017, 0.2539, 0.0000]], device='cuda:0')\n",
      "tensor(0.2373, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([100.2541,  92.7995,  71.0862,  60.8180,  60.7815], device='cuda:0')\n",
      "['Striking fashion silhouette' 'colorful procession'\n",
      " 'Eclectic street scenes' 'Evocative silhouettes'\n",
      " 'Rich and opulent interior decor']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1695, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2073, 0.1815, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2459, 0.1324, 0.1762, 0.0000, 0.0000],\n",
      "        [0.2534, 0.1895, 0.2353, 0.1895, 0.0000]], device='cuda:0')\n",
      "tensor(0.1981, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([287.8859, 189.2754, 182.6521, 161.5226, 158.7545], device='cuda:0')\n",
      "['Detailed illustration of a piece of jewelry' 'Playful details'\n",
      " 'Striking fashion shot' 'Striking fashion statement'\n",
      " 'Striking fashion silhouette']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1735, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2066, 0.2191, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2004, 0.2045, 0.3193, 0.0000, 0.0000],\n",
      "        [0.1982, 0.1916, 0.3070, 0.2862, 0.0000]], device='cuda:0')\n",
      "tensor(0.2306, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([6000.7505, 4781.6787, 3824.8362, 2424.9526, 1776.3070],\n",
      "       device='cuda:0')\n",
      "['Warm and cozy indoor scene' 'cozy home interior'\n",
      " 'cozy bedroom atmosphere' 'Warm home interior'\n",
      " 'Macro botanical photography']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2882, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2679, 0.2963, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2953, 0.3081, 0.2775, 0.0000, 0.0000],\n",
      "        [0.2093, 0.2208, 0.2128, 0.2235, 0.0000]], device='cuda:0')\n",
      "tensor(0.2600, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([12916.4805, 10425.1689,  9919.5898,  9245.4492,  8730.1807],\n",
      "       device='cuda:0')\n",
      "['Enchanting  mystical realm' 'Frozen memories' 'Mysterious ambiance'\n",
      " 'Nostalgic traditions' 'colorful procession']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1656, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1847, 0.1916, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1644, 0.1828, 0.1903, 0.0000, 0.0000],\n",
      "        [0.1340, 0.1369, 0.1384, 0.1601, 0.0000]], device='cuda:0')\n",
      "tensor(0.1649, device='cuda:0')\n",
      "\n",
      "Most Changed, by Ratio:\n",
      "tensor([146.0082, 144.1322,  82.2659,  81.1029,  64.3846], device='cuda:0')\n",
      "['cozy home interior' 'cozy bedroom atmosphere'\n",
      " 'Photo taken in the Moroccan desert' 'A pearl'\n",
      " 'Inviting bedroom atmosphere']\n",
      "tensor([[0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.2963, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1897, 0.1985, 0.0000, 0.0000, 0.0000],\n",
      "        [0.1807, 0.1772, 0.1796, 0.0000, 0.0000],\n",
      "        [0.2782, 0.3179, 0.2121, 0.1971, 0.0000]], device='cuda:0')\n",
      "tensor(0.2227, device='cuda:0')\n",
      "torch.Size([40, 40])\n",
      "tensor(0.1990)\n"
     ]
    }
   ],
   "source": [
    "# subtract from default, label, and print trends\n",
    "text_probs_altered.shape\n",
    "\n",
    "# selected_vocab = all_imagenet_class_names\n",
    "selected_vocab = larger_vocab\n",
    "\n",
    "cov_stuff_avgs = []\n",
    "# cov_stuff_avgs_least = []\n",
    "for j, text_probs_altered in enumerate(text_probs_altered_list):\n",
    "    print(f\"\\n\\nFor Feature {random_feat_idxs[j]}\")\n",
    "    logit_diff = text_probs_altered - text_probs_default\n",
    "    logit_ratio = text_probs_altered/text_probs_default\n",
    "    \n",
    "    vals, idxs = torch.topk(logit_diff,k=5)\n",
    "    vals_least, idxs_least = torch.topk(logit_diff,k=5,largest=False)\n",
    "    \n",
    "    ratios, ratios_idxs = torch.topk(logit_ratio,k=5)\n",
    "    ratios_least, ratios_idxs_least = torch.topk(logit_ratio,k=5,largest=False)\n",
    "    \n",
    "    cov_over_images = []\n",
    "    for i in range(logit_diff.shape[0]//4):\n",
    "#         print(f\"\\nImage {i} ========================\\nMost Changed, by Absolute Diff\\n:{vals[i]}\")\n",
    "#         print(np.array(all_imagenet_class_names)[idxs.cpu()][i])\n",
    "#         print(vals_least[i])\n",
    "#         print(np.array(all_imagenet_class_names)[idxs_least.cpu()][i])\n",
    "        \n",
    "        print(\"\\nMost Changed, by Ratio:\")\n",
    "        print(ratios[i])\n",
    "        print(np.array(selected_vocab)[ratios_idxs.cpu()][i])\n",
    "#         print(ratios_least[i])\n",
    "#         print(np.array(selected_vocab)[ratios_idxs_least.cpu()][i])\n",
    "        \n",
    "        text = tokenizer(np.array(selected_vocab)[ratios_idxs.cpu()][i])\n",
    "#         text_least = tokenizer(np.array(selected_vocab)[ratios_idxs_least.cpu()][i])\n",
    "        text_features = og_model.encode_text(text.cuda())\n",
    "        cov_over_images.append(text_features)\n",
    "#         text_features_least = og_model.encode_text(text_least.cuda())\n",
    "        print(torch.tril(torch.cov(text_features), diagonal=-1))\n",
    "        print(torch.tril(torch.cov(text_features), diagonal=-1).sum()/10)\n",
    "#         cov_stuff = torch.tril(torch.cov(text_features), diagonal=-1).sum()/10\n",
    "#         cov_stuff_least = torch.tril(torch.cov(text_features_least), diagonal=-1).sum()/10\n",
    "    print(torch.tril(torch.cov(torch.cat(cov_over_images)), diagonal=-1).shape)\n",
    "    n = torch.tril(torch.cov(torch.cat(cov_over_images)), diagonal=-1).shape[0]\n",
    "    num_elements = (n**2)/2 - n\n",
    "    cov_stuff = torch.tril(torch.cov(torch.cat(cov_over_images)), diagonal=-1).sum()/num_elements\n",
    "    cov_stuff_avgs.append(cov_stuff)\n",
    "#         cov_stuff_avgs_least.append(cov_stuff_least)\n",
    "    if j > 10:\n",
    "        break\n",
    "print(torch.tensor(cov_stuff_avgs).mean())\n",
    "# print(torch.tensor(cov_stuff_avgs_least).mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_k_imgnet_labels = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from collections import defaultdict, Counter\n",
    "\n",
    "feat_autolabels_default = defaultdict(Counter)\n",
    "for i in range(text_probs_default.shape[0]):\n",
    "    vals, idxs = torch.topk(text_probs_default[i],k=top_k_imgnet_labels)\n",
    "    print(i)\n",
    "    for k, idx in enumerate(idxs):\n",
    "        feat_autolabels_default[i][all_imagenet_class_names[idx]] += vals[k]\n",
    "        print(\"\\t\", all_imagenet_class_names[idx])\n",
    "feat_autolabels_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subtract from default, label, and print trends\n",
    "text_probs_altered.shape\n",
    "\n",
    "for text_probs_altered in text_probs_altered_list:\n",
    "    logit_diff = text_probs_altered - text_probs_default\n",
    "    print(logit_diff)\n",
    "    vals, idxs = torch.topk(logit_diff,k=5)\n",
    "    print(vals, np.array(all_imagenet_class_names[idxs])\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_imagenet_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "feat_autolabels_altered_list = []\n",
    "for text_probs_altered in text_probs_altered_list:\n",
    "    feat_autolabels_altered = defaultdict(Counter)\n",
    "    for i in range(text_probs_altered.shape[0]):\n",
    "        vals, idxs = torch.topk(text_probs_altered[i],k=top_k_imgnet_labels)\n",
    "#         print(i)\n",
    "        for k, idx in enumerate(idxs):\n",
    "            feat_autolabels_altered[i][all_imagenet_class_names[idx]] += vals[k]\n",
    "#             print(\"\\t\", all_imagenet_class_names[idx])\n",
    "    feat_autolabels_altered_list.append(feat_autolabels_altered)\n",
    "\n",
    "start_idx = 9\n",
    "end_idx = 10\n",
    "    \n",
    "h = 0\n",
    "for key in feat_autolabels_default:\n",
    "    print(f\"\\nfeat_autolabels_default img {key}:\\n {feat_autolabels_default[key]}\\n\")\n",
    "    h += 1\n",
    "    if h > end_idx:\n",
    "        break\n",
    "for i, f_a_a in enumerate(feat_autolabels_altered_list):\n",
    "    print(\"============= feature number \", i, \"====================\")\n",
    "    h = 0\n",
    "    for key in range(start_idx, end_idx):\n",
    "#         print(\"\\n\", key)\n",
    "#         for item in f_a_a[key]:\n",
    "#             print(\"\\t\", item, f_a_a[key][item].cpu().item())\n",
    "        print(f\"\\nf_a_a img {key}:\\n {f_a_a[key]}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(text_probs_default.shape[0]):\n",
    "    vals, idxs = torch.topk(text_probs_default[i],k=1000)\n",
    "    print(i, ind_to_name[str(idxs[0].cpu().item())][1])\n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "#     ax.xaxis.set_ticks((1000))\n",
    "#     ax.set_xticks(list(range(1000)), [ind_to_name[str(idxs[idx].cpu().item())][1] for idx in idxs])\n",
    "    plt.bar(idxs.cpu(), vals.cpu(), width=5)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(batch_images[2].cpu().permute((1,2,0)).numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "@torch.no_grad()\n",
    "def get_heatmap(\n",
    "          image,\n",
    "          model,\n",
    "          sparse_autoencoder,\n",
    "          feature_id,\n",
    "): \n",
    "    image = image.to(cfg.device)\n",
    "    _, cache = model.run_with_cache(image.unsqueeze(0))\n",
    "\n",
    "    post_reshaped = einops.rearrange(cache[sparse_autoencoder.cfg.hook_point], \"batch seq d_mlp -> (batch seq) d_mlp\")\n",
    "    # Compute activations (not from a fwd pass, but explicitly, by taking only the feature we want)\n",
    "    # This code is copied from the first part of the 'forward' method of the AutoEncoder class\n",
    "    sae_in =  post_reshaped - sparse_autoencoder.b_dec # Remove decoder bias as per Anthropic\n",
    "    print(f\"sae_in.shape: {sae_in.shape}\")\n",
    "    acts = einops.einsum(\n",
    "            sae_in,\n",
    "            sparse_autoencoder.W_enc[:, feature_id],\n",
    "            \"x d_in, d_in -> x\",\n",
    "        )\n",
    "    return acts \n",
    "     \n",
    "def image_patch_heatmap(activation_values,image_size=224, pixel_num=14):\n",
    "    activation_values = activation_values.detach().cpu().numpy()\n",
    "    activation_values = activation_values[1:]\n",
    "    activation_values = activation_values.reshape(pixel_num, pixel_num)\n",
    "\n",
    "    # Create a heatmap overlay\n",
    "    heatmap = np.zeros((image_size, image_size))\n",
    "    patch_size = image_size // pixel_num\n",
    "\n",
    "    for i in range(pixel_num):\n",
    "        for j in range(pixel_num):\n",
    "            heatmap[i*patch_size:(i+1)*patch_size, j*patch_size:(j+1)*patch_size] = activation_values[i, j]\n",
    "\n",
    "    return heatmap\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "\n",
    "grid_size = 1\n",
    "fig, axs = plt.subplots(int(np.ceil(len(images)/grid_size)), grid_size, figsize=(15, 15))\n",
    "name=  f\"Category: uhh,  Feature: {0}\"\n",
    "fig.suptitle(name)#, y=0.95)\n",
    "for ax in axs.flatten():\n",
    "    ax.axis('off')\n",
    "complete_bid = []\n",
    "\n",
    "heatmap = get_heatmap(batch_images[2], model,sparse_autoencoder, 10000)\n",
    "heatmap = image_patch_heatmap(heatmap, pixel_num=224//cfg.patch_size)\n",
    "\n",
    "display = batch_images[2].cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "has_zero = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(display)\n",
    "plt.imshow(heatmap, alpha=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(display)\n",
    "plt.imshow(heatmap, alpha=0.3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
