{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating your SAE\n",
    "\n",
    "Code based off Rob Graham's ([themachinefan](https://github.com/themachinefan)) SAE evaluation code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/ViT-Prisma/src/vit_prisma/sae/evals'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import einops\n",
    "import torch\n",
    "import torchvision\n",
    "\n",
    "import plotly.express as px\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import numpy as np\n",
    "import os\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens_per_buffer (millions): 0.032\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 158691\n",
      "Total training images: 13000000\n",
      "Total wandb updates: 15869\n",
      "Expansion factor: 16\n",
      "n_tokens_per_feature_sampling_window (millions): 204.8\n",
      "n_tokens_per_dead_feature_window (millions): 1024.0\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 158 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Gradient clipping with max_norm=1.0\n",
      "Using SAE initialization method: encoder_transpose_decoder\n"
     ]
    }
   ],
   "source": [
    "from dataclasses import dataclass\n",
    "from vit_prisma.sae.config import VisionModelSAERunnerConfig\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class EvalConfig(VisionModelSAERunnerConfig):\n",
    "    # sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-0.0001\n",
    "    # sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-11-hook_resid_post-l1-0.0001\n",
    "    sae_path: str = '/workspace/sae_checkpoints/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-0.0001/n_images_2600058.pt'\n",
    "    model_name: str = \"open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "    model_type: str =  \"clip\"\n",
    "    patch_size: str = 32\n",
    "\n",
    "    dataset_path = \"/workspace\"\n",
    "    dataset_train_path: str = \"/workspace/ILSVRC/Data/CLS-LOC/train\"\n",
    "    dataset_val_path: str = \"/workspace/ILSVRC/Data/CLS-LOC/val\"\n",
    "\n",
    "    verbose: bool = True\n",
    "\n",
    "    device: bool = 'cuda'\n",
    "\n",
    "    eval_max: int = 50_000 # 50_000\n",
    "    batch_size: int = 32\n",
    "\n",
    "    # make the max image output folder a subfolder of the sae path\n",
    "\n",
    "\n",
    "    @property\n",
    "    def max_image_output_folder(self) -> str:\n",
    "        # Get the base directory of sae_checkpoints\n",
    "        sae_base_dir = os.path.dirname(os.path.dirname(self.sae_path))\n",
    "        \n",
    "        # Get the name of the original SAE checkpoint folder\n",
    "        sae_folder_name = os.path.basename(os.path.dirname(self.sae_path))\n",
    "        \n",
    "        # Create a new folder path in sae_checkpoints/images with the original name\n",
    "        output_folder = os.path.join(sae_base_dir, 'max_images', sae_folder_name)\n",
    "        output_folder = os.path.join(output_folder, f\"layer_{self.hook_point_layer}\") # Add layer number\n",
    "\n",
    "        \n",
    "        # Ensure the directory exists\n",
    "        os.makedirs(output_folder, exist_ok=True)\n",
    "        \n",
    "        return output_folder\n",
    "\n",
    "cfg = EvalConfig()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7fefbdf96cb0>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "Official model name open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "Converting OpenCLIP weights\n",
      "model_id download_pretrained_from_hf: laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\n",
      "visual projection shape torch.Size([768, 512])\n",
      "Setting center_writing_weights to False for OpenCLIP\n",
      "Setting fold_ln to False for OpenCLIP\n",
      "Loaded pretrained model open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "from vit_prisma.models.base_vit import HookedViT\n",
    "\n",
    "model_name = \"open-clip:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "model = HookedViT.from_pretrained(model_name, is_timm=False, is_clip=True).to(cfg.device)\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import vit_prisma\n",
    "# importlib.reload(vit_prisma.dataloaders.imagenet_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Validation data length: 50000\n"
     ]
    }
   ],
   "source": [
    "# load dataset\n",
    "import open_clip\n",
    "from vit_prisma.utils.data_utils.imagenet_utils import setup_imagenet_paths\n",
    "from vit_prisma.dataloaders.imagenet_dataset import get_imagenet_transforms_clip, ImageNetValidationDataset\n",
    "\n",
    "from torchvision import transforms\n",
    "from transformers import CLIPProcessor\n",
    "\n",
    "og_model_name = \"hf-hub:laion/CLIP-ViT-B-32-DataComp.XL-s13B-b90K\"\n",
    "og_model, _, preproc = open_clip.create_model_and_transforms(og_model_name)\n",
    "processor = preproc\n",
    "\n",
    "size=224\n",
    "\n",
    "data_transforms = transforms.Compose([\n",
    "    transforms.Resize((size, size)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                     std=[0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "    \n",
    "imagenet_paths = setup_imagenet_paths(cfg.dataset_path)\n",
    "imagenet_paths[\"train\"] = \"/workspace/ILSVRC/Data/CLS-LOC/train\"\n",
    "imagenet_paths[\"val\"] = \"/workspace/ILSVRC/Data/CLS-LOC/val\"\n",
    "imagenet_paths[\"val_labels\"] = \"/workspace/LOC_val_solution.csv\"\n",
    "imagenet_paths[\"label_strings\"] = \"/workspace/LOC_synset_mapping.txt\"\n",
    "print()\n",
    "train_data = torchvision.datasets.ImageFolder(cfg.dataset_train_path, transform=data_transforms)\n",
    "val_data = ImageNetValidationDataset(cfg.dataset_val_path, \n",
    "                                imagenet_paths['label_strings'], \n",
    "                                imagenet_paths['val_labels'], \n",
    "                                data_transforms,\n",
    "                                return_index=True,\n",
    ")\n",
    "val_data_visualize = ImageNetValidationDataset(cfg.dataset_val_path, \n",
    "                                imagenet_paths['label_strings'], \n",
    "                                imagenet_paths['val_labels'],\n",
    "                                torchvision.transforms.Compose([\n",
    "    torchvision.transforms.Resize((224, 224)),\n",
    "    torchvision.transforms.ToTensor(),]), return_index=True)\n",
    "\n",
    "print(f\"Validation data length: {len(val_data)}\") if cfg.verbose else None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_prisma.sae.training.activations_store import VisionActivationsStore\n",
    "# import dataloader\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# activations_loader = VisionActivationsStore(cfg, model, train_data, eval_dataset=val_data)\n",
    "val_dataloader = DataLoader(val_data, batch_size=cfg.batch_size, shuffle=False, num_workers=4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load pretrained SAE to evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "get_activation_fn received: activation_fn=relu, kwargs={}\n",
      "n_tokens_per_buffer (millions): 0.032\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.00064\n",
      "Total training steps: 158691\n",
      "Total training images: 13000000\n",
      "Total wandb updates: 1586\n",
      "Expansion factor: 64\n",
      "n_tokens_per_feature_sampling_window (millions): 204.8\n",
      "n_tokens_per_dead_feature_window (millions): 1024.0\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 158 times.\n",
      "Number tokens in sparsity calculation window: 4.10e+06\n",
      "Gradient clipping with max_norm=1.0\n",
      "Using SAE initialization method: encoder_transpose_decoder\n",
      "get_activation_fn received: activation_fn=relu, kwargs={}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SparseAutoencoder(\n",
       "  (hook_sae_in): HookPoint()\n",
       "  (hook_hidden_pre): HookPoint()\n",
       "  (hook_hidden_post): HookPoint()\n",
       "  (hook_sae_out): HookPoint()\n",
       "  (activation_fn): ReLU()\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from vit_prisma.sae.sae import SparseAutoencoder\n",
    "sparse_autoencoder = SparseAutoencoder(cfg).load_from_pretrained(\"/workspace/sae_checkpoints/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-0.0001/n_images_2600058.pt\")\n",
    "sparse_autoencoder.to(cfg.device)\n",
    "sparse_autoencoder.eval()  # prevents error if we're expecting a dead neuron mask for who \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clip Labeling AutoInterp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# all_imagenet_class_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vit_prisma.dataloaders.imagenet_dataset import get_imagenet_index_to_name\n",
    "ind_to_name = get_imagenet_index_to_name()\n",
    "\n",
    "all_imagenet_class_names = []\n",
    "for i in range(len(ind_to_name)):\n",
    "    all_imagenet_class_names.append(ind_to_name[str(i)][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/workspace/sae_checkpoints/max_images/sparse-autoencoder-clip-b-32-sae-vanilla-x64-layer-10-hook_mlp_out-l1-0.0001/layer_9'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.max_image_output_folder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature steering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def steering_hook_fn_cls_only(\n",
    "    activations, cfg, hook, sae, steering_indices, steering_strength=1.0, mean_ablation_values=None, include_error=False\n",
    "\n",
    "):\n",
    "    sae.to(activations.device)\n",
    "\n",
    "\n",
    "    sae_input = activations.clone()\n",
    "    sae_output, feature_activations, *data = sae(sae_input)\n",
    "    \n",
    "    steered_feature_activations = feature_activations.clone()\n",
    "    \n",
    "    # batch, stream, feats\n",
    "    # cls token is *last* in sequence\n",
    "    steered_feature_activations[:, 0, steering_indices] = steering_strength\n",
    "\n",
    "    steered_sae_out = einops.einsum(\n",
    "                steered_feature_activations,\n",
    "                sae.W_dec,\n",
    "                \"... d_sae, d_sae d_in -> ... d_in\",\n",
    "            ) + sae.b_dec\n",
    "\n",
    "    steered_sae_out = sae.run_time_activation_norm_fn_out(steered_sae_out)\n",
    "    \n",
    "    # print(f\"steering norm: {(steered_sae_out - sae_output).norm()}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    if include_error:\n",
    "        error = sae_input - sae_output\n",
    "        # print(f\"error.norm(): {error.norm()}\")\n",
    "        return steered_sae_out + error\n",
    "    return steered_sae_out\n",
    "\n",
    "\n",
    "def steering_hook_fn(\n",
    "    activations, cfg, hook, sae, steering_indices, steering_strength=1.0, mean_ablation_values=None, include_error=False\n",
    "\n",
    "):\n",
    "    sae.to(activations.device)\n",
    "\n",
    "\n",
    "    sae_input = activations.clone()\n",
    "    sae_output, feature_activations, *data = sae(sae_input)\n",
    "    \n",
    "    steered_feature_activations = feature_activations.clone()\n",
    "    \n",
    "    steered_feature_activations[:, :, steering_indices] = steering_strength\n",
    "\n",
    "    steered_sae_out = einops.einsum(\n",
    "                steered_feature_activations,\n",
    "                sae.W_dec,\n",
    "                \"... d_sae, d_sae d_in -> ... d_in\",\n",
    "            ) + sae.b_dec\n",
    "\n",
    "    steered_sae_out = sae.run_time_activation_norm_fn_out(steered_sae_out)\n",
    "    \n",
    "    # print(f\"steering norm: {(steered_sae_out - sae_output).norm()}\")\n",
    "    \n",
    "    \n",
    "\n",
    "    if include_error:\n",
    "        error = sae_input - sae_output\n",
    "        # print(f\"error.norm(): {error.norm()}\")\n",
    "        return steered_sae_out + error\n",
    "    return steered_sae_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_feat_idxs = np.random.randint(0, high=3000, size=(25))\n",
    "random_feat_idxs[0] = 655\n",
    "random_feat_idxs[1] = 656\n",
    "random_feat_idxs[2] = 665"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for a given feature, set it high/low on maxim activ. imgs and high/low on non-activ images\n",
    "# hook SAE and replace desired feature with 0 or 1 \n",
    "from typing import List, Dict, Tuple\n",
    "import torch\n",
    "import einops\n",
    "from tqdm import tqdm\n",
    "\n",
    "from functools import partial\n",
    "\n",
    "@torch.no_grad()\n",
    "def compute_feature_activations_set_feat(\n",
    "    images: torch.Tensor,\n",
    "    model: torch.nn.Module,\n",
    "    sparse_autoencoder: torch.nn.Module,\n",
    "    encoder_weights: torch.Tensor,\n",
    "    encoder_biases: torch.Tensor,\n",
    "    feature_ids: List[int],\n",
    "    feature_categories: List[str],\n",
    "    top_k: int = 10,\n",
    "    steering_strength: float = 10.0\n",
    "):\n",
    "    \"\"\"\n",
    "    Compute the highest activating tokens for given features in a batch of images.\n",
    "    \n",
    "    Args:\n",
    "        images: Input images\n",
    "        model: The main model\n",
    "        sparse_autoencoder: The sparse autoencoder\n",
    "        encoder_weights: Encoder weights for selected features\n",
    "        encoder_biases: Encoder biases for selected features\n",
    "        feature_ids: List of feature IDs to analyze\n",
    "        feature_categories: Categories of the features\n",
    "        top_k: Number of top activations to return per feature\n",
    "\n",
    "    Returns:\n",
    "        Dictionary mapping feature IDs to tuples of (top_indices, top_values)\n",
    "    \"\"\"\n",
    "#     _, cache = model.run_with_cache(images, names_filter=[sparse_autoencoder.cfg.hook_point])\n",
    "    recons_image_embeddings_feat_altered_list = []\n",
    "    for idx in np.array(range(sparse_autoencoder.W_dec.shape[0]))[random_feat_idxs]:\n",
    "#         print(f\"Feature: {idx} ====================\")\n",
    "        \n",
    "        # steering_hook_fn, steering_hook_fn_cls_only\n",
    "        steering_hook = partial(\n",
    "            steering_hook_fn,\n",
    "            cfg=cfg,\n",
    "            sae=sparse_autoencoder,\n",
    "            steering_indices=[idx],\n",
    "            steering_strength=steering_strength,\n",
    "            mean_ablation_values = [1.0],\n",
    "            include_error=True,\n",
    "            )\n",
    "        \n",
    "        \n",
    "        recons_image_embeddings_feat_altered = model.run_with_hooks(\n",
    "            images,\n",
    "            fwd_hooks=[(\"blocks.9.hook_mlp_out\", steering_hook)],\n",
    "        )\n",
    "        recons_image_embeddings_feat_altered_list.append(recons_image_embeddings_feat_altered)\n",
    "\n",
    "    \n",
    "    # output is in clip embedding space\n",
    "    recons_image_embeddings_default = model.run_with_hooks(\n",
    "        images,\n",
    "        fwd_hooks=[(\"blocks.9.hook_mlp_out\", lambda x, hook: x)],\n",
    "    )\n",
    "    \n",
    "#     print(f\"recons_image_embeddings_default: {recons_image_embeddings_default}\")\n",
    "#     print(f\"recons_image_embeddings_default.shape: {recons_image_embeddings_default.shape}\")\n",
    "#     print(f\"recons_image_embeddings_default: {recons_image_embeddings_default.shape}\")\n",
    "\n",
    "#     print(f\"recons_image_embeddings_feat_altered: {recons_image_embeddings_feat_altered}\")\n",
    "#     print(f\"recons_image_embeddings_feat_altered.shape: {recons_image_embeddings_feat_altered.shape}\")\n",
    "\n",
    "    return recons_image_embeddings_feat_altered_list, recons_image_embeddings_default"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================ steering_strength: 0.0 ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/1562 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "655\n",
      "656\n",
      "665\n",
      "204\n",
      "1692\n",
      "371\n",
      "1595\n",
      "2598\n",
      "546\n",
      "20\n",
      "606\n",
      "2536\n",
      "393\n",
      "2726\n",
      "2596\n",
      "113\n",
      "2773\n",
      "478\n",
      "138\n",
      "854\n",
      "2594\n",
      "1839\n",
      "1325\n",
      "2741\n",
      "1405\n",
      "========================================================================================\n",
      "\n",
      "For Feature 655\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0018, 0.0013, 0.0013, 0.0009, 0.0009, 0.0006, 0.0004, 0.0003, 0.0003,\n",
      "        0.0003], device='cuda:0')\n",
      "['hairy' 'dog' 'model' 'golden' 'roof' 'museum' 'cafe' 'milfhunter' 'cock'\n",
      " 'douglas']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0043, 1.0043, 1.0037, 1.0036, 1.0031, 1.0031, 1.0031, 1.0029, 1.0028,\n",
      "        1.0028], device='cuda:0')\n",
      "['wings' 'tokyo' 'plastic' 'coast' 'jul' 'japan' 'stereo' 'coastal'\n",
      " 'costa' 'ear']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 656\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0049, 0.0042, 0.0027, 0.0022, 0.0019, 0.0014, 0.0012, 0.0012, 0.0010,\n",
      "        0.0009], device='cuda:0')\n",
      "['ski' 'adopted' 'model' 'mouse' 'boxes' 'kits' 'pair' 'dakota' 'hunting'\n",
      " 'museum']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0094, 1.0087, 1.0085, 1.0084, 1.0081, 1.0081, 1.0079, 1.0078, 1.0077,\n",
      "        1.0077], device='cuda:0')\n",
      "['thailand' 'periods' 'stable' 'horses' 'oklahoma' 'southern' 'texas'\n",
      " 'highlights' 'broad' 'wells']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 665\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0041, 0.0028, 0.0017, 0.0014, 0.0011, 0.0008, 0.0008, 0.0008, 0.0005,\n",
      "        0.0005], device='cuda:0')\n",
      "['turkey' 'guinea' 'bears' 'adopted' 'bird' 'fucking' 'dakota' 'wing'\n",
      " 'mac' 'dogs']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0042, 1.0041, 1.0040, 1.0040, 1.0038, 1.0037, 1.0037, 1.0037, 1.0037,\n",
      "        1.0036], device='cuda:0')\n",
      "['buffalo' 'fly' 'wing' 'loading' 'wings' 'pittsburgh' 'black' 'pipe'\n",
      " 'tank' 'emissions']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 204\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0036, 0.0023, 0.0019, 0.0013, 0.0012, 0.0010, 0.0004, 0.0004, 0.0004,\n",
      "        0.0003], device='cuda:0')\n",
      "['mouse' 'golden' 'eagle' 'hairy' 'bird' 'douglas' 'buddy' 'seal'\n",
      " 'infection' 'model']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0057, 1.0047, 1.0046, 1.0044, 1.0040, 1.0040, 1.0039, 1.0038, 1.0038,\n",
      "        1.0038], device='cuda:0')\n",
      "['sf' 'wooden' 'edinburgh' 'bath' 'vancouver' 'model' 'mn' 'navy' 'rubber'\n",
      " 'scotland']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1692\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0056, 0.0032, 0.0031, 0.0020, 0.0015, 0.0012, 0.0012, 0.0008, 0.0007,\n",
      "        0.0007], device='cuda:0')\n",
      "['mouse' 'model' 'kits' 'guinea' 'dog' 'foster' 'bird' 'wing' 'mac'\n",
      " 'package']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0058, 1.0056, 1.0044, 1.0040, 1.0040, 1.0038, 1.0037, 1.0037, 1.0036,\n",
      "        1.0035], device='cuda:0')\n",
      "['arrival' 'switzerland' 'plug' 'cape' 'joint' 'proposal' 'button'\n",
      " 'ireland' 'usb' 'meeting']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 371\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0032, 0.0022, 0.0022, 0.0011, 0.0007, 0.0006, 0.0005, 0.0005, 0.0004,\n",
      "        0.0003], device='cuda:0')\n",
      "['eagle' 'dog' 'dakota' 'adopted' 'stick' 'milfhunter' 'char' 'doc' 'fl'\n",
      " 'apple']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0067, 1.0058, 1.0057, 1.0050, 1.0045, 1.0045, 1.0042, 1.0042, 1.0040,\n",
      "        1.0037], device='cuda:0')\n",
      "['fox' 'clinton' 'milwaukee' 'baltimore' 'jay' 'jordan' 'sublime' 'seal'\n",
      " 'campbell' 'indonesia']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1595\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001,\n",
      "        0.0001], device='cuda:0')\n",
      "['van' 'dicke' 'little' 'cock' 'glance' 'my' 'visitor' 'rear' 'spring'\n",
      " 'ma']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0026, 1.0021, 1.0020, 1.0018, 1.0018, 1.0017, 1.0017, 1.0017, 1.0017,\n",
      "        1.0017], device='cuda:0')\n",
      "['cocks' 'cock' 'papers' 'patrick' 'manchester' 'linux' 'cable'\n",
      " 'technology' 'fan' 'narrow']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2598\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0036, 0.0013, 0.0013, 0.0010, 0.0008, 0.0007, 0.0006, 0.0004, 0.0004,\n",
      "        0.0004], device='cuda:0')\n",
      "['turkey' 'model' 'bird' 'roof' 'wing' 'dakota' 'cock' 'buddy' 'doc'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0053, 1.0049, 1.0049, 1.0044, 1.0041, 1.0040, 1.0040, 1.0040, 1.0038,\n",
      "        1.0038], device='cuda:0')\n",
      "['lp' 'harry' 'prince' 'ed' 'rice' 'shock' 'cock' 'chicken' 'journey'\n",
      " 'steven']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 546\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0037, 0.0032, 0.0027, 0.0027, 0.0014, 0.0013, 0.0009, 0.0005, 0.0005,\n",
      "        0.0005], device='cuda:0')\n",
      "['mouse' 'guinea' 'purple' 'dolls' 'model' 'recipe' 'roof' 'pair' 'doc'\n",
      " 'male']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0057, 1.0056, 1.0052, 1.0052, 1.0052, 1.0052, 1.0051, 1.0049, 1.0047,\n",
      "        1.0043], device='cuda:0')\n",
      "['virgin' 'flash' 'vision' 'egypt' 'vermont' 'coffee' 'bulk' 'justice'\n",
      " 'comics' 'thousands']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 20\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0008, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.0002, 0.0002, 0.0001,\n",
      "        0.0001], device='cuda:0')\n",
      "['museum' 'pair' 'looking' 'la' 'cute' 'visitor' 'console' 'glance'\n",
      " 'berlin' 'thailand']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0022, 1.0022, 1.0021, 1.0021, 1.0019, 1.0019, 1.0019, 1.0019, 1.0019,\n",
      "        1.0019], device='cuda:0')\n",
      "['indonesia' 'fox' 'humor' 'driver' 'interested' 'beastiality'\n",
      " 'especially' 'responsibility' 'example' 'around']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 606\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0060, 0.0033, 0.0031, 0.0021, 0.0020, 0.0019, 0.0015, 0.0007, 0.0007,\n",
      "        0.0005], device='cuda:0')\n",
      "['dog' 'mouse' 'model' 'roof' 'hairy' 'adopted' 'eagle' 'golden' 'package'\n",
      " 'dogs']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0108, 1.0086, 1.0077, 1.0077, 1.0074, 1.0069, 1.0066, 1.0065, 1.0063,\n",
      "        1.0063], device='cuda:0')\n",
      "['switzerland' 'england' 'usd' 'lingerie' 'michael' 'churches' 'hawaii'\n",
      " 'fund' 'settlement' 'wealth']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2536\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0038, 0.0028, 0.0022, 0.0021, 0.0017, 0.0015, 0.0012, 0.0011, 0.0010,\n",
      "        0.0009], device='cuda:0')\n",
      "['mouse' 'dolls' 'eagle' 'hairy' 'debian' 'dakota' 'glance' 'model'\n",
      " 'foster' 'wing']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0059, 1.0056, 1.0055, 1.0049, 1.0049, 1.0047, 1.0046, 1.0046, 1.0045,\n",
      "        1.0045], device='cuda:0')\n",
      "['kong' 'lighting' 'vision' 'disney' 'blonde' 'lights' 'highlights'\n",
      " 'france' 'wave' 'strong']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 393\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0018, 0.0016, 0.0010, 0.0007, 0.0004, 0.0004, 0.0004, 0.0004, 0.0003,\n",
      "        0.0002], device='cuda:0')\n",
      "['dog' 'model' 'roof' 'turkey' 'doc' 'dicke' 'telecommunications' 'eagle'\n",
      " 'my' 'ma']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0044, 1.0040, 1.0038, 1.0035, 1.0034, 1.0033, 1.0032, 1.0032, 1.0031,\n",
      "        1.0031], device='cuda:0')\n",
      "['mit' 'finland' 'norway' 'netherlands' 'nl' 'und' 'scenes' 'switzerland'\n",
      " 'amsterdam' 'casino']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2726\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0027, 0.0026, 0.0015, 0.0014, 0.0009, 0.0008, 0.0005, 0.0005, 0.0004,\n",
      "        0.0004], device='cuda:0')\n",
      "['dolls' 'eating' 'boxes' 'hairy' 'package' 'stars' 'ski' 'guinea' 'dogs'\n",
      " 'rolling']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0044, 1.0040, 1.0038, 1.0037, 1.0036, 1.0035, 1.0033, 1.0032, 1.0032,\n",
      "        1.0030], device='cuda:0')\n",
      "['spain' 'split' 'miles' 'leave' 'nice' 'particular' 'sleep' 'jerry'\n",
      " 'rolling' 'catch']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2596\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0007, 0.0006, 0.0005, 0.0004, 0.0004, 0.0004, 0.0003, 0.0003, 0.0003,\n",
      "        0.0002], device='cuda:0')\n",
      "['adopted' 'pair' 'douglas' 'foster' 'turkey' 'eagle' 'depth' 'python'\n",
      " 'rolling' 'model']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0029, 1.0029, 1.0024, 1.0024, 1.0024, 1.0023, 1.0022, 1.0022, 1.0022,\n",
      "        1.0022], device='cuda:0')\n",
      "['portugal' 'shadow' 'jonathan' 'fr' 'anne' 'municipal' 'von' 'website'\n",
      " 'paint' 'diego']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 113\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0034, 0.0011, 0.0009, 0.0009, 0.0008, 0.0008, 0.0006, 0.0006, 0.0005,\n",
      "        0.0005], device='cuda:0')\n",
      "['eagle' 'recipe' 'museum' 'mac' 'fucking' 'polish' 'van' 'smile' 'golden'\n",
      " 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0062, 1.0057, 1.0056, 1.0056, 1.0055, 1.0054, 1.0053, 1.0052, 1.0051,\n",
      "        1.0050], device='cuda:0')\n",
      "['gay' 'xxx' 'taylor' 'basketball' 'nba' 'ba' 'mercury' 'bulgaria' 'harry'\n",
      " 'angel']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2773\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0017, 0.0010, 0.0007, 0.0003, 0.0003, 0.0003, 0.0002, 0.0001, 0.0001,\n",
      "        0.0001], device='cuda:0')\n",
      "['model' 'roof' 'dakota' 'milfhunter' 'pair' 'char' 'my' 'little' 'boxes'\n",
      " 'dicke']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0023, 1.0022, 1.0022, 1.0020, 1.0020, 1.0020, 1.0020, 1.0020, 1.0020,\n",
      "        1.0020], device='cuda:0')\n",
      "['von' 'palace' 'share' 'edge' 'clinton' 'finland' 'czech' 'planet'\n",
      " 'clicking' 'zum']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 478\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0008, 0.0007, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002, 0.0001, 0.0001,\n",
      "        0.0001], device='cuda:0')\n",
      "['dakota' 'package' 'buddy' 'stick' 'little' 'pussy' 'model' 'kits'\n",
      " 'golden' 'packages']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0016, 1.0016, 1.0016, 1.0015, 1.0015, 1.0015, 1.0015, 1.0015, 1.0014,\n",
      "        1.0013], device='cuda:0')\n",
      "['fred' 'little' 'floor' 'fig' 'pool' 'creek' 'lincoln' 'nearest' 'ray'\n",
      " 'neck']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 138\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0092, 0.0075, 0.0038, 0.0037, 0.0035, 0.0025, 0.0020, 0.0019, 0.0018,\n",
      "        0.0015], device='cuda:0')\n",
      "['roof' 'kits' 'agricultural' 'bird' 'cafe' 'flying' 'wing' 'berlin' 'box'\n",
      " 'lamp']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0271, 1.0248, 1.0231, 1.0229, 1.0227, 1.0221, 1.0220, 1.0219, 1.0217,\n",
      "        1.0214], device='cuda:0')\n",
      "['arrival' 'palm' 'bookmark' 'leaves' 'directions' 'aud' 'tennessee'\n",
      " 'signature' 'vietnam' 'heating']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 854\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0039, 0.0014, 0.0014, 0.0009, 0.0008, 0.0007, 0.0006, 0.0006, 0.0005,\n",
      "        0.0005], device='cuda:0')\n",
      "['hairy' 'adopted' 'volunteers' 'museum' 'eagle' 'tiger' 'sydney' 'dakota'\n",
      " 'pussy' 'chip']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0080, 1.0079, 1.0078, 1.0076, 1.0075, 1.0074, 1.0074, 1.0073, 1.0072,\n",
      "        1.0071], device='cuda:0')\n",
      "['height' 'chemistry' 'columns' 'counties' 'avg' 'tripadvisor'\n",
      " 'statistics' 'wells' 'sri' 'strategy']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2594\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0036, 0.0025, 0.0024, 0.0013, 0.0008, 0.0008, 0.0005, 0.0003, 0.0003,\n",
      "        0.0003], device='cuda:0')\n",
      "['mouse' 'dolls' 'dog' 'bird' 'tiger' 'mac' 'doc' 'toys' 'warm' 'dogs']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0044, 1.0039, 1.0039, 1.0038, 1.0038, 1.0037, 1.0035, 1.0034, 1.0034,\n",
      "        1.0033], device='cuda:0')\n",
      "['ie' 'http' 'euro' 'basket' 'loop' 'orlando' 'bell' 'blogger' 'belgium'\n",
      " 'bulgaria']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1839\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0020, 0.0013, 0.0010, 0.0007, 0.0003, 0.0002, 0.0002, 0.0002, 0.0001,\n",
      "        0.0001], device='cuda:0')\n",
      "['guinea' 'bird' 'adopted' 'watching' 'milfhunter' 'pussy' 'fighting'\n",
      " 'dick' 'little' 'row']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0028, 1.0028, 1.0028, 1.0025, 1.0023, 1.0023, 1.0022, 1.0022, 1.0021,\n",
      "        1.0020], device='cuda:0')\n",
      "['saw' 'it' 'monster' 'jason' 'iii' 'virus' 'elementary' 'plasma' 'jobs'\n",
      " 'infection']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1325\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0105, 0.0076, 0.0049, 0.0048, 0.0040, 0.0028, 0.0026, 0.0025, 0.0021,\n",
      "        0.0015], device='cuda:0')\n",
      "['guinea' 'mouse' 'bed' 'sequence' 'agriculture' 'pair' 'ball' 'box'\n",
      " 'eagle' 'rear']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0250, 1.0227, 1.0218, 1.0212, 1.0203, 1.0197, 1.0196, 1.0194, 1.0194,\n",
      "        1.0193], device='cuda:0')\n",
      "['victoria' 'cock' 'principal' 'posting' 'zealand' 'breast' 'breasts'\n",
      " 'managed' 'palm' 'elected']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2741\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0019, 0.0010, 0.0009, 0.0007, 0.0003, 0.0003, 0.0002, 0.0002, 0.0002,\n",
      "        0.0002], device='cuda:0')\n",
      "['eagle' 'sequence' 'museum' 'dakota' 'telecommunications' 'rail' 'little'\n",
      " 'milfhunter' 'bird' 'chip']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0018, 1.0016, 1.0015, 1.0015, 1.0015, 1.0015, 1.0015, 1.0015, 1.0014,\n",
      "        1.0014], device='cuda:0')\n",
      "['milfhunter' 'application' 'der' 'catch' 'proceedings' 'apparently'\n",
      " 'reservation' 'effect' 'desert' 'mom']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1405\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.0283, 0.0086, 0.0054, 0.0043, 0.0040, 0.0034, 0.0032, 0.0027, 0.0026,\n",
      "        0.0025], device='cuda:0')\n",
      "['eagle' 'guinea' 'apple' 'tea' 'python' 'table' 'dakota' 'model' 'ski'\n",
      " 'bird']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1.0266, 1.0253, 1.0236, 1.0230, 1.0226, 1.0218, 1.0218, 1.0210, 1.0208,\n",
      "        1.0200], device='cuda:0')\n",
      "['interracial' 'vhs' 'pool' 'rain' 'dildo' 'smoke' 'arizona' 'him' 'ebony'\n",
      " 'chile']\n",
      "============================ steering_strength: 5.0 ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/1562 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "655\n",
      "656\n",
      "665\n",
      "204\n",
      "1692\n",
      "371\n",
      "1595\n",
      "2598\n",
      "546\n",
      "20\n",
      "606\n",
      "2536\n",
      "393\n",
      "2726\n",
      "2596\n",
      "113\n",
      "2773\n",
      "478\n",
      "138\n",
      "854\n",
      "2594\n",
      "1839\n",
      "1325\n",
      "2741\n",
      "1405\n",
      "========================================================================================\n",
      "\n",
      "For Feature 655\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.2691, 0.2021, 0.2020, 0.1952, 0.1753, 0.1413, 0.1369, 0.1295, 0.1212,\n",
      "        0.0912], device='cuda:0')\n",
      "['dolls' 'eagle' 'fucking' 'hunting' 'mouse' 'roads' 'conservation'\n",
      " 'guinea' 'roof' 'links']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9.9347, 9.2574, 8.6827, 8.3259, 7.4986, 7.3675, 7.3523, 7.1602, 6.6852,\n",
      "        6.5630], device='cuda:0')\n",
      "['rss' 'wholesale' 'xxx' 'bags' 'ministry' 'agreements' 'bonds' 'links'\n",
      " 'attendance' 'availability']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 656\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3895, 0.2026, 0.1828, 0.1748, 0.1731, 0.1517, 0.1481, 0.1441, 0.1365,\n",
      "        0.1248], device='cuda:0')\n",
      "['dog' 'purple' 'apple' 'lamp' 'flying' 'bowl' 'eating' 'green' 'box'\n",
      " 'van']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([10.4900,  9.3632,  7.2179,  6.9583,  6.7874,  6.5587,  6.3812,  6.3294,\n",
      "         6.1938,  5.9639], device='cuda:0')\n",
      "['winter' 'nature' 'rain' 'snow' 'germany' 'fall' 'norway' 'denmark'\n",
      " 'outdoor' 'art']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 665\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6596, 0.3603, 0.2596, 0.1925, 0.1515, 0.1442, 0.1258, 0.1213, 0.1162,\n",
      "        0.1086], device='cuda:0')\n",
      "['cute' 'debian' 'telecommunications' 'flying' 'roof' 'dog' 'bowl' 'hairy'\n",
      " 'mouse' 'hunting']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([13.8255, 11.9977, 10.0858,  9.3897,  9.2010,  8.9149,  8.7801,  8.4478,\n",
      "         8.3896,  8.2891], device='cuda:0')\n",
      "['cookies' 'dvds' 'chocolate' 'chinese' 'clothes' 'debian' 'disney'\n",
      " 'pants' 'anime' 'processor']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 204\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.2393, 0.2096, 0.1701, 0.1561, 0.1436, 0.1429, 0.1110, 0.0996, 0.0899,\n",
      "        0.0864], device='cuda:0')\n",
      "['guinea' 'construction' 'tea' 'debian' 'roof' 'dog' 'hunting' 'boxes'\n",
      " 'furniture' 'dogs']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9.7133, 8.8522, 8.8258, 8.2563, 7.4866, 7.4791, 7.2997, 7.2235, 7.1298,\n",
      "        7.0300], device='cuda:0')\n",
      "['dreams' 'chairs' 'depression' 'norway' 'thoughts' 'risks' 'alone'\n",
      " 'header' 'healing' 'atmosphere']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1692\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.2350, 0.1797, 0.1751, 0.1357, 0.1343, 0.1142, 0.1097, 0.1079, 0.1034,\n",
      "        0.0940], device='cuda:0')\n",
      "['detail' 'roads' 'dolls' 'flying' 'boxes' 'tiger' 'dog' 'birds' 'apple'\n",
      " 'structural']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([14.1886, 13.8385, 12.2383, 10.2633,  9.5564,  9.4824,  8.7129,  8.6175,\n",
      "         8.4874,  8.4054], device='cuda:0')\n",
      "['trucks' 'band' 'farmers' 'studies' 'heads' 'bands' 'yard' 'horses'\n",
      " 'creek' 'brothers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 371\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3870, 0.3548, 0.3449, 0.2782, 0.2413, 0.2171, 0.2090, 0.1613, 0.1416,\n",
      "        0.1359], device='cuda:0')\n",
      "['bed' 'roof' 'dog' 'purple' 'flying' 'apple' 'hairy' 'table' 'mouse'\n",
      " 'dogs']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([6.6571, 6.0187, 5.6395, 5.3890, 5.1122, 4.9164, 4.7281, 4.6256, 4.6117,\n",
      "        4.3993], device='cuda:0')\n",
      "['bed' 'beds' 'displays' 'videos' 'sign' 'sitemap' 'display' 'food'\n",
      " 'video' 'furniture']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1595\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.1991, 0.1931, 0.1642, 0.1567, 0.1162, 0.0927, 0.0774, 0.0742, 0.0720,\n",
      "        0.0637], device='cuda:0')\n",
      "['shooting' 'model' 'pair' 'bears' 'van' 'wing' 'dog' 'flying' 'finished'\n",
      " 'agricultural']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([8.3108, 7.8744, 7.7435, 7.1763, 6.0041, 5.6787, 5.1456, 5.0671, 4.9932,\n",
      "        4.9871], device='cuda:0')\n",
      "['forecast' 'rain' 'flood' 'hurricane' 'protect' 'accept' 'weather'\n",
      " 'overseas' 'cumshots' 'lp']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2598\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3944, 0.3729, 0.3647, 0.3511, 0.2648, 0.2522, 0.2299, 0.1981, 0.1882,\n",
      "        0.1662], device='cuda:0')\n",
      "['mouse' 'python' 'dog' 'model' 'eagle' 'hunting' 'van' 'table' 'tea'\n",
      " 'flying']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([6.6682, 6.4613, 6.0120, 5.8739, 5.7574, 5.7189, 5.5762, 5.0640, 4.9814,\n",
      "        4.9632], device='cuda:0')\n",
      "['fishing' 'motorcycle' 'worker' 'model' 'present' 'editing' 'seller'\n",
      " 'apartment' 'proposed' 'sugar']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 546\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5275, 0.2940, 0.1517, 0.1405, 0.1300, 0.1250, 0.1043, 0.1031, 0.0968,\n",
      "        0.0798], device='cuda:0')\n",
      "['dog' 'roof' 'table' 'hairy' 'sequence' 'agricultural' 'male' 'epinions'\n",
      " 'bears' 'van']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([8.3049, 8.3036, 8.1825, 7.2768, 7.1266, 6.2177, 5.8037, 5.6753, 5.5758,\n",
      "        5.5523], device='cuda:0')\n",
      "['ron' 'dean' 'andy' 'taken' 'it' 'andrew' 'logic' 'wells' 'frank' 'dan']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 20\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3362, 0.2689, 0.1682, 0.1630, 0.1588, 0.1481, 0.1306, 0.1291, 0.1214,\n",
      "        0.1113], device='cuda:0')\n",
      "['tea' 'vehicle' 'boxes' 'debian' 'van' 'cup' 'ski' 'guinea' 'volunteers'\n",
      " 'cute']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9.3453, 6.9268, 6.4101, 6.2942, 5.8328, 5.6200, 5.3318, 5.1995, 4.9864,\n",
      "        4.5220], device='cuda:0')\n",
      "['shirts' 'clothes' 'bondage' 'coupons' 'supplies' 'clothing' 'shirt'\n",
      " 'ingredients' 'photo' 'casinos']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 606\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.4188, 0.3877, 0.3269, 0.2868, 0.2793, 0.2532, 0.1839, 0.1635, 0.1274,\n",
      "        0.1179], device='cuda:0')\n",
      "['roof' 'ray' 'van' 'dog' 'guinea' 'bears' 'boxes' 'hunting' 'mining'\n",
      " 'mouse']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7.3113, 5.0222, 4.8676, 4.7610, 4.7211, 4.5364, 4.4964, 4.4726, 4.3782,\n",
      "        4.3161], device='cuda:0')\n",
      "['owners' 'suppliers' 'xxx' 'bears' 'garden' 'labs' 'publisher' 'themes'\n",
      " 'gardens' 'bedroom']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2536\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3179, 0.2959, 0.2881, 0.2271, 0.2002, 0.1231, 0.1123, 0.1079, 0.1064,\n",
      "        0.1007], device='cuda:0')\n",
      "['flying' 'roads' 'dolls' 'cute' 'kits' 'cup' 'boxes' 'tea' 'stars'\n",
      " 'furniture']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([8.0435, 6.3278, 6.2449, 6.1248, 6.0969, 5.9097, 5.4608, 5.3423, 5.2846,\n",
      "        5.2592], device='cuda:0')\n",
      "['chair' 'seat' 'seats' 'chairs' 'santa' 'farmers' 'canadian' 'canada'\n",
      " 'seed' 'pharmacy']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 393\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3055, 0.2203, 0.2076, 0.1865, 0.1630, 0.1396, 0.1194, 0.1012, 0.0863,\n",
      "        0.0839], device='cuda:0')\n",
      "['pair' 'hunting' 'purple' 'python' 'agricultural' 'dog' 'globe' 'mac'\n",
      " 'mouse' 'seal']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([5.0637, 4.6347, 4.6069, 4.5619, 4.5164, 4.4111, 4.3817, 4.3778, 4.3670,\n",
      "        4.2578], device='cuda:0')\n",
      "['aug' 'historic' 'font' 'birmingham' 'athletic' 'printable' 'santa'\n",
      " 'stable' 'patrick' 'desktops']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2726\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5197, 0.2992, 0.2750, 0.2368, 0.2351, 0.2027, 0.1972, 0.1873, 0.1576,\n",
      "        0.1571], device='cuda:0')\n",
      "['bears' 'apple' 'dolls' 'boxes' 'seal' 'cute' 'volunteers' 'roads' 'bowl'\n",
      " 'debian']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9.5004, 8.6070, 7.5400, 7.2566, 6.6513, 6.1159, 5.7911, 5.6206, 5.5315,\n",
      "        5.5205], device='cuda:0')\n",
      "['soldiers' 'officers' 'disclosure' 'bands' 'finland' 'posters' 'teens'\n",
      " 'avatar' 'displays' 'representatives']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2596\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.2683, 0.1810, 0.1798, 0.1791, 0.1025, 0.1018, 0.0970, 0.0888, 0.0872,\n",
      "        0.0810], device='cuda:0')\n",
      "['shooting' 'dog' 'dolls' 'turkey' 'exhibit' 'nsw' 'ski' 'sub' 'nz'\n",
      " 'models']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([10.9452, 10.1197,  9.5869,  8.8775,  8.8003,  7.8007,  7.7891,  7.3548,\n",
      "         7.2639,  7.2562], device='cuda:0')\n",
      "['putting' 'saw' 'bands' 'presents' 'shoe' 'reporter' 'bags' 'elections'\n",
      " 'greek' 'proposal']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 113\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.4181, 0.3259, 0.2451, 0.2149, 0.1770, 0.1574, 0.1276, 0.1165, 0.1159,\n",
      "        0.1074], device='cuda:0')\n",
      "['python' 'dog' 'mouse' 'bears' 'vehicle' 'structural' 'model' 'mit'\n",
      " 'hairy' 'cute']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7.4852, 7.2984, 6.1887, 6.0589, 5.6836, 5.6055, 5.4979, 5.3556, 5.3333,\n",
      "        5.2677], device='cuda:0')\n",
      "['alaska' 'html' 'cotton' 'xml' 'patent' 'seattle' 'tissue' 'clothing'\n",
      " 'phentermine' 'denver']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2773\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.2387, 0.2290, 0.2239, 0.1970, 0.1831, 0.1487, 0.1243, 0.1206, 0.1066,\n",
      "        0.0936], device='cuda:0')\n",
      "['flying' 'dolls' 'museum' 'vehicle' 'turkey' 'mit' 'ski' 'tea' 'visitor'\n",
      " 'roof']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([10.0580,  8.8930,  6.8734,  6.0344,  6.0008,  5.9331,  5.7751,  5.7110,\n",
      "         5.6935,  5.6759], device='cuda:0')\n",
      "['hospital' 'meter' 'hospitals' 'path' 'schools' 'sensor' 'broadband'\n",
      " 'building' 'profiles' 'swimming']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 478\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5057, 0.4465, 0.3189, 0.2602, 0.2367, 0.2100, 0.2096, 0.1730, 0.1491,\n",
      "        0.1409], device='cuda:0')\n",
      "['python' 'roof' 'dog' 'bowl' 'furniture' 'hunting' 'guinea' 'mouse'\n",
      " 'flying' 'turkey']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([10.1992,  9.9171,  9.7239,  9.6198,  7.8151,  7.7271,  7.6735,  7.6709,\n",
      "         7.4986,  7.4378], device='cuda:0')\n",
      "['appliances' 'supplements' 'batteries' 'dvds' 'frames' 'patches' 'bureau'\n",
      " 'programmes' 'directories' 'printers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 138\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.8127, 0.6922, 0.5184, 0.2889, 0.2850, 0.2754, 0.2634, 0.2597, 0.2302,\n",
      "        0.2061], device='cuda:0')\n",
      "['guinea' 'dog' 'dogs' 'table' 'roof' 'eagle' 'dolls' 'debian' 'roads'\n",
      " 'fucking']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7.8016, 6.5678, 5.9929, 5.5980, 5.5717, 5.3979, 5.0615, 5.0297, 5.0154,\n",
      "        4.9870], device='cuda:0')\n",
      "['dogs' 'mississippi' 'balls' 'boobs' 'women' 'foods' 'horses' 'couples'\n",
      " 'womens' 'seattle']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 854\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.4203, 0.3010, 0.2699, 0.1726, 0.1666, 0.1628, 0.1390, 0.1346, 0.1292,\n",
      "        0.1196], device='cuda:0')\n",
      "['roof' 'van' 'flying' 'mit' 'volunteers' 'seal' 'bowl' 'debian' 'foster'\n",
      " 'purple']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9.7127, 7.1175, 6.3721, 6.3494, 6.3101, 6.1584, 5.9534, 5.9420, 5.8442,\n",
      "        5.8413], device='cuda:0')\n",
      "['finder' 'tiffany' 'limousines' 'feet' 'foot' 'thompson' 'michael'\n",
      " 'thongs' 'guestbook' 'receipt']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2594\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5963, 0.2457, 0.2242, 0.1447, 0.1422, 0.0939, 0.0894, 0.0873, 0.0839,\n",
      "        0.0719], device='cuda:0')\n",
      "['pair' 'detail' 'flying' 'dolls' 'ski' 'dog' 'cute' 'apple' 'watching'\n",
      " 'agricultural']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([11.4231,  9.4457,  9.1441,  8.1254,  7.9307,  7.7174,  7.4266,  7.2835,\n",
      "         7.2672,  7.2067], device='cuda:0')\n",
      "['delaware' 'maryland' 'vermont' 'tennessee' 'cars' 'mississippi' 'wv'\n",
      " 'philadelphia' 'nj' 'ipod']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1839\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3163, 0.3131, 0.2951, 0.2642, 0.1695, 0.1550, 0.1226, 0.1210, 0.1064,\n",
      "        0.1020], device='cuda:0')\n",
      "['roof' 'turkey' 'flying' 'bowl' 'sequence' 'ray' 'rolling' 'pair'\n",
      " 'volunteers' 'debian']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9.1559, 8.4764, 5.7373, 5.5291, 5.3275, 5.2980, 5.2775, 5.2722, 5.2029,\n",
      "        5.1828], device='cuda:0')\n",
      "['tripadvisor' 'swimming' 'publisher' 'supplies' 'subscription' 'coupons'\n",
      " 'magazines' 'library' 'sex' 'sugar']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1325\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.2788, 0.2239, 0.2079, 0.1766, 0.1706, 0.1656, 0.1619, 0.1356, 0.1268,\n",
      "        0.1171], device='cuda:0')\n",
      "['python' 'eagle' 'mit' 'ski' 'van' 'furniture' 'guinea' 'tea' 'tiny'\n",
      " 'bed']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9.7172, 8.4539, 8.1075, 7.3688, 6.8963, 6.8840, 6.8345, 6.1652, 6.0873,\n",
      "        6.0251], device='cuda:0')\n",
      "['appliances' 'speakers' 'guitar' 'speaker' 'radio' 'shirts' 'developer'\n",
      " 'music' 'shorts' 'amp']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2741\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3727, 0.2938, 0.2072, 0.1808, 0.1786, 0.1653, 0.1489, 0.1417, 0.1332,\n",
      "        0.1193], device='cuda:0')\n",
      "['dolls' 'dog' 'dogs' 'vehicle' 'trembl' 'purple' 'golden' 'epinions'\n",
      " 'cute' 'eagle']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7.1158, 7.0918, 6.3463, 5.9236, 5.9048, 5.8025, 5.7327, 5.6534, 5.6445,\n",
      "        5.6187], device='cuda:0')\n",
      "['owners' 'banner' 'ireland' 'vehicles' 'logos' 'wyoming' 'surgery'\n",
      " 'sitemap' 'engineers' 'guides']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1405\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.4748, 0.2874, 0.2385, 0.1793, 0.1456, 0.1384, 0.1022, 0.1008, 0.0990,\n",
      "        0.0844], device='cuda:0')\n",
      "['hairy' 'python' 'fucking' 'box' 'flying' 'turkey' 'max' 'agricultural'\n",
      " 'watching' 'recipe']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7.5585, 7.1110, 6.3872, 5.8709, 5.7512, 5.3808, 5.2873, 5.2415, 5.2408,\n",
      "        5.0348], device='cuda:0')\n",
      "['bruce' 'dublin' 'ordering' 'ireland' 'payments' 'dean' 'contract'\n",
      " 'dinner' 'printer' 'payment']\n",
      "============================ steering_strength: 10.0 ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/1562 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "655\n",
      "656\n",
      "665\n",
      "204\n",
      "1692\n",
      "371\n",
      "1595\n",
      "2598\n",
      "546\n",
      "20\n",
      "606\n",
      "2536\n",
      "393\n",
      "2726\n",
      "2596\n",
      "113\n",
      "2773\n",
      "478\n",
      "138\n",
      "854\n",
      "2594\n",
      "1839\n",
      "1325\n",
      "2741\n",
      "1405\n",
      "========================================================================================\n",
      "\n",
      "For Feature 655\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.7553, 0.4588, 0.3161, 0.2988, 0.2679, 0.2637, 0.2534, 0.1784, 0.1771,\n",
      "        0.1624], device='cuda:0')\n",
      "['conservation' 'dolls' 'eagle' 'felt' 'purple' 'hunting' 'links' 'bowl'\n",
      " 'bears' 'fucking']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([151.7220, 125.4206, 107.7547,  85.9695,  78.0027,  75.9435,  68.4573,\n",
      "         65.8482,  62.8024,  59.7922], device='cuda:0')\n",
      "['bags' 'rss' 'xxx' 'wholesale' 'laptops' 'bonds' 'agreements'\n",
      " 'contractors' 'brands' 'offers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 656\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.9691, 0.4783, 0.3911, 0.3085, 0.2248, 0.2230, 0.2130, 0.2035, 0.2005,\n",
      "        0.1889], device='cuda:0')\n",
      "['dog' 'purple' 'green' 'flying' 'cup' 'box' 'pet' 'photo' 'baby' 'snow']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([220.3217, 108.8515,  95.6880,  84.2925,  84.0210,  82.0098,  74.5375,\n",
      "         68.1416,  64.0585,  63.1478], device='cuda:0')\n",
      "['winter' 'snow' 'nature' 'rain' 'germany' 'art' 'professional' 'outdoor'\n",
      " 'outdoors' 'sweden']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 665\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5947, 0.5451, 0.5112, 0.4233, 0.3840, 0.2483, 0.2320, 0.1728, 0.1308,\n",
      "        0.1233], device='cuda:0')\n",
      "['cute' 'telecommunications' 'hunting' 'flying' 'dog' 'debian' 'dogs'\n",
      " 'stars' 'agriculture' 'ski']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([418.9670, 285.8240, 209.1577, 166.3105, 162.3210, 137.7953, 126.0355,\n",
      "        121.4053, 113.9713, 110.9642], device='cuda:0')\n",
      "['cookies' 'chocolate' 'clothes' 'dvds' 'lingerie' 'thailand' 'korea'\n",
      " 'pants' 'clothing' 'chinese']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 204\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.4266, 0.3295, 0.2571, 0.2454, 0.2433, 0.1959, 0.1903, 0.1716, 0.1678,\n",
      "        0.1528], device='cuda:0')\n",
      "['construction' 'dog' 'dogs' 'ocean' 'sleep' 'conservation' 'roof'\n",
      " 'freedom' 'agriculture' 'cup']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([163.3556, 118.0636,  81.6757,  77.8259,  74.9845,  71.5306,  68.1839,\n",
      "         67.2919,  66.7808,  64.2493], device='cuda:0')\n",
      "['quotes' 'dreams' 'risks' 'quote' 'depression' 'healing' 'mental'\n",
      " 'wallpapers' 'norway' 'chairs']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1692\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3234, 0.3010, 0.2890, 0.2868, 0.2857, 0.2576, 0.2461, 0.2280, 0.2034,\n",
      "        0.1989], device='cuda:0')\n",
      "['roads' 'trailer' 'birds' 'dolls' 'flying' 'dogs' 'installation' 'border'\n",
      " 'dog' 'balls']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([938.6978, 184.7863, 164.4205, 137.5851, 131.6121, 126.3527, 110.7976,\n",
      "         92.7018,  84.9288,  81.6822], device='cuda:0')\n",
      "['trucks' 'band' 'horses' 'farmers' 'cats' 'truck' 'bands' 'studies'\n",
      " 'boobs' 'dogs']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 371\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6001, 0.5486, 0.4900, 0.4532, 0.4446, 0.3443, 0.3242, 0.2851, 0.2487,\n",
      "        0.2367], device='cuda:0')\n",
      "['dog' 'bed' 'purple' 'flying' 'roof' 'apple' 'vehicle' 'hairy' 'bowl'\n",
      " 'furniture']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([57.4092, 45.8910, 43.4229, 39.7725, 31.3178, 31.0582, 29.9716, 27.4555,\n",
      "        26.9913, 26.7762], device='cuda:0')\n",
      "['bed' 'chocolate' 'displays' 'beds' 'display' 'food' 'sign' 'furniture'\n",
      " 'videos' 'catalog']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1595\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.3823, 0.3162, 0.3009, 0.2474, 0.2240, 0.2011, 0.2003, 0.1878, 0.1387,\n",
      "        0.1318], device='cuda:0')\n",
      "['dog' 'bears' 'hurricane' 'pet' 'finished' 'dogs' 'shooting' 'birth'\n",
      " 'van' 'wing']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([183.0992,  97.7350,  89.8685,  72.9608,  55.3747,  52.9744,  50.9151,\n",
      "         49.9593,  48.4700,  46.8618], device='cuda:0')\n",
      "['forecast' 'hurricane' 'weather' 'rain' 'wedding' 'accept' 'disaster'\n",
      " 'debate' 'protect' 'flood']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2598\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.8944, 0.8345, 0.5429, 0.5011, 0.4680, 0.4644, 0.3820, 0.2907, 0.2890,\n",
      "        0.2555], device='cuda:0')\n",
      "['dog' 'model' 'mouse' 'van' 'cup' 'eagle' 'hunting' 'flying' 'python'\n",
      " 'cute']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([74.5134, 45.1854, 41.4989, 40.1296, 36.8329, 36.6112, 34.4006, 33.7483,\n",
      "        33.6590, 32.8618], device='cuda:0')\n",
      "['motorcycle' 'attorney' 'contractors' 'fishing' 'seller' 'worker'\n",
      " 'cleaning' 'navy' 'model' 'contractor']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 546\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0716, 0.4733, 0.4346, 0.3060, 0.2889, 0.2381, 0.1975, 0.1750, 0.1387,\n",
      "        0.1319], device='cuda:0')\n",
      "['dog' 'roof' 'jerry' 'bears' 'table' 'conservation' 'agricultural' 'huge'\n",
      " 'bowl' 'van']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([125.7077,  90.2343,  87.8008,  84.6239,  76.6833,  64.6207,  54.9347,\n",
      "         45.0671,  44.1320,  38.7537], device='cuda:0')\n",
      "['dean' 'ron' 'taken' 'andy' 'it' 'logic' 'quotes' 'frank' 'arrival'\n",
      " 'credits']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 20\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.9215, 0.3421, 0.3204, 0.2787, 0.2771, 0.2398, 0.2232, 0.1893, 0.1882,\n",
      "        0.1879], device='cuda:0')\n",
      "['vehicle' 'cup' 'dogs' 'photo' 'milfhunter' 'roof' 'dog' 'boxes'\n",
      " 'structural' 'flying']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([142.3438, 113.8814,  93.4901,  72.3085,  63.0251,  49.5853,  49.0285,\n",
      "         40.7438,  36.2199,  33.9522], device='cuda:0')\n",
      "['shirts' 'clothes' 'clothing' 'supplies' 'coupons' 'shirt' 'ingredients'\n",
      " 'materials' 'contractors' 'cocks']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 606\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.9907, 0.6121, 0.5578, 0.3594, 0.3347, 0.2656, 0.2397, 0.2396, 0.1954,\n",
      "        0.1885], device='cuda:0')\n",
      "['bears' 'dog' 'van' 'roof' 'guinea' 'bowl' 'mining' 'boxes' 'agriculture'\n",
      " 'ray']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([167.0219,  93.1313,  68.7219,  54.0706,  53.7295,  50.6136,  49.5682,\n",
      "         44.8435,  43.8736,  43.5958], device='cuda:0')\n",
      "['owners' 'bears' 'spa' 'gardens' 'suppliers' 'garden' 'bedroom' 'themes'\n",
      " 'resorts' 'collections']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2536\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6181, 0.6072, 0.4744, 0.4283, 0.3688, 0.2938, 0.2304, 0.2252, 0.2219,\n",
      "        0.2023], device='cuda:0')\n",
      "['flying' 'roads' 'dolls' 'cute' 'stars' 'farmers' 'cup' 'tiny' 'antiques'\n",
      " 'pet']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([65.6908, 59.1684, 57.4377, 54.2144, 49.2652, 46.4581, 46.1257, 43.6012,\n",
      "        42.3179, 41.5782], device='cuda:0')\n",
      "['farmers' 'bear' 'logic' 'memorial' 'chair' 'pharmacy' 'art' 'motorcycle'\n",
      " 'wishlist' 'santa']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 393\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.4205, 0.3381, 0.3320, 0.2830, 0.2711, 0.2481, 0.2231, 0.2038, 0.1523,\n",
      "        0.1381], device='cuda:0')\n",
      "['pair' 'dog' 'flying' 'purple' 'hunting' 'agricultural' 'mac' 'roof'\n",
      " 'globe' 'python']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([44.0712, 43.2336, 40.2017, 39.6622, 33.0747, 29.9741, 28.7056, 28.0685,\n",
      "        25.1394, 25.1297], device='cuda:0')\n",
      "['aug' 'et' 'patrick' 'santa' 'wallpapers' 'churches' 'stupid' 'gcc'\n",
      " 'virginia' 'desktops']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2726\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.8097, 0.4804, 0.4661, 0.3228, 0.3137, 0.2792, 0.2723, 0.2627, 0.2296,\n",
      "        0.2288], device='cuda:0')\n",
      "['bears' 'dolls' 'bowl' 'shared' 'cute' 'seal' 'boxes' 'apple' 'debian'\n",
      " 'dogs']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([256.2422, 195.0085, 187.3598, 134.0204, 116.0236, 111.8022,  83.7331,\n",
      "         78.4502,  75.8637,  70.7495], device='cuda:0')\n",
      "['soldiers' 'bands' 'officers' 'posters' 'teens' 'bears' 'disclosure'\n",
      " 'army' 'guides' 'cats']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2596\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.7166, 0.3856, 0.3830, 0.3518, 0.2352, 0.1841, 0.1809, 0.1774, 0.1755,\n",
      "        0.1666], device='cuda:0')\n",
      "['dog' 'models' 'shooting' 'dolls' 'scale' 'exhibit' 'turkey' 'nsw' 'ski'\n",
      " 'fl']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([187.1563, 148.0328, 116.3333,  93.8572,  92.7846,  84.5225,  80.6200,\n",
      "         78.4121,  77.5725,  74.6776], device='cuda:0')\n",
      "['bands' 'weight' 'tennessee' 'football' 'reporter' 'putting' 'vs' 'shoe'\n",
      " 'soccer' 'greek']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 113\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6548, 0.5923, 0.4358, 0.3934, 0.2915, 0.2727, 0.1935, 0.1919, 0.1708,\n",
      "        0.1595], device='cuda:0')\n",
      "['dog' 'python' 'cute' 'bears' 'vehicle' 'mouse' 'structural' 'flying'\n",
      " 'hairy' 'adult']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([136.7664,  78.1775,  60.5248,  56.7834,  56.5326,  56.3114,  54.2098,\n",
      "         51.1474,  41.7656,  41.5724], device='cuda:0')\n",
      "['alaska' 'seattle' 'html' 'patent' 'clothing' 'airlines' 'denver'\n",
      " 'cotton' 'phentermine' 'pubmed']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2773\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5993, 0.2938, 0.2887, 0.2729, 0.2686, 0.2359, 0.2243, 0.1984, 0.1952,\n",
      "        0.1723], device='cuda:0')\n",
      "['flying' 'vehicle' 'dolls' 'museum' 'python' 'dog' 'roof' 'tea' 'visitor'\n",
      " 'wildlife']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([74.7531, 71.1079, 70.1079, 66.1550, 63.3704, 62.3255, 62.1338, 60.3701,\n",
      "        59.5846, 59.2894], device='cuda:0')\n",
      "['meter' 'building' 'hospital' 'websites' 'schools' 'buildings'\n",
      " 'hospitals' 'recipes' 'textbooks' 'universities']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 478\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.8818, 0.7703, 0.5355, 0.5146, 0.3798, 0.2839, 0.2308, 0.2263, 0.1565,\n",
      "        0.1336], device='cuda:0')\n",
      "['dog' 'python' 'roof' 'furniture' 'bowl' 'hunting' 'toys' 'flying' 'wing'\n",
      " 'dogs']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([199.8689, 141.0154, 127.4418, 126.4416, 120.7216, 117.9644, 114.6974,\n",
      "        100.3255,  96.4332,  95.8583], device='cuda:0')\n",
      "['appliances' 'spyware' 'dvds' 'printers' 'supplements' 'publishing'\n",
      " 'publications' 'directories' 'frames' 'magazines']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 138\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.2001, 1.0182, 0.9233, 0.5244, 0.4720, 0.4212, 0.3379, 0.2694, 0.2533,\n",
      "        0.2527], device='cuda:0')\n",
      "['dogs' 'guinea' 'dog' 'fucking' 'bowl' 'roads' 'dolls' 'roof' 'purple'\n",
      " 'eagle']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([125.5808,  68.1131,  63.8440,  63.0322,  55.9693,  53.1196,  51.6311,\n",
      "         48.4565,  42.7768,  38.8493], device='cuda:0')\n",
      "['dogs' 'foods' 'womens' 'supplements' 'women' 'balls' 'boobs' 'sizes'\n",
      " 'dog' 'mississippi']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 854\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6770, 0.6273, 0.5027, 0.3924, 0.3416, 0.3277, 0.2359, 0.1858, 0.1787,\n",
      "        0.1409], device='cuda:0')\n",
      "['roof' 'flying' 'van' 'bowl' 'seal' 'foster' 'purple' 'thongs' 'helping'\n",
      " 'agricultural']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([199.3047,  86.7993,  53.7419,  49.9360,  45.4681,  45.2375,  43.1697,\n",
      "         43.1043,  42.0372,  41.8091], device='cuda:0')\n",
      "['finder' 'receipt' 'thongs' 'tiffany' 'editors' 'thompson' 'feet'\n",
      " 'guestbook' 'firefox' 'michael']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2594\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.9051, 0.4994, 0.3109, 0.2188, 0.2072, 0.1586, 0.1576, 0.1374, 0.1265,\n",
      "        0.1228], device='cuda:0')\n",
      "['pair' 'flying' 'dog' 'ski' 'dolls' 'cute' 'watching' 'apple' 'camping'\n",
      " 'gulf']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([121.2797, 118.3252, 104.6937,  97.9054,  95.2319,  79.6301,  78.9156,\n",
      "         70.0628,  65.0615,  60.7301], device='cuda:0')\n",
      "['delaware' 'maryland' 'nj' 'tennessee' 'vermont' 'wv' 'mississippi'\n",
      " 'wallpaper' 'bookmark' 'bands']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1839\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6116, 0.4668, 0.4661, 0.3085, 0.2794, 0.2721, 0.2375, 0.2002, 0.1977,\n",
      "        0.1913], device='cuda:0')\n",
      "['flying' 'turkey' 'roof' 'sequence' 'bowl' 'bears' 'fucking' 'dolls'\n",
      " 'dakota' 'volunteers']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([123.2107,  69.8377,  59.4428,  55.0140,  40.8291,  39.0983,  36.8131,\n",
      "         35.8207,  35.2807,  33.7654], device='cuda:0')\n",
      "['tripadvisor' 'library' 'publisher' 'swimming' 'magazines' 'breakfast'\n",
      " 'supplies' 'sugar' 'pollution' 'bread']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1325\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5768, 0.3328, 0.3168, 0.3124, 0.3016, 0.2999, 0.2674, 0.2545, 0.2374,\n",
      "        0.2365], device='cuda:0')\n",
      "['python' 'roof' 'bears' 'furniture' 'sub' 'sheet' 'milfhunter' 'dog'\n",
      " 'ski' 'tea']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([236.8499, 200.5693, 174.4744, 117.4328, 100.6422,  86.8254,  79.6543,\n",
      "         77.2537,  76.0843,  71.6887], device='cuda:0')\n",
      "['speakers' 'appliances' 'guitar' 'speaker' 'music' 'logic' 'radio' 'bags'\n",
      " 'amp' 'audio']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2741\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.4968, 0.4937, 0.4829, 0.4343, 0.3455, 0.3350, 0.3040, 0.2691, 0.2380,\n",
      "        0.2187], device='cuda:0')\n",
      "['dogs' 'purple' 'dog' 'dolls' 'epinions' 'trembl' 'cute' 'swimming'\n",
      " 'vehicle' 'guides']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([174.8266, 153.1283, 114.5181,  97.7111,  83.2644,  82.2387,  78.0318,\n",
      "         76.9777,  74.8739,  71.9711], device='cuda:0')\n",
      "['owners' 'wyoming' 'ireland' 'wales' 'nebraska' 'careers' 'vermont'\n",
      " 'surgery' 'kentucky' 'engineers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1405\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.8699, 0.4379, 0.3960, 0.3623, 0.3288, 0.2811, 0.2193, 0.1900, 0.1835,\n",
      "        0.1465], device='cuda:0')\n",
      "['hairy' 'python' 'fucking' 'flying' 'box' 'bears' 'breakfast' 'toys'\n",
      " 'watching' 'agricultural']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([47.8839, 39.1483, 38.6751, 38.0194, 36.8647, 36.4497, 35.1388, 33.8856,\n",
      "        33.8450, 31.8766], device='cuda:0')\n",
      "['bruce' 'dublin' 'met' 'ireland' 'fig' 'holidays' 'scotland' 'parliament'\n",
      " 'edinburgh' 'dean']\n",
      "============================ steering_strength: 20.0 ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/1562 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "655\n",
      "656\n",
      "665\n",
      "204\n",
      "1692\n",
      "371\n",
      "1595\n",
      "2598\n",
      "546\n",
      "20\n",
      "606\n",
      "2536\n",
      "393\n",
      "2726\n",
      "2596\n",
      "113\n",
      "2773\n",
      "478\n",
      "138\n",
      "854\n",
      "2594\n",
      "1839\n",
      "1325\n",
      "2741\n",
      "1405\n",
      "========================================================================================\n",
      "\n",
      "For Feature 655\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5076, 0.9779, 0.5841, 0.5067, 0.4517, 0.3758, 0.3481, 0.3283, 0.2997,\n",
      "        0.2826], device='cuda:0')\n",
      "['conservation' 'felt' 'dogs' 'dolls' 'pottery' 'links' 'verzeichnis'\n",
      " 'binding' 'firefox' 'bears']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([8509.5391, 4772.6172, 3600.7678, 2715.4761, 2267.6716, 2256.8306,\n",
      "        2235.0500, 2172.0049, 2153.6301, 2094.9995], device='cuda:0')\n",
      "['bags' 'brands' 'presentations' 'laptops' 'tables' 'certificates'\n",
      " 'crafts' 'rss' 'awards' 'wholesale']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 656\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0258, 0.8363, 0.5677, 0.2891, 0.2792, 0.2618, 0.2541, 0.2090, 0.2064,\n",
      "        0.2005], device='cuda:0')\n",
      "['dog' 'winter' 'snow' 'colour' 'warm' 'nature' 'corner' 'ocean' 'fruit'\n",
      " 'picture']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([5700.6099, 4833.6655, 3507.0513, 3207.4207, 2467.0083, 1622.7991,\n",
      "        1403.3469, 1244.8480, 1212.5635, 1212.2021], device='cuda:0')\n",
      "['winter' 'snow' 'professional' 'professionals' 'rain' 'cloudy' 'wet'\n",
      " 'art' 'ocean' 'meat']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 665\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.0838, 0.5952, 0.5696, 0.4155, 0.3616, 0.3508, 0.2925, 0.2313, 0.2249,\n",
      "        0.2242], device='cuda:0')\n",
      "['cute' 'hunting' 'cookies' 'pregnancy' 'dogs' 'pregnant' 'overall'\n",
      " 'photos' 'flying' 'cooling']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([28604.5293, 12459.8506,  8454.9902,  7942.3413,  7491.1016,  6776.7915,\n",
      "         5161.9077,  4987.9639,  4610.2969,  4457.4761], device='cuda:0')\n",
      "['cookies' 'clothes' 'pregnancy' 'cute' 'chocolate' 'pants' 'suit'\n",
      " 'lingerie' 'fashion' 'clothing']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 204\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5768, 0.4783, 0.3809, 0.2180, 0.2177, 0.2131, 0.2036, 0.1966, 0.1941,\n",
      "        0.1804], device='cuda:0')\n",
      "['dog' 'freedom' 'sleep' 'alaska' 'animal' 'dogs' 'pet' 'animals'\n",
      " 'agriculture' 'ocean']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([37326.1641,  4947.0767,  3925.4490,  2785.0818,  2726.2832,  2445.3804,\n",
      "         2200.9131,  2170.7742,  2153.6606,  2147.3613], device='cuda:0')\n",
      "['quotes' 'quote' 'healing' 'posters' 'summer' 'nashville' 'shorts'\n",
      " 'poster' 'wallpapers' 'wedding']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1692\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0461, 0.7069, 0.5360, 0.4928, 0.4160, 0.4072, 0.3500, 0.3285, 0.2502,\n",
      "        0.2397], device='cuda:0')\n",
      "['border' 'boobs' 'birds' 'truck' 'dolls' 'trailer' 'trucks' 'dogs' 'pet'\n",
      " 'installed']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([16304.3838,  7392.4741,  6748.5635,  3653.5010,  3531.4158,  2257.9619,\n",
      "         2128.3352,  2097.1641,  1841.1909,  1823.0659], device='cuda:0')\n",
      "['trucks' 'band' 'boobs' 'bands' 'horses' 'cocks' 'cumshot' 'cats' 'creek'\n",
      " 'sponsors']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 371\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.7947, 0.6607, 0.4833, 0.4454, 0.4428, 0.4183, 0.3969, 0.3368, 0.3360,\n",
      "        0.3064], device='cuda:0')\n",
      "['pet' 'bed' 'vehicle' 'dog' 'flying' 'sand' 'furniture' 'food' 'purple'\n",
      " 'cake']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([10683.8047,  3312.9133,  2285.6311,  2009.6414,  1787.0872,  1716.9985,\n",
      "         1354.1672,  1329.5784,  1223.6335,  1182.7913], device='cuda:0')\n",
      "['chocolate' 'cake' 'food' 'bed' 'furniture' 'cookies' 'brands' 'meat'\n",
      " 'foods' 'displays']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1595\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.7244, 0.4277, 0.4101, 0.3302, 0.2731, 0.2465, 0.2068, 0.1950, 0.1857,\n",
      "        0.1474], device='cuda:0')\n",
      "['hurricane' 'dogs' 'pregnancy' 'birth' 'pregnant' 'forecast' 'guest'\n",
      " 'dog' 'protect' 'wind']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([5248.8560, 2723.8750, 2273.1934, 2243.2100, 1901.9144, 1814.3646,\n",
      "        1754.0548, 1753.3173, 1728.4781, 1719.9543], device='cuda:0')\n",
      "['forecast' 'women' 'wedding' 'tonight' 'weather' 'hurricane' 'navy' 'men'\n",
      " 'guests' 'catering']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2598\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.4761, 1.2269, 0.5231, 0.5114, 0.3320, 0.3150, 0.2921, 0.2350, 0.2121,\n",
      "        0.2075], device='cuda:0')\n",
      "['model' 'dog' 'eagle' 'pet' 'cup' 'sealed' 'toy' 'package' 'asset' 'van']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([13263.4189,  2420.1343,  2144.3342,  1676.5649,  1599.1155,  1473.9916,\n",
      "         1431.1229,  1160.8225,  1028.6071,   993.3487], device='cuda:0')\n",
      "['motorcycle' 'attorney' 'navy' 'contractors' 'builder' 'lawyer'\n",
      " 'contractor' 'car' 'seller' 'apartment']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 546\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.1942, 0.6213, 0.5169, 0.4569, 0.3965, 0.3644, 0.3021, 0.2458, 0.2277,\n",
      "        0.2242], device='cuda:0')\n",
      "['dog' 'conservation' 'jerry' 'roof' 'table' 'bears' 'roads' 'it' 'van'\n",
      " 'dead']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9624.3857, 4711.4580, 3319.5752, 3054.7588, 2634.0183, 1998.1261,\n",
      "        1960.7238, 1912.5410, 1834.9482, 1629.0940], device='cuda:0')\n",
      "['quotes' 'dean' 'taken' 'tennessee' 'logic' 'nashville' 'portland'\n",
      " 'facts' 'credits' 'colleges']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 20\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0534, 0.7091, 0.6664, 0.5463, 0.3249, 0.2935, 0.2545, 0.2493, 0.2298,\n",
      "        0.2257], device='cuda:0')\n",
      "['vehicle' 'photo' 'dogs' 'lot' 'cocks' 'milfhunter' 'cup' 'dog' 'several'\n",
      " 'stock']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([3956.4897, 3692.0869, 3445.0720, 3268.6941, 3240.2144, 3117.3184,\n",
      "        2750.1287, 2640.6528, 2546.4060, 2385.3284], device='cuda:0')\n",
      "['clothes' 'coupons' 'clothing' 'customers' 'contractors' 'cocks'\n",
      " 'supplies' 'shirts' 'manufacturers' 'ingredients']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 606\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.7288, 0.6813, 0.6660, 0.6630, 0.5657, 0.5118, 0.4227, 0.3506, 0.3442,\n",
      "        0.2723], device='cuda:0')\n",
      "['bears' 'labs' 'spa' 'cotton' 'dogs' 'sand' 'collections' 'images' 'pic'\n",
      " 'agriculture']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([38515.9453,  8427.2295,  7947.7852,  6322.1348,  4342.9756,  4103.4766,\n",
      "         4036.8110,  3846.8872,  3562.5842,  3518.2246], device='cuda:0')\n",
      "['owners' 'bears' 'collections' 'scientists' 'resorts' 'quotes' 'types'\n",
      " 'spa' 'physicians' 'bedroom']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2536\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6061, 0.4702, 0.4663, 0.3586, 0.3445, 0.3337, 0.3019, 0.2576, 0.2561,\n",
      "        0.2058], device='cuda:0')\n",
      "['flying' 'farmers' 'cute' 'tiny' 'riding' 'pet' 'biological' 'flight'\n",
      " 'fruit' 'stars']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([5223.4331, 3734.7297, 3563.4888, 3298.7358, 2857.7278, 2819.7839,\n",
      "        2637.7485, 2293.9106, 2182.2371, 1918.6255], device='cuda:0')\n",
      "['motorcycle' 'logic' 'physicians' 'wishlist' 'roses' 'farmers' 'nursing'\n",
      " 'plants' 'ships' 'interracial']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 393\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5780, 0.4949, 0.2651, 0.2262, 0.2255, 0.2141, 0.1934, 0.1855, 0.1840,\n",
      "        0.1527], device='cuda:0')\n",
      "['pair' 'flying' 'beds' 'mac' 'sri' 'po' 'installed' 'gcc' 'santa' 'cake']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([11866.6250,  5654.1831,  3244.9399,  2000.8879,  1473.6895,  1006.4205,\n",
      "         1004.5889,   848.4174,   802.6117,   655.8174], device='cuda:0')\n",
      "['et' 'wallpapers' 'laptops' 'santa' 'wallpaper' 'companies' 'churches'\n",
      " 'colleges' 'desktops' 'bears']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2726\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.7928, 0.6037, 0.5494, 0.4655, 0.4368, 0.4084, 0.3864, 0.3150, 0.3091,\n",
      "        0.3009], device='cuda:0')\n",
      "['dogs' 'bowl' 'farmers' 'guides' 'milfhunter' 'shared' 'bears' 'stands'\n",
      " 'soldiers' 'pair']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([27228.2988, 18398.9863, 13842.8262,  9171.4326,  7071.8511,  5483.6777,\n",
      "         5073.7344,  4207.2007,  3989.6284,  3406.7886], device='cuda:0')\n",
      "['bands' 'owners' 'soldiers' 'officers' 'teens' 'bears' 'picks' 'guides'\n",
      " 'sponsors' 'ladies']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2596\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0822, 0.6012, 0.4673, 0.3959, 0.3314, 0.2654, 0.2561, 0.2451, 0.2109,\n",
      "        0.2062], device='cuda:0')\n",
      "['dog' 'weight' 'scale' 'fl' 'dolls' 'po' 'models' 'swiss' 'et' 'dogs']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([4108.1528, 2725.4421, 2669.4834, 2332.1941, 2318.4990, 2261.5793,\n",
      "        2260.2246, 2122.9548, 1967.5376, 1890.6039], device='cuda:0')\n",
      "['tampa' 'tennessee' 'arkansas' 'miami' 'reporter' 'et' 'weight' 'fl'\n",
      " 'vermont' 'bands']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 113\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5936, 0.5575, 0.3879, 0.3301, 0.3047, 0.3013, 0.2988, 0.2795, 0.2245,\n",
      "        0.2032], device='cuda:0')\n",
      "['dog' 'cute' 'alaska' 'dogs' 'vacation' 'rental' 'removal' 'pet'\n",
      " 'packages' 'conservation']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([4900.0845, 4808.6172, 4506.3252, 3807.0295, 3648.0945, 3335.5115,\n",
      "        3184.2192, 2569.2944, 2394.5129, 2250.6450], device='cuda:0')\n",
      "['seattle' 'alaska' 'hawaii' 'airlines' 'clothing' 'idaho' 'hotels'\n",
      " 'travel' 'plane' 'jobs']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2773\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.9763, 0.6088, 0.2848, 0.2263, 0.2138, 0.2015, 0.1844, 0.1661, 0.1582,\n",
      "        0.1567], device='cuda:0')\n",
      "['conservation' 'flying' 'swimming' 'watching' 'engineering' 'hunting'\n",
      " 'beastiality' 'wildlife' 'toys' 'dog']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([4859.1230, 3583.4949, 2882.4614, 2396.8228, 2069.8782, 2007.4663,\n",
      "        2003.7068, 1751.6561, 1725.7968, 1673.4369], device='cuda:0')\n",
      "['buildings' 'websites' 'building' 'contractors' 'engineering' 'lake'\n",
      " 'engineers' 'apartments' 'swimming' 'street']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 478\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0106, 0.7168, 0.5997, 0.3248, 0.3113, 0.3013, 0.2695, 0.2691, 0.2582,\n",
      "        0.2143], device='cuda:0')\n",
      "['dog' 'balls' 'toys' 'pet' 'wing' 'wings' 'provisions' 'furniture'\n",
      " 'spyware' 'produce']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([19419.4688,  6255.9995,  6133.5576,  5812.5352,  5631.9409,  4973.4189,\n",
      "         4444.3296,  4413.4546,  2794.2163,  2689.4600], device='cuda:0')\n",
      "['appliances' 'magazines' 'printers' 'electronics' 'publishing'\n",
      " 'publications' 'provisions' 'businesses' 'supplements' 'laptops']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 138\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.6851, 1.1517, 0.4663, 0.4052, 0.4040, 0.3720, 0.3442, 0.3037, 0.3015,\n",
      "        0.2984], device='cuda:0')\n",
      "['dogs' 'boobs' 'womens' 'wings' 'bowl' 'fucking' 'dog' 'roads' 'balls'\n",
      " 'pussy']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7108.7554, 6560.7588, 5190.8477, 3986.8240, 3178.4980, 2834.7839,\n",
      "        2376.2261, 1194.2502, 1154.4385, 1084.1768], device='cuda:0')\n",
      "['womens' 'supplements' 'boobs' 'foods' 'women' 'dogs' 'sizes'\n",
      " 'substances' 'taiwan' 'balls']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 854\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.5502, 0.4809, 0.4797, 0.4293, 0.4211, 0.4024, 0.3206, 0.3099, 0.2876,\n",
      "        0.2556], device='cuda:0')\n",
      "['foster' 'flying' 'roof' 'tags' 'milfs' 'thongs' 'feeds' 'bowl' 'helping'\n",
      " 'dog']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([10178.1289,  7415.4326,  7135.5068,  6917.6338,  5619.3262,  2670.1350,\n",
      "         2284.4275,  2183.4136,  2152.1379,  1535.1862], device='cuda:0')\n",
      "['finder' 'labels' 'editors' 'receipt' 'tags' 'prices' 'pricing' 'label'\n",
      " 'contractors' 'merchandise']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2594\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.8394, 0.4741, 0.4571, 0.3317, 0.2236, 0.1948, 0.1730, 0.1711, 0.1704,\n",
      "        0.1605], device='cuda:0')\n",
      "['pair' 'flying' 'dog' 'pic' 'field' 'ph' 'fly' 'dolls' 'installation'\n",
      " 'preview']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7644.6201, 5624.5273, 4366.3081, 3812.7874, 2540.6807, 2389.7683,\n",
      "        2296.3379, 2234.4512, 2006.2803, 1986.7107], device='cuda:0')\n",
      "['fly' 'wallpaper' 'maryland' 'tennessee' 'nj' 'idaho' 'wallpapers'\n",
      " 'kentucky' 'quotes' 'delaware']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1839\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.8115, 0.6781, 0.5084, 0.4875, 0.3879, 0.3132, 0.2890, 0.2756, 0.2371,\n",
      "        0.2346], device='cuda:0')\n",
      "['roof' 'turkey' 'flying' 'dolls' 'conservation' 'dakota' 'packages'\n",
      " 'dogs' 'sugar' 'bread']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([3242.1265, 2783.9619, 2018.4387, 1449.5222, 1348.5833, 1287.7396,\n",
      "        1248.8247, 1223.3993, 1199.5898, 1106.0331], device='cuda:0')\n",
      "['library' 'tripadvisor' 'chicken' 'pollution' 'foods' 'bread'\n",
      " 'encyclopedia' 'materials' 'breakfast' 'publisher']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1325\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6372, 0.5354, 0.4166, 0.2972, 0.2968, 0.2949, 0.2672, 0.2495, 0.1964,\n",
      "        0.1826], device='cuda:0')\n",
      "['bass' 'sub' 'kernel' 'amp' 'beds' 'bears' 'milfhunter' 'epinions'\n",
      " 'firefox' 'cluster']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([14623.8809, 14104.3467,  9238.0703,  5298.7715,  5126.3208,  4771.8169,\n",
      "         3299.6812,  3154.7625,  3123.0247,  2891.3147], device='cuda:0')\n",
      "['appliances' 'speakers' 'logic' 'guitar' 'recipes' 'brands' 'speaker'\n",
      " 'bags' 'developer' 'directories']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2741\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0171, 0.5408, 0.3284, 0.2605, 0.2302, 0.1934, 0.1916, 0.1912, 0.1861,\n",
      "        0.1858], device='cuda:0')\n",
      "['dogs' 'guides' 'profiles' 'agricultural' 'epinions' 'clubs' 'providers'\n",
      " 'purple' 'biological' 'trembl']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([100756.5312,  13520.1240,  11847.2871,   6170.5811,   6161.8853,\n",
      "          6128.4121,   5733.0073,   5502.9639,   4673.8208,   4440.0708],\n",
      "       device='cuda:0')\n",
      "['owners' 'scientists' 'careers' 'officers' 'customers' 'engineers'\n",
      " 'restaurants' 'nebraska' 'physicians' 'consultants']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1405\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.1323, 0.6308, 0.4796, 0.4408, 0.3797, 0.3420, 0.3404, 0.3323, 0.2798,\n",
      "        0.2495], device='cuda:0')\n",
      "['hairy' 'flying' 'box' 'breakfast' 'fruit' 'sand' 'fucking'\n",
      " 'conservation' 'toys' 'pet']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([5873.3657, 4262.2197, 3998.2578, 3319.2119, 1864.4187, 1699.5143,\n",
      "        1610.0646, 1594.6012, 1477.5558, 1411.9393], device='cuda:0')\n",
      "['presents' 'bondage' 'bush' 'hairy' 'bread' 'parties' 'party' 'lounge'\n",
      " 'et' 'rooms']\n",
      "============================ steering_strength: 50.0 ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/1562 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "655\n",
      "656\n",
      "665\n",
      "204\n",
      "1692\n",
      "371\n",
      "1595\n",
      "2598\n",
      "546\n",
      "20\n",
      "606\n",
      "2536\n",
      "393\n",
      "2726\n",
      "2596\n",
      "113\n",
      "2773\n",
      "478\n",
      "138\n",
      "854\n",
      "2594\n",
      "1839\n",
      "1325\n",
      "2741\n",
      "1405\n",
      "========================================================================================\n",
      "\n",
      "For Feature 655\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.6291, 0.9716, 0.9184, 0.7120, 0.6663, 0.4315, 0.4019, 0.3364, 0.3245,\n",
      "        0.2726], device='cuda:0')\n",
      "['for' 'posts' 'outdoor' 'pair' 'thumbnail' 'felt' 'sterling' 'wholesale'\n",
      " 'peer' 'estate']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([232949.5000, 143069.0000,  92122.9609,  79913.3203,  73186.1641,\n",
      "         61242.3047,  54763.0352,  43138.8672,  41579.6992,  41040.0742],\n",
      "       device='cuda:0')\n",
      "['laptops' 'bags' 'tables' 'presentations' 'betting' 'crafts' 'guestbook'\n",
      " 'networking' 'brands' 'navy']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 656\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5435, 1.1550, 0.9887, 0.6765, 0.4595, 0.4058, 0.2974, 0.2590, 0.2359,\n",
      "        0.2191], device='cuda:0')\n",
      "['traditional' 'professionals' 'professional' 'installed' 'fabric'\n",
      " 'leather' 'tradition' 'president' 'preferences' 'progressive']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([407514.7500, 163385.2031, 142143.9062, 120700.0547,  98304.4375,\n",
      "         97230.1328,  96429.3438,  81571.5156,  73801.5703,  57308.8320],\n",
      "       device='cuda:0')\n",
      "['christmas' 'professionals' 'stars' 'fabric' 'creek' 'leather'\n",
      " 'professional' 'designer' 'fishing' 'designers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 665\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.1100, 0.8804, 0.8038, 0.4295, 0.4076, 0.3602, 0.3582, 0.3558, 0.3431,\n",
      "        0.3084], device='cuda:0')\n",
      "['anime' 'cute' 'yard' 'japanese' 'oh' 'you' 'cards' 'ph' 'card' 'overall']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([414322.7500, 131561.6406,  96989.8984,  96425.1953,  90229.0234,\n",
      "         79649.2891,  73625.0781,  67898.7812,  67397.9453,  67213.6797],\n",
      "       device='cuda:0')\n",
      "['anime' 'mountains' 'ships' 'cookies' 'houses' 'fashion' 'garden' 'suit'\n",
      " 'lounge' 'boats']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 204\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0685, 0.8643, 0.8242, 0.7692, 0.3808, 0.3572, 0.2889, 0.2746, 0.2606,\n",
      "        0.2475], device='cuda:0')\n",
      "['wallpapers' 'nature' 'outdoors' 'wallpaper' 'seat' 'outdoor' 'adventure'\n",
      " 'patterns' 'intellectual' 'fantasy']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([958805.8750, 667007.5000, 248092.2969, 187871.8594, 112248.5234,\n",
      "         99783.8984,  87762.8359,  77400.4844,  57864.4102,  50608.8750],\n",
      "       device='cuda:0')\n",
      "['quotes' 'wallpapers' 'navy' 'nature' 'wallpaper' 'flowers' 'colleges'\n",
      " 'mountains' 'quote' 'fishing']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1692\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.4905, 1.1399, 0.6165, 0.3709, 0.3406, 0.3283, 0.3089, 0.2997, 0.2782,\n",
      "        0.2688], device='cuda:0')\n",
      "['border' 'cumshot' 'by' 'team' 'binding' 'trailer' 'want' 'edt'\n",
      " 'thumbnail' 'let']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([445728.5938,  99708.1016,  76803.6641,  70886.0391,  59631.5625,\n",
      "         41057.1797,  29484.5391,  26978.4473,  25284.2832,  24952.7578],\n",
      "       device='cuda:0')\n",
      "['cumshot' 'band' 'trucks' 'boobs' 'dress' 'bands' 'certificates' 'dolls'\n",
      " 'books' 'notebooks']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 371\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.6683, 1.5647, 0.6896, 0.6404, 0.6340, 0.4174, 0.3966, 0.3770, 0.3360,\n",
      "        0.3122], device='cuda:0')\n",
      "['pet' 'cake' 'button' 'firefox' 'chocolate' 'pin' 'furniture' 'car'\n",
      " 'table' 'food']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([416531.4062, 368955.8438, 255817.5781, 236552.3125, 149428.0469,\n",
      "        119999.5547, 101751.9219,  88265.1875,  81647.0547,  75007.2031],\n",
      "       device='cuda:0')\n",
      "['chocolate' 'purple' 'cake' 'recipes' 'furniture' 'foods' 'dress'\n",
      " 'brands' 'food' 'tree']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1595\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.6551, 0.4408, 0.3297, 0.2896, 0.2037, 0.1960, 0.1658, 0.1559, 0.1548,\n",
      "        0.1507], device='cuda:0')\n",
      "['pregnancy' 'bill' 'size' 'zip' 'pregnant' 'transition' 'billy' 'still'\n",
      " 'carry' 'newest']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([53133.0547, 35346.3320, 33524.7852, 32073.1621, 31719.9863, 31155.7324,\n",
      "        28245.5879, 26072.5801, 24750.3633, 23796.6914], device='cuda:0')\n",
      "['recipes' 'catering' 'motorcycle' 'pregnancy' 'quotes' 'wedding' 'poster'\n",
      " 'programs' 'women' 'program']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2598\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.0094, 0.6684, 0.6283, 0.4305, 0.2833, 0.2828, 0.2683, 0.2391, 0.2337,\n",
      "        0.2251], device='cuda:0')\n",
      "['lease' 'thumbnail' 'font' 'toy' 'pearl' 'stock' 'mens' 'product'\n",
      " 'sealed' 'present']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([109112.7344,  91003.2969,  90884.8516,  56741.6367,  49828.1016,\n",
      "         41955.0273,  33366.6094,  25829.8945,  21277.7656,  20700.7656],\n",
      "       device='cuda:0')\n",
      "['attorney' 'lawyer' 'navy' 'motorcycle' 'pharmacy' 'automotive' 'lease'\n",
      " 'builder' 'contractors' 'pearl']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 546\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.6645, 1.2409, 0.7830, 0.7219, 0.5694, 0.5406, 0.5104, 0.4022, 0.3670,\n",
      "        0.3621], device='cuda:0')\n",
      "['dean' 'posts' 'facts' 'table' 'counter' 'bars' 'yard' 'quotes' 'yards'\n",
      " 'batteries']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([6837663.0000,  379926.7812,  313337.7188,  270927.3750,  209002.7500,\n",
      "         202786.7500,  181045.2031,  172041.5469,  156561.8594,  149302.6406],\n",
      "       device='cuda:0')\n",
      "['quotes' 'facts' 'colleges' 'dean' 'contractors' 'papers' 'bathroom'\n",
      " 'nashville' 'tables' 'shirts']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 20\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.2032, 1.1382, 0.9802, 0.9480, 0.8599, 0.4126, 0.3560, 0.3531, 0.2792,\n",
      "        0.2713], device='cuda:0')\n",
      "['suppliers' 'lot' 'stock' 'photo' 'front' 'rack' 'crew' 'generated'\n",
      " 'pipe' 'pdt']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([250057.4844, 170646.4219, 110620.0391,  93273.8594,  61645.7578,\n",
      "         56086.7812,  49344.2305,  45261.1445,  43087.9336,  39915.1719],\n",
      "       device='cuda:0')\n",
      "['customers' 'suppliers' 'coupons' 'lesbian' 'manufacturers' 'businesses'\n",
      " 'engineers' 'sponsors' 'industries' 'shirts']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 606\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.1556, 1.1100, 0.7324, 0.5041, 0.4270, 0.4219, 0.3983, 0.3399, 0.3195,\n",
      "        0.3138], device='cuda:0')\n",
      "['net' 'ice' 'theme' 'themes' 'images' 'wallpapers' 'cotton' 'collections'\n",
      " 'milfhunter' 'newsletters']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([476543.5938, 359566.9688, 344737.7500, 227723.8438, 204913.0000,\n",
      "        172983.1250, 161722.7969, 119895.9453, 119728.0000, 118441.8047],\n",
      "       device='cuda:0')\n",
      "['beach' 'scientists' 'businesses' 'wallpapers' 'ice' 'shops' 'owners'\n",
      " 'programmes' 'brands' 'affiliates']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2536\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.7528, 0.3390, 0.3390, 0.2940, 0.2937, 0.2454, 0.2412, 0.2377, 0.2294,\n",
      "        0.2284], device='cuda:0')\n",
      "['commission' 'largest' 'assumes' 'breasts' 'hurricane' 'flights' 'nsw'\n",
      " 'lane' 'farmers' 'huge']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([308286.0312, 226163.9375, 117787.9375,  62796.4453,  59819.3438,\n",
      "         53273.0938,  52065.0859,  50762.2773,  47773.9062,  41778.0625],\n",
      "       device='cuda:0')\n",
      "['physicians' 'farmers' 'plants' 'roses' 'laptops' 'lingerie' 'scientists'\n",
      " 'jewellery' 'motorcycle' 'boots']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 393\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.2456, 0.8961, 0.4035, 0.2911, 0.2796, 0.2744, 0.2598, 0.2431, 0.2156,\n",
      "        0.1901], device='cuda:0')\n",
      "['wallpapers' 'wallpaper' 'se' 'cases' 'windows' 'screen' 'br' 'permalink'\n",
      " 'tn' 'mailing']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([699519.0000, 237304.5469, 181708.2188, 123209.4062,  73133.6719,\n",
      "         66150.5859,  63521.0898,  59031.5625,  35042.6953,  34949.3047],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'scientists' 'windows' 'wallpaper' 'laptops' 'catalog'\n",
      " 'companies' 'santa' 'contractors' 'engineers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2726\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5502, 0.8010, 0.7714, 0.7273, 0.7144, 0.6868, 0.6010, 0.5283, 0.5244,\n",
      "        0.4646], device='cuda:0')\n",
      "['guides' 'pair' 'bands' 'merchandise' 'couples' 'pets' 'pin' 'clubs'\n",
      " 'soldiers' 'communities']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([692649.1875, 401294.1250, 235295.6406, 188779.6562, 177818.5625,\n",
      "        149555.5469, 136416.1875, 133785.0625, 130162.4375,  90693.6875],\n",
      "       device='cuda:0')\n",
      "['bands' 'owners' 'sponsors' 'officers' 'bears' 'farmers' 'soldiers'\n",
      " 'stars' 'picks' 'pets']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2596\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.2001, 0.6489, 0.6452, 0.3947, 0.3819, 0.3427, 0.2515, 0.2151, 0.1935,\n",
      "        0.1599], device='cuda:0')\n",
      "['weight' 'merchandise' 'it' 'ram' 'scale' 'seller' 'potter' 'fl' 'et'\n",
      " 'news']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([360553.0312, 137996.4844,  84549.7500,  40671.8594,  38461.2109,\n",
      "         30081.0117,  26301.3906,  24824.4062,  24520.7891,  23598.1348],\n",
      "       device='cuda:0')\n",
      "['et' 'tampa' 'sponsors' 'merchandise' 'potter' 'customer' 'maryland'\n",
      " 'weight' 'anonymous' 'brands']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 113\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.1778, 0.8603, 0.6929, 0.5993, 0.4469, 0.4348, 0.4245, 0.3900, 0.3662,\n",
      "        0.3149], device='cuda:0')\n",
      "['removal' 'rental' 'case' 'ha' 'wikipedia' 'advertise' 'shown'\n",
      " 'equipment' 'numerous' 'cars']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([317785.4688, 274188.8750, 107787.7500,  89980.9062,  73760.0078,\n",
      "         60070.0586,  59875.6484,  59272.3984,  56735.3516,  55390.7422],\n",
      "       device='cuda:0')\n",
      "['idaho' 'cars' 'hawaii' 'businesses' 'jobs' 'vehicles' 'hotels' 'recipes'\n",
      " 'simpson' 'bags']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2773\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.9727, 1.1074, 0.8031, 0.6616, 0.5409, 0.3349, 0.3033, 0.2766, 0.2196,\n",
      "        0.1907], device='cuda:0')\n",
      "['pair' 'site' 'conservation' 'park' 'yard' 'flying' 'area' 'outdoors'\n",
      " 'thermal' 'camp']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([640293.0000, 305934.0312, 235078.7969, 149229.5312, 122031.9375,\n",
      "        120139.3281,  84118.0078,  63767.1562,  60350.6016,  50639.2773],\n",
      "       device='cuda:0')\n",
      "['buildings' 'garden' 'park' 'beach' 'creek' 'building' 'lake' 'gardens'\n",
      " 'mountains' 'village']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 478\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.3055, 1.2977, 0.7859, 0.7223, 0.5925, 0.5772, 0.4644, 0.4405, 0.3956,\n",
      "        0.2967], device='cuda:0')\n",
      "['balls' 'net' 'printers' 'toys' 'vacuum' 'cards' 'motors' 'appliances'\n",
      " 'magazines' 'paperback']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1605624.7500,  674981.4375,  316460.9688,  298928.0000,  163729.7656,\n",
      "         144169.2344,  143582.5781,  133782.3594,  117929.0859,  113416.4688],\n",
      "       device='cuda:0')\n",
      "['appliances' 'computers' 'magazines' 'laptops' 'printers' 'dvds' 'balls'\n",
      " 'bags' 'businesses' 'electronics']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 138\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.4459, 1.1976, 0.9941, 0.8649, 0.5744, 0.5727, 0.4501, 0.4438, 0.4411,\n",
      "        0.3411], device='cuda:0')\n",
      "['porn' 'boobs' 'womens' 'ports' 'toll' 'tits' 'latina' 'las' 'sexcam'\n",
      " 'felt']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([368278.9375, 132634.3594, 116236.2734,  97805.5547,  91913.0547,\n",
      "         86375.1406,  69667.0234,  62891.8750,  59966.4766,  49505.9141],\n",
      "       device='cuda:0')\n",
      "['boobs' 'ports' 'phentermine' 'women' 'womens' 'tampa' 'supplements'\n",
      " 'cities' 'flowers' 'pills']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 854\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([4.1084, 0.5677, 0.5372, 0.4327, 0.4200, 0.3838, 0.3678, 0.3301, 0.3153,\n",
      "        0.2971], device='cuda:0')\n",
      "['tags' 'pricing' 'receipt' 'saving' 'mailing' 'prices' 'feet' 'savings'\n",
      " 'postal' 'labels']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1658348.8750,  288749.8750,  250694.7500,  230374.4219,  199225.3125,\n",
      "          97155.6250,   94697.0859,   80559.2266,   60036.2773,   47876.3398],\n",
      "       device='cuda:0')\n",
      "['tags' 'labels' 'receipt' 'coupons' 'pricing' 'lingerie' 'ratings'\n",
      " 'prices' 'savings' 'certificates']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2594\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0574, 0.8269, 0.6474, 0.5459, 0.5185, 0.4828, 0.4402, 0.3785, 0.3292,\n",
      "        0.3114], device='cuda:0')\n",
      "['thumbnail' 'wallpaper' 'font' 'pic' 'follow' 'pin' 'counter'\n",
      " 'wallpapers' 'ph' 'preview']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([938448.0000, 358036.7812, 253087.8750, 209200.1562, 167469.4375,\n",
      "        143124.1875, 140207.5938, 116854.1172, 115547.6875, 108289.8281],\n",
      "       device='cuda:0')\n",
      "['kitchen' 'bathroom' 'wallpapers' 'boats' 'directory' 'quotes'\n",
      " 'wallpaper' 'shoes' 'bedroom' 'catering']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1839\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.9249, 0.7592, 0.6275, 0.6242, 0.4627, 0.4627, 0.3957, 0.2911, 0.2850,\n",
      "        0.2621], device='cuda:0')\n",
      "['numerous' 'addition' 'immigration' 'subscriptions' 'nationwide' 'roof'\n",
      " 'proteins' 'tripadvisor' 'oak' 'attendance']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([340302.0625, 141967.7812, 117894.7031,  79105.7500,  77737.4844,\n",
      "         75060.4453,  63172.3281,  54483.2891,  52598.2891,  49127.4531],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'subscriptions' 'tripadvisor' 'warehouse' 'library' 'foods'\n",
      " 'roof' 'addresses' 'proteins' 'databases']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1325\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.1913, 1.0379, 0.8245, 0.5832, 0.5513, 0.4186, 0.4063, 0.3490, 0.3178,\n",
      "        0.2834], device='cuda:0')\n",
      "['investor' 'listings' 'buffer' 'leads' 'ads' 'bidding' 'thumbnail'\n",
      " 'remove' 'indexed' 'auctions']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([215052.5156, 148797.6406, 105945.9062,  85561.4766,  85088.2891,\n",
      "         84785.3516,  81020.4922,  77702.1953,  74154.2734,  72225.5547],\n",
      "       device='cuda:0')\n",
      "['listings' 'directories' 'bedroom' 'recipes' 'domains' 'brands'\n",
      " 'bedrooms' 'ads' 'quotes' 'buffer']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2741\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.7061, 0.5711, 0.4968, 0.4644, 0.4128, 0.4000, 0.3928, 0.3747, 0.3017,\n",
      "        0.2739], device='cuda:0')\n",
      "['clubs' 'researchers' 'restaurants' 'verzeichnis' 'czech' 'providers'\n",
      " 'brief' 'institutions' 'draft' 'hospitals']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([868127.6250, 795708.2500, 480729.9375, 462312.9688, 325986.7812,\n",
      "        320801.5312, 292303.5000, 248126.5469, 233364.8125, 177305.5156],\n",
      "       device='cuda:0')\n",
      "['restaurants' 'hospitals' 'physicians' 'scientists' 'researchers'\n",
      " 'businesses' 'recipes' 'customers' 'catering' 'consultants']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1405\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0117, 0.5419, 0.5243, 0.4384, 0.4137, 0.3863, 0.3327, 0.3204, 0.2156,\n",
      "        0.2141], device='cuda:0')\n",
      "['bush' 'xx' 'residents' 'wishlist' 'stephen' 'stewart' 'resident'\n",
      " 'residential' 'president' 'bill']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([603280.0000, 424590.8125, 222218.4844, 140432.6875, 130482.3828,\n",
      "         84841.5703,  83966.2812,  52651.0742,  44609.5000,  44183.6953],\n",
      "       device='cuda:0')\n",
      "['bush' 'bedroom' 'bedrooms' 'presents' 'apartments' 'wishlist'\n",
      " 'residents' 'guestbook' 'resident' 'sex']\n",
      "============================ steering_strength: 150.0 ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/1562 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "655\n",
      "656\n",
      "665\n",
      "204\n",
      "1692\n",
      "371\n",
      "1595\n",
      "2598\n",
      "546\n",
      "20\n",
      "606\n",
      "2536\n",
      "393\n",
      "2726\n",
      "2596\n",
      "113\n",
      "2773\n",
      "478\n",
      "138\n",
      "854\n",
      "2594\n",
      "1839\n",
      "1325\n",
      "2741\n",
      "1405\n",
      "========================================================================================\n",
      "\n",
      "For Feature 655\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.0951, 1.5323, 1.1852, 0.7186, 0.7115, 0.6643, 0.5152, 0.4448, 0.3628,\n",
      "        0.3546], device='cuda:0')\n",
      "['for' 'pair' 'listening' 'posts' 'lot' 'estate' 'post' 'sterling'\n",
      " 'containing' 'pm']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([708388.1250, 298176.4062, 211621.7656, 175056.9062, 160939.3125,\n",
      "        116493.7031, 101212.9453,  68757.0469,  59526.9531,  56710.6094],\n",
      "       device='cuda:0')\n",
      "['laptops' 'laptop' 'betting' 'pink' 'jewellery' 'tables' 'desk' 'bags'\n",
      " 'networking' 'presentations']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 656\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.8821, 1.7943, 1.0880, 1.0285, 0.9586, 0.6880, 0.6621, 0.5363, 0.4479,\n",
      "        0.3388], device='cuda:0')\n",
      "['threads' 'fabric' 'breast' 'elected' 'thread' 'installed' 'leather'\n",
      " 'traditional' 'preferences' 'womens']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([822859.2500, 623795.2500, 479282.9688, 457065.0625, 318240.0312,\n",
      "        281416.1562, 218186.2656, 208437.8125, 206107.1562, 201635.2031],\n",
      "       device='cuda:0')\n",
      "['fabric' 'christmas' 'ships' 'boats' 'clothes' 'navy' 'leather'\n",
      " 'lingerie' 'threads' 'stars']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 665\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.5374, 1.9570, 1.5349, 0.8675, 0.7743, 0.6148, 0.5012, 0.4755, 0.3375,\n",
      "        0.3272], device='cuda:0')\n",
      "['anime' 'yard' 'card' 'ph' 'oh' 'ink' 'and' 'japanese' 'cards' 'ave']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1033630.8750,  942742.8750,  639068.1875,  349032.5312,  347566.4062,\n",
      "         326888.7188,  305923.2500,  240987.5156,  170052.6875,  163745.1719],\n",
      "       device='cuda:0')\n",
      "['ships' 'anime' 'mountains' 'boats' 'garden' 'navy' 'companies' 'yard'\n",
      " 'bedroom' 'universities']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 204\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([4.1056, 2.7775, 2.5212, 1.6038, 1.0071, 0.5696, 0.4773, 0.3554, 0.3097,\n",
      "        0.2684], device='cuda:0')\n",
      "['wallpapers' 'wallpaper' 'patterns' 'pattern' 'navy' 'leather' 'nature'\n",
      " 'printable' 'wooden' 'seat']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([5667326.0000, 3882542.2500,  808199.6875,  777896.2500,  656824.0000,\n",
      "         533276.5625,  372903.3438,  316432.6875,  305285.8750,  285055.2188],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'navy' 'wallpaper' 'boats' 'patterns' 'ships' 'colleges'\n",
      " 'mountains' 'pattern' 'nature']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1692\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.2945, 0.8199, 0.7536, 0.7531, 0.6759, 0.6056, 0.4945, 0.4722, 0.4399,\n",
      "        0.4352], device='cuda:0')\n",
      "['cumshot' 'card' 'page' 'border' 'ordering' 'by' 'adapter' 'drawing'\n",
      " 'jersey' 'front']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1639273.5000,  246259.4219,  158464.5781,  155438.6406,  114026.9531,\n",
      "          87766.4062,   74444.3984,   73336.6250,   72086.4141,   63488.0352],\n",
      "       device='cuda:0')\n",
      "['cumshot' 'bedroom' 'dress' 'certificates' 'recipes' 'notebooks'\n",
      " 'college' 'page' 'poster' 'boxes']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 371\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.7970, 1.7417, 1.4482, 1.1992, 0.8460, 0.6092, 0.4557, 0.4470, 0.4322,\n",
      "        0.3601], device='cuda:0')\n",
      "['purple' 'basketball' 'dell' 'tree' 'button' 'name' 'cake' 'card' 'pet'\n",
      " 'jordan']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([4895457.5000, 1412951.2500, 1072358.6250,  727671.3750,  670023.7500,\n",
      "         619140.0000,  216236.4375,  169771.3750,  166399.3438,  140626.6250],\n",
      "       device='cuda:0')\n",
      "['purple' 'recipes' 'basketball' 'pink' 'tree' 'dress' 'desk' 'companies'\n",
      " 'cake' 'foods']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1595\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([0.9171, 0.6939, 0.6166, 0.4976, 0.4918, 0.4150, 0.3507, 0.3217, 0.2857,\n",
      "        0.2759], device='cuda:0')\n",
      "['thompson' 'poster' 'zip' 'transportation' 'transition' 'transport'\n",
      " 'gray' 'traditional' 'classic' 'professional']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([867962.3750, 290729.2812, 167871.2812, 155819.4688, 113161.5000,\n",
      "        105026.7656,  90063.6328,  66028.6172,  64105.0000,  61348.8281],\n",
      "       device='cuda:0')\n",
      "['recipes' 'poster' 'quotes' 'posters' 'motorcycle' 'program' 'programs'\n",
      " 'restaurants' 'tropical' 'bar']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2598\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.4570, 0.5552, 0.4922, 0.4725, 0.3865, 0.3855, 0.3601, 0.3349, 0.2911,\n",
      "        0.2709], device='cuda:0')\n",
      "['font' 'lease' 'pearl' 'lp' 'stock' 'toy' 'thumbnail' 'potter' 'mens'\n",
      " 'type']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([281259.4688, 274361.0625, 220846.4375, 148629.9531, 127404.6953,\n",
      "        120798.2656, 100818.1797,  94607.0859,  90279.1484,  85757.1797],\n",
      "       device='cuda:0')\n",
      "['attorney' 'lawyer' 'bedroom' 'doctor' 'pharmacy' 'recipes' 'navy'\n",
      " 'lingerie' 'jewelry' 'pearl']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 546\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.0890, 2.0882, 2.0760, 1.1128, 0.8448, 0.8448, 0.5865, 0.5011, 0.4632,\n",
      "        0.4256], device='cuda:0')\n",
      "['bars' 'quotes' 'facts' 'posts' 'counter' 'yard' 'dean' 'yards'\n",
      " 'cumshots' 'console']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([45015288.0000,  2293554.2500,  1323985.5000,  1254369.6250,\n",
      "          963483.7500,   851700.7500,   764681.5000,   497136.8750,\n",
      "          482739.3750,   401930.2188], device='cuda:0')\n",
      "['quotes' 'boats' 'facts' 'ships' 'bathroom' 'recipes' 'shots' 'cumshots'\n",
      " 'colleges' 'papers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 20\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.7385, 0.9327, 0.6926, 0.6803, 0.6400, 0.5467, 0.5405, 0.4966, 0.4020,\n",
      "        0.3914], device='cuda:0')\n",
      "['front' 'card' 'drivers' 'shown' 'rack' 'suppliers' 'thumbnail' 'stock'\n",
      " 'supplied' 'russell']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([249455.1094, 170868.0156, 131740.5312, 127990.2812,  99078.6250,\n",
      "         86584.3984,  85779.5703,  76838.4453,  76119.4688,  75748.3281],\n",
      "       device='cuda:0')\n",
      "['customers' 'drivers' 'businesses' 'suppliers' 'lesbian' 'coupons'\n",
      " 'front' 'christmas' 'industries' 'sponsors']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 606\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.3967, 1.6380, 1.1754, 1.1385, 1.0531, 0.6150, 0.6021, 0.5620, 0.4646,\n",
      "        0.4466], device='cuda:0')\n",
      "['net' 'front' 'wallpapers' 'affiliates' 'ice' 'newsletters' 'foto'\n",
      " 'article' 'milfhunter' 'programmes']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2163149.7500, 1494643.3750, 1357428.3750, 1062649.0000,  841841.1875,\n",
      "         772939.6875,  537328.1250,  530002.8125,  450813.2188,  447528.2188],\n",
      "       device='cuda:0')\n",
      "['businesses' 'wallpapers' 'brands' 'beach' 'companies' 'affiliates'\n",
      " 'restaurants' 'logos' 'shops' 'recipes']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2536\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.9105, 0.9315, 0.9203, 0.7486, 0.6471, 0.3870, 0.2636, 0.2521, 0.2375,\n",
      "        0.2164], device='cuda:0')\n",
      "['assumes' 'boots' 'lane' 'commission' 'lingerie' 'journal' 'breasts'\n",
      " 'sri' 'shoes' 'largest']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([5642239.0000,  426374.5312,  247393.9219,  247285.4062,  223077.3125,\n",
      "         221142.7344,  220247.5938,  182204.8906,  174651.7812,  160948.3906],\n",
      "       device='cuda:0')\n",
      "['lingerie' 'boots' 'farmers' 'laptops' 'trees' 'physicians' 'jewellery'\n",
      " 'shoes' 'roads' 'flowers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 393\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.3415, 1.8247, 0.9947, 0.7090, 0.6662, 0.6358, 0.3751, 0.3552, 0.3230,\n",
      "        0.3120], device='cuda:0')\n",
      "['wallpapers' 'wallpaper' 'mens' 'printable' 'windows' 'screen' 'tn'\n",
      " 'thumbnail' 'recruitment' 'permalink']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([3045952.7500,  646752.0625,  601293.0000,  505212.7188,  263962.7500,\n",
      "         223464.1406,  217895.1094,  208659.7188,  166392.2344,  153136.0938],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'catalog' 'windows' 'wallpaper' 'scientists' 'hunting'\n",
      " 'catalogue' 'limousines' 'shirts' 'bathroom']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2726\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.8153, 1.0229, 0.6880, 0.6366, 0.6223, 0.5717, 0.5666, 0.5610, 0.4663,\n",
      "        0.4198], device='cuda:0')\n",
      "['pets' 'merchandise' 'guides' 'bears' 'printable' 'dogs' 'sharing'\n",
      " 'stars' 'pair' 'couples']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1787876.3750, 1507432.3750, 1111928.6250,  846088.5625,  650194.3750,\n",
      "         645600.5000,  542144.5625,  391790.7812,  325345.0938,  280676.6562],\n",
      "       device='cuda:0')\n",
      "['stars' 'pets' 'shops' 'bears' 'appliances' 'dogs' 'customers' 'farmers'\n",
      " 'quotes' 'bands']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2596\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.0961, 0.5916, 0.5895, 0.5039, 0.4513, 0.4108, 0.4013, 0.3758, 0.3604,\n",
      "        0.3516], device='cuda:0')\n",
      "['alan' 'it' 'dell' 'jack' 'instance' 'font' 'ram' 'michigan'\n",
      " 'merchandise' 'www']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([782781.7500, 430332.5000, 109605.1875, 105754.5859,  99094.0078,\n",
      "         89862.9141,  82260.6250,  76168.2266,  70217.8672,  67409.1641],\n",
      "       device='cuda:0')\n",
      "['sponsors' 'et' 'kitchen' 'jobs' 'maryland' 'sponsor' 'interracial'\n",
      " 'anonymous' 'ink' 'javascript']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 113\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.2762, 1.0928, 0.8644, 0.7661, 0.7621, 0.7577, 0.5879, 0.5223, 0.4637,\n",
      "        0.4406], device='cuda:0')\n",
      "['case' 'epson' 'cars' 'oh' 'ha' 'covers' 'numerous' 'script' 'scottish'\n",
      " 'virgin']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1404599.8750,  929770.1875,  346467.9375,  273485.7500,  227378.1875,\n",
      "         204075.1719,  197068.3906,  193495.6875,  147224.5469,  132832.7500],\n",
      "       device='cuda:0')\n",
      "['cars' 'recipes' 'bags' 'citysearch' 'simpson' 'purple' 'idaho'\n",
      " 'businesses' 'flags' 'jobs']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2773\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.7634, 2.6096, 1.2825, 1.0430, 0.8330, 0.4472, 0.4115, 0.3987, 0.3913,\n",
      "        0.3823], device='cuda:0')\n",
      "['pair' 'site' 'park' 'summit' 'yard' 'area' 'meeting' 'place' 'flying'\n",
      " 'picture']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([3151554.5000, 2586489.0000, 2517548.7500, 1393750.8750,  510211.7500,\n",
      "         482900.5312,  384543.4062,  339118.8750,  329294.3125,  304920.1250],\n",
      "       device='cuda:0')\n",
      "['mountains' 'buildings' 'garden' 'beach' 'park' 'shops' 'mountain' 'lake'\n",
      " 'ships' 'building']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 478\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.9148, 1.5482, 1.3316, 1.2865, 0.7933, 0.5176, 0.5054, 0.4541, 0.4063,\n",
      "        0.3726], device='cuda:0')\n",
      "['net' 'gps' 'satellite' 'wet' 'cards' 'postal' 'walk' 'walking' 'walker'\n",
      " 'card']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2036104.2500,  282052.3125,  279825.3750,  242455.1094,  236608.9531,\n",
      "         231720.2812,  211089.6250,  205527.2812,  204361.0000,  184222.3750],\n",
      "       device='cuda:0')\n",
      "['computers' 'vehicles' 'laptops' 'net' 'keyboard' 'viagra' 'bags' 'pool'\n",
      " 'appliances' 'recipes']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 138\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([5.5246, 1.0001, 0.6018, 0.4210, 0.3853, 0.3800, 0.3163, 0.3023, 0.2921,\n",
      "        0.2837], device='cuda:0')\n",
      "['toll' 'richmond' 'porn' 'womens' 'latina' 'rear' 'greek' 'tx' 'felt'\n",
      " 'vietnam']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1209528.0000,  928855.8125,  643630.0625,  492798.3438,  274087.5000,\n",
      "         251971.1875,  210893.2500,  208696.9531,  168035.3750,  151444.9219],\n",
      "       device='cuda:0')\n",
      "['richmond' 'toll' 'phentermine' 'citysearch' 'customers' 'laptops'\n",
      " 'vermont' 'singapore' 'cities' 'women']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 854\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.8755, 1.6886, 0.8214, 0.6221, 0.6199, 0.5935, 0.5436, 0.5088, 0.4622,\n",
      "        0.4520], device='cuda:0')\n",
      "['tags' 'sizes' 'card' 'savings' 'coupons' 'receipt' 'requirement'\n",
      " 'pricing' 'cards' 'saving']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1910770.5000, 1350585.0000,  590585.7500,  404487.3750,  364833.9062,\n",
      "         264723.2812,  203464.9844,  199279.1250,  176483.0781,  170713.4844],\n",
      "       device='cuda:0')\n",
      "['coupons' 'tags' 'sizes' 'lingerie' 'receipt' 'certificates' 'pricing'\n",
      " 'labels' 'ratings' 'savings']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2594\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.1427, 1.9242, 1.1101, 1.0025, 0.9902, 0.7002, 0.6806, 0.5845, 0.5011,\n",
      "        0.3791], device='cuda:0')\n",
      "['font' 'thumbnail' 'banner' 'sign' 'shoes' 'wallpaper' 'wallpapers'\n",
      " 'counter' 'named' 'signature']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([3460862.5000, 2008878.3750,  928169.3125,  776814.6875,  695338.2500,\n",
      "         688779.1250,  495701.4688,  419794.7188,  349183.1562,  278981.0312],\n",
      "       device='cuda:0')\n",
      "['kitchen' 'boats' 'wallpapers' 'shoes' 'businesses' 'bathroom' 'beach'\n",
      " 'logos' 'quotes' 'pool']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1839\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.0845, 1.0867, 0.8770, 0.6789, 0.6354, 0.4899, 0.3641, 0.3344, 0.3334,\n",
      "        0.3180], device='cuda:0')\n",
      "['addition' 'numerous' 'oak' 'platform' 'attendance' 'narrow' 'anthony'\n",
      " 'subscriptions' 'immigration' 'guarantee']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([904587.1250, 343436.0938, 230345.5625, 189696.1250, 151000.9375,\n",
      "        144015.9375, 139269.7500, 138784.8281, 103439.5312, 102894.5234],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'databases' 'platform' 'warranty' 'warehouse' 'subscriptions'\n",
      " 'businesses' 'addresses' 'addition' 'diabetes']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1325\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.5977, 1.5490, 1.2763, 1.1500, 1.0709, 0.8068, 0.5979, 0.4897, 0.4136,\n",
      "        0.3658], device='cuda:0')\n",
      "['listings' 'leads' 'bidding' 'buffer' 'remove' 'ads' 'investor'\n",
      " 'thumbnail' 'conversion' 'auctions']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1012481.2500,  606655.0000,  269250.3125,  261797.0312,  214122.6406,\n",
      "         177393.2812,  162141.6719,  138531.7812,  138336.6875,  105877.2422],\n",
      "       device='cuda:0')\n",
      "['listings' 'bedroom' 'bedrooms' 'quotes' 'bidding' 'sitemap' 'affiliates'\n",
      " 'directories' 'ads' 'shorts']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2741\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5880, 1.2739, 0.6521, 0.6263, 0.5510, 0.4946, 0.4887, 0.4598, 0.4255,\n",
      "        0.4021], device='cuda:0')\n",
      "['draft' 'brief' 'breasts' 'brands' 'cart' 'breast' 'registry'\n",
      " 'representatives' 'restaurants' 'charter']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2387692.7500, 2093092.0000, 1506776.3750, 1366581.3750, 1102113.3750,\n",
      "         652765.6875,  627515.8125,  609487.0000,  447260.6562,  328388.8750],\n",
      "       device='cuda:0')\n",
      "['brands' 'restaurants' 'recipes' 'companies' 'sponsors' 'logos'\n",
      " 'catering' 'businesses' 'hospitals' 'physicians']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1405\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5963, 1.2731, 0.5864, 0.4873, 0.4221, 0.4050, 0.4006, 0.3820, 0.3363,\n",
      "        0.3263], device='cuda:0')\n",
      "['pool' 'sex' 'xx' 'bush' 'vhs' 'los' 'lists' 'residential' 'louis'\n",
      " 'resident']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([4944906.0000, 3106865.7500, 1212658.0000, 1178077.6250,  349529.3750,\n",
      "         316904.7812,  254927.7344,  211281.4844,  166682.7031,  161260.4062],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'pool' 'sex' 'bedrooms' 'bush' 'apartments' 'apartment'\n",
      " 'bathroom' 'shower' 'basketball']\n",
      "============================ steering_strength: 300.0 ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/1562 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "655\n",
      "656\n",
      "665\n",
      "204\n",
      "1692\n",
      "371\n",
      "1595\n",
      "2598\n",
      "546\n",
      "20\n",
      "606\n",
      "2536\n",
      "393\n",
      "2726\n",
      "2596\n",
      "113\n",
      "2773\n",
      "478\n",
      "138\n",
      "854\n",
      "2594\n",
      "1839\n",
      "1325\n",
      "2741\n",
      "1405\n",
      "========================================================================================\n",
      "\n",
      "For Feature 655\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.2346, 1.7028, 1.6495, 0.7784, 0.6857, 0.5166, 0.4697, 0.4448, 0.4188,\n",
      "        0.3939], device='cuda:0')\n",
      "['listening' 'for' 'pair' 'lot' 'estate' 'posts' 'post' 'costa'\n",
      " 'containing' 'latest']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([799613.5625, 490967.9688, 332448.9062, 245971.9688, 239566.9844,\n",
      "        128398.0781,  99453.7969,  80871.0781,  71839.8438,  65321.6367],\n",
      "       device='cuda:0')\n",
      "['laptops' 'laptop' 'pink' 'betting' 'jewellery' 'desk' 'tables' 'purple'\n",
      " 'tampa' 'catalog']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 656\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.2305, 1.7426, 1.5990, 1.1492, 1.0546, 0.5275, 0.4954, 0.4929, 0.4115,\n",
      "        0.3780], device='cuda:0')\n",
      "['threads' 'fabric' 'breast' 'elected' 'thread' 'leather' 'preferences'\n",
      " 'installed' 'highlights' 'womens']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([895247.9375, 865165.8750, 861791.1875, 466385.5000, 457349.2500,\n",
      "        436176.0938, 390627.3750, 331990.9688, 323013.9375, 258604.9688],\n",
      "       device='cuda:0')\n",
      "['ships' 'fabric' 'boats' 'navy' 'christmas' 'clothes' 'lingerie' 'horses'\n",
      " 'shirts' 'threads']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 665\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.1013, 1.8059, 1.6470, 1.1046, 0.8079, 0.7692, 0.6453, 0.4687, 0.3366,\n",
      "        0.2406], device='cuda:0')\n",
      "['anime' 'card' 'yard' 'ph' 'oh' 'ink' 'and' 'ave' 'japanese' 'ships']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1308731.2500,  882551.8125,  799282.6250,  449103.0000,  401780.5938,\n",
      "         364797.1875,  315062.5312,  253867.3438,  219296.8438,  215546.0000],\n",
      "       device='cuda:0')\n",
      "['ships' 'mountains' 'anime' 'companies' 'boats' 'navy' 'garden'\n",
      " 'universities' 'yard' 'ink']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 204\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([4.6133, 3.0763, 2.9761, 1.9470, 1.4353, 0.6697, 0.6463, 0.4584, 0.2635,\n",
      "        0.2571], device='cuda:0')\n",
      "['wallpapers' 'patterns' 'wallpaper' 'pattern' 'navy' 'wooden' 'leather'\n",
      " 'printable' 'nature' 'boat']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7149196.5000, 5867280.5000, 1939296.8750,  957825.0000,  844970.7500,\n",
      "         652327.8125,  388242.2500,  343516.9688,  322918.8750,  318525.8750],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'navy' 'boats' 'wallpaper' 'patterns' 'ships' 'pattern'\n",
      " 'trees' 'boat' 'forest']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1692\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.0680, 1.3093, 0.8820, 0.7845, 0.7520, 0.6518, 0.6178, 0.5139, 0.4650,\n",
      "        0.4479], device='cuda:0')\n",
      "['cumshot' 'card' 'ordering' 'page' 'drawing' 'border' 'adapter' 'jersey'\n",
      " 'front' 'by']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1651341.7500,  458481.4375,  242043.0312,  165021.4375,  161397.9688,\n",
      "         110782.9688,  106568.6094,  105099.4922,  101195.5781,   98569.4297],\n",
      "       device='cuda:0')\n",
      "['cumshot' 'bedroom' 'certificates' 'recipes' 'dress' 'catalog' 'boxes'\n",
      " 'notebooks' 'poster' 'catalogue']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 371\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.1623, 2.1583, 2.0422, 1.6338, 0.7480, 0.6405, 0.5663, 0.4113, 0.3163,\n",
      "        0.2683], device='cuda:0')\n",
      "['purple' 'basketball' 'dell' 'tree' 'button' 'name' 'card' 'jordan' 'pin'\n",
      " 'permalink']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([6388008.0000, 1720106.0000, 1392283.0000, 1296750.0000,  922015.5000,\n",
      "         774287.6875,  322777.5625,  229490.5312,  142079.7656,  110133.3125],\n",
      "       device='cuda:0')\n",
      "['purple' 'recipes' 'basketball' 'pink' 'tree' 'dress' 'desk' 'companies'\n",
      " 'nba' 'cake']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1595\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.4820, 0.9280, 0.8441, 0.5687, 0.5473, 0.5257, 0.4695, 0.4451, 0.4325,\n",
      "        0.4016], device='cuda:0')\n",
      "['thompson' 'poster' 'transportation' 'transport' 'zip' 'menu'\n",
      " 'transition' 'gray' 'traditional' 'shown']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1667916.3750,  417298.5312,  252034.3906,  248006.9375,  126731.9531,\n",
      "         125260.8047,  124834.1797,  121172.6953,  101996.3750,   97415.2969],\n",
      "       device='cuda:0')\n",
      "['recipes' 'poster' 'posters' 'quotes' 'restaurants' 'program'\n",
      " 'motorcycle' 'menu' 'programs' 'thompson']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2598\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5318, 0.7862, 0.4680, 0.3860, 0.3460, 0.3161, 0.3055, 0.3034, 0.2773,\n",
      "        0.2603], device='cuda:0')\n",
      "['font' 'lp' 'pearl' 'potter' 'toy' 'record' 'pick' 'thumbnail' 'stock'\n",
      " 'type']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([410297.0938, 257170.1562, 237551.9375, 234771.8750, 185827.0156,\n",
      "        122118.8906, 117053.6484, 114733.3750, 103417.6641, 102026.2656],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'attorney' 'recipes' 'lawyer' 'doctor' 'jewelry' 'doctors'\n",
      " 'pharmacy' 'picks' 'furniture']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 546\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.3677, 2.2901, 1.9692, 1.3308, 0.8218, 0.8072, 0.8046, 0.4931, 0.4005,\n",
      "        0.3703], device='cuda:0')\n",
      "['bars' 'quotes' 'facts' 'cumshots' 'posts' 'yard' 'counter' 'yards'\n",
      " 'shots' 'ships']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([50636832.0000,  5157101.0000,  2050471.2500,  2035089.6250,\n",
      "         1564518.8750,  1507680.3750,  1278386.7500,  1225660.1250,\n",
      "          378662.3438,   336747.4375], device='cuda:0')\n",
      "['quotes' 'boats' 'ships' 'shots' 'cumshots' 'recipes' 'facts' 'bathroom'\n",
      " 'colleges' 'papers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 20\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.2465, 1.6591, 0.9345, 0.7669, 0.7214, 0.6224, 0.4261, 0.4010, 0.3929,\n",
      "        0.3457], device='cuda:0')\n",
      "['front' 'card' 'shown' 'drivers' 'thumbnail' 'rack' 'supplied' 'includes'\n",
      " 'russell' 'reg']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([197165.4062, 164122.8125, 117572.5312, 105505.0938,  90867.9219,\n",
      "         88605.0156,  87399.0000,  75379.3750,  71478.6875,  71108.9844],\n",
      "       device='cuda:0')\n",
      "['drivers' 'customers' 'front' 'businesses' 'christmas' 'catalog' 'quotes'\n",
      " 'suppliers' 'lesbian' 'sponsors']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 606\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.3271, 2.3505, 1.5517, 1.0453, 0.7642, 0.6730, 0.6247, 0.5797, 0.5757,\n",
      "        0.5297], device='cuda:0')\n",
      "['front' 'net' 'wallpapers' 'affiliates' 'ice' 'foto' 'websites' 'article'\n",
      " 'newsletters' 'homepage']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2304533.2500, 2124968.2500, 1959270.2500, 1175503.8750, 1130952.2500,\n",
      "         993152.6250,  736083.3750,  735965.5000,  468884.3750,  460082.7500],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'businesses' 'brands' 'beach' 'companies' 'logos'\n",
      " 'affiliates' 'restaurants' 'recipes' 'shops']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2536\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.2258, 1.3082, 1.2387, 1.0072, 0.5699, 0.4083, 0.3428, 0.3200, 0.2353,\n",
      "        0.2287], device='cuda:0')\n",
      "['assumes' 'boots' 'lingerie' 'lane' 'commission' 'journal' 'shoes'\n",
      " 'glasses' 'large' 'lighting']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([12505090.0000,   638382.1875,   334871.0625,   332798.1250,\n",
      "          292957.0312,   240911.7188,   230403.9062,   212251.9062,\n",
      "          170581.4531,   169376.8906], device='cuda:0')\n",
      "['lingerie' 'boots' 'trees' 'laptops' 'shoes' 'jewellery' 'lights'\n",
      " 'flowers' 'roads' 'dress']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 393\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.3991, 1.9463, 1.6479, 1.4131, 0.6776, 0.6369, 0.4795, 0.3507, 0.3484,\n",
      "        0.3470], device='cuda:0')\n",
      "['wallpapers' 'wallpaper' 'mens' 'printable' 'windows' 'screen'\n",
      " 'thumbnail' 'cards' 'card' 'recruitment']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([3605233.7500, 1049004.6250,  650210.1875,  607401.3750,  390813.7188,\n",
      "         304982.7812,  302908.7500,  286214.2812,  230309.3438,  188086.5625],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'catalog' 'windows' 'wallpaper' 'catalogue' 'shirts'\n",
      " 'printable' 'limousines' 'bathroom' 'hunting']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2726\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.5226, 0.9601, 0.8943, 0.7979, 0.7819, 0.7741, 0.6199, 0.4566, 0.4158,\n",
      "        0.3951], device='cuda:0')\n",
      "['pets' 'dogs' 'printable' 'stars' 'merchandise' 'bears' 'sharing'\n",
      " 'friends' 'guides' 'pair']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2672093.5000, 2212523.0000, 1442687.6250, 1213010.0000, 1146000.3750,\n",
      "        1098850.0000,  739847.0625,  641485.8750,  284076.7188,  280519.4062],\n",
      "       device='cuda:0')\n",
      "['stars' 'pets' 'shops' 'appliances' 'dogs' 'bears' 'customers' 'quotes'\n",
      " 'bedrooms' 'farmers']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2596\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5276, 0.7405, 0.7388, 0.6434, 0.5398, 0.4872, 0.4613, 0.4204, 0.4198,\n",
      "        0.4171], device='cuda:0')\n",
      "['alan' 'after' 'dell' 'jack' 'ink' 'michigan' 'instance' 'front' 'it'\n",
      " 'allen']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1136974.1250,  291464.0938,  195251.8281,  179108.9062,  165756.1875,\n",
      "         152527.2188,  131976.7812,  112389.6172,  101943.5000,   83158.9688],\n",
      "       device='cuda:0')\n",
      "['sponsors' 'et' 'jobs' 'interracial' 'kitchen' 'ink' 'sponsor' 'black'\n",
      " 'maryland' 'desk']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 113\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.3207, 1.2001, 0.9559, 0.8896, 0.8030, 0.6726, 0.5951, 0.5697, 0.4383,\n",
      "        0.4166], device='cuda:0')\n",
      "['case' 'epson' 'cars' 'covers' 'oh' 'ha' 'script' 'numerous' 'simpson'\n",
      " 'scottish']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1667999.8750, 1273752.1250,  353383.9062,  347951.4375,  345994.3750,\n",
      "         284006.0625,  202185.4375,  151417.9375,  145249.2812,  139855.9844],\n",
      "       device='cuda:0')\n",
      "['cars' 'recipes' 'citysearch' 'bags' 'purple' 'simpson' 'flags' 'laptops'\n",
      " 'businesses' 'pink']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2773\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.0993, 1.9432, 1.3536, 1.2469, 0.8990, 0.5830, 0.4516, 0.4341, 0.4134,\n",
      "        0.4017], device='cuda:0')\n",
      "['site' 'pair' 'park' 'summit' 'yard' 'mountains' 'garden' 'mountain'\n",
      " 'place' 'meeting']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([9274109.0000, 3640980.7500, 3303141.5000, 2394557.2500, 1057176.2500,\n",
      "        1033935.2500,  775223.6250,  739368.2500,  547839.8750,  523555.5625],\n",
      "       device='cuda:0')\n",
      "['mountains' 'garden' 'buildings' 'beach' 'shops' 'mountain' 'window'\n",
      " 'ships' 'park' 'sky']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 478\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.8410, 1.6373, 1.6235, 1.4806, 0.6774, 0.6125, 0.5514, 0.5376, 0.5024,\n",
      "        0.4989], device='cuda:0')\n",
      "['gps' 'wet' 'net' 'satellite' 'cards' 'card' 'walk' 'belt' 'walker' 'pet']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1605416.8750,  438336.7812,  411826.7812,  267089.2188,  252687.2969,\n",
      "         230741.8594,  226636.2031,  219469.5000,  218245.1094,  216750.6719],\n",
      "       device='cuda:0')\n",
      "['computers' 'pool' 'vehicles' 'belt' 'keyboard' 'net' 'desk' 'viagra'\n",
      " 'recipes' 'satellite']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 138\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([6.4646, 1.2946, 0.5085, 0.4967, 0.3682, 0.3160, 0.3042, 0.2693, 0.2648,\n",
      "        0.2453], device='cuda:0')\n",
      "['toll' 'richmond' 'philippines' 'rear' 'vietnam' 'au' 'porn' 'womens'\n",
      " 'split' 'felt']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1784383.2500, 1205214.8750,  809814.6875,  532464.4375,  501464.5312,\n",
      "         368172.7188,  275188.9688,  263796.9375,  233913.3594,  209072.7812],\n",
      "       device='cuda:0')\n",
      "['richmond' 'toll' 'citysearch' 'laptops' 'phentermine' 'customers'\n",
      " 'vermont' 'singapore' 'philippines' 'companies']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 854\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.5455, 1.4651, 1.1411, 0.7403, 0.6065, 0.5519, 0.5401, 0.4392, 0.4171,\n",
      "        0.3831], device='cuda:0')\n",
      "['sizes' 'card' 'tags' 'cards' 'coupons' 'requirement' 'receipt' 'height'\n",
      " 'measurements' 'savings']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1952940.6250,  978102.7500,  894415.7500,  438777.0938,  380585.5938,\n",
      "         350120.0625,  330383.2812,  175579.8125,  175167.8125,  160151.0156],\n",
      "       device='cuda:0')\n",
      "['coupons' 'sizes' 'tags' 'lingerie' 'certificates' 'receipt' 'apartments'\n",
      " 'bags' 'labels' 'catalogue']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2594\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.1940, 1.6716, 1.5680, 1.3183, 1.0095, 0.6638, 0.6547, 0.6271, 0.6072,\n",
      "        0.5387], device='cuda:0')\n",
      "['font' 'thumbnail' 'banner' 'sign' 'shoes' 'wallpapers' 'signature'\n",
      " 'symbol' 'named' 'basket']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2901957.5000, 2435375.5000, 1018035.6250,  978086.7500,  868990.3750,\n",
      "         719328.1875,  692292.9375,  441226.0312,  438815.5312,  381884.2812],\n",
      "       device='cuda:0')\n",
      "['kitchen' 'boats' 'wallpapers' 'logos' 'shoes' 'businesses' 'beach'\n",
      " 'citysearch' 'bathroom' 'quotes']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1839\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.6299, 1.0639, 0.9472, 0.9043, 0.8312, 0.8016, 0.6598, 0.3441, 0.3272,\n",
      "        0.3173], device='cuda:0')\n",
      "['addition' 'numerous' 'narrow' 'oak' 'attendance' 'platform' 'anthony'\n",
      " 'affordable' 'monitoring' 'guarantee']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([976274.3750, 351585.9062, 287022.0000, 238234.3750, 204085.7969,\n",
      "        140007.5156, 125673.2812, 122941.3984, 122924.6953, 106967.5078],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'databases' 'platform' 'warranty' 'businesses' 'addresses'\n",
      " 'attendance' 'warehouse' 'bedrooms' 'subscriptions']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1325\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.0002, 1.5100, 1.2720, 1.2246, 0.9488, 0.8746, 0.4847, 0.4065, 0.3626,\n",
      "        0.3361], device='cuda:0')\n",
      "['listings' 'leads' 'bidding' 'remove' 'buffer' 'ads' 'thumbnail'\n",
      " 'sitemap' 'investor' 'conversion']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1247301.8750,  878731.1875,  400687.7188,  364350.9375,  296231.1562,\n",
      "         225619.9531,  199253.6562,  196327.9531,  151588.9062,  149121.0312],\n",
      "       device='cuda:0')\n",
      "['listings' 'bedroom' 'quotes' 'sitemap' 'bedrooms' 'bidding' 'shorts'\n",
      " 'affiliates' 'ads' 'directories']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2741\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.8869, 1.3027, 1.0810, 0.6752, 0.6323, 0.6158, 0.5085, 0.4953, 0.4373,\n",
      "        0.3056], device='cuda:0')\n",
      "['draft' 'brief' 'brands' 'registry' 'breasts' 'breast' 'cart'\n",
      " 'representatives' 'charter' 'broad']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([4231676.5000, 2345371.7500, 1708894.1250, 1695248.6250, 1619331.3750,\n",
      "         881186.3125,  611695.3750,  601484.9375,  318897.8750,  260041.0312],\n",
      "       device='cuda:0')\n",
      "['brands' 'companies' 'restaurants' 'sponsors' 'recipes' 'logos'\n",
      " 'businesses' 'catering' 'hospitals' 'physicians']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1405\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([4.0890, 1.3036, 0.8129, 0.5798, 0.3026, 0.3023, 0.2945, 0.2899, 0.2847,\n",
      "        0.2743], device='cuda:0')\n",
      "['pool' 'sex' 'vhs' 'los' 'flood' 'xx' 'heating' 'bedrooms' 'louis'\n",
      " 'lists']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([8473828.0000, 7162815.0000, 1413046.3750, 1303823.6250,  381346.2812,\n",
      "         326636.3750,  320526.9062,  312858.1562,  305713.8750,  192945.1406],\n",
      "       device='cuda:0')\n",
      "['pool' 'bedroom' 'sex' 'bedrooms' 'bathroom' 'apartment' 'apartments'\n",
      " 'shower' 'vhs' 'bush']\n",
      "============================ steering_strength: 500.0 ============================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                            | 0/1562 [00:02<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text_features_normed.shape: torch.Size([5000, 512])\n",
      "655\n",
      "656\n",
      "665\n",
      "204\n",
      "1692\n",
      "371\n",
      "1595\n",
      "2598\n",
      "546\n",
      "20\n",
      "606\n",
      "2536\n",
      "393\n",
      "2726\n",
      "2596\n",
      "113\n",
      "2773\n",
      "478\n",
      "138\n",
      "854\n",
      "2594\n",
      "1839\n",
      "1325\n",
      "2741\n",
      "1405\n",
      "========================================================================================\n",
      "\n",
      "For Feature 655\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.8452, 1.6594, 1.5318, 0.7851, 0.6719, 0.4717, 0.4417, 0.4362, 0.4314,\n",
      "        0.4276], device='cuda:0')\n",
      "['listening' 'pair' 'for' 'lot' 'estate' 'costa' 'laptop' 'posts'\n",
      " 'containing' 'post']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([821473.8750, 570925.7500, 419022.0000, 283203.1562, 258654.3750,\n",
      "        136030.2812, 105980.2578,  91627.6094,  83168.8125,  77567.2109],\n",
      "       device='cuda:0')\n",
      "['laptops' 'laptop' 'pink' 'jewellery' 'betting' 'desk' 'purple' 'tables'\n",
      " 'tampa' 'catalog']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 656\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.0230, 1.7687, 1.6539, 1.1005, 1.0040, 0.5000, 0.4982, 0.4947, 0.4487,\n",
      "        0.4379], device='cuda:0')\n",
      "['threads' 'breast' 'fabric' 'elected' 'thread' 'preferences' 'horses'\n",
      " 'highlights' 'leather' 'interior']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1179070.6250, 1093268.2500,  842400.6250,  595244.3125,  507588.0938,\n",
      "         504872.9375,  450838.0625,  435781.3438,  409622.5000,  319281.1562],\n",
      "       device='cuda:0')\n",
      "['ships' 'boats' 'fabric' 'navy' 'clothes' 'horses' 'lingerie' 'shirts'\n",
      " 'christmas' 'roses']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 665\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.9022, 1.8787, 1.4490, 1.2095, 0.8167, 0.8057, 0.7012, 0.5266, 0.2855,\n",
      "        0.2609], device='cuda:0')\n",
      "['anime' 'card' 'yard' 'ph' 'oh' 'ink' 'and' 'ave' 'japanese' 'import']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1377772.5000,  996846.2500,  731236.3750,  518529.4375,  414484.5312,\n",
      "         364268.6562,  303673.7500,  289529.7812,  229658.4844,  205661.8125],\n",
      "       device='cuda:0')\n",
      "['ships' 'mountains' 'anime' 'companies' 'boats' 'navy' 'universities'\n",
      " 'garden' 'ink' 'colleges']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 204\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([4.8382, 3.1491, 3.0409, 2.0269, 1.5658, 0.8919, 0.6429, 0.5226, 0.3223,\n",
      "        0.2955], device='cuda:0')\n",
      "['wallpapers' 'patterns' 'wallpaper' 'pattern' 'navy' 'wooden' 'leather'\n",
      " 'printable' 'header' 'boat']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([7752465.0000, 6515175.5000, 2624763.2500, 1004435.6875,  880885.1250,\n",
      "         651342.2500,  412051.3750,  395336.2500,  383893.0000,  323500.9688],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'navy' 'boats' 'wallpaper' 'patterns' 'ships' 'pattern'\n",
      " 'trees' 'boat' 'forest']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1692\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.9227, 1.5700, 0.9381, 0.8913, 0.7928, 0.6524, 0.6101, 0.5530, 0.4656,\n",
      "        0.3837], device='cuda:0')\n",
      "['cumshot' 'card' 'ordering' 'drawing' 'page' 'adapter' 'border' 'jersey'\n",
      " 'front' 'by']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1596190.6250,  580486.7500,  289896.2812,  191401.3906,  159992.6094,\n",
      "         141548.7031,  129291.3750,  124293.8750,  117063.2422,  112280.3203],\n",
      "       device='cuda:0')\n",
      "['cumshot' 'bedroom' 'certificates' 'recipes' 'dress' 'catalog' 'boxes'\n",
      " 'catalogue' 'poster' 'notebooks']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 371\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.3103, 2.2398, 2.2178, 1.8285, 0.7117, 0.6446, 0.6173, 0.4127, 0.3131,\n",
      "        0.2727], device='cuda:0')\n",
      "['dell' 'purple' 'basketball' 'tree' 'button' 'name' 'card' 'jordan' 'pin'\n",
      " 'pink']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([6817804.0000, 1816036.1250, 1598904.1250, 1447678.1250, 1032993.6250,\n",
      "         831553.3750,  375072.6250,  253383.9062,  146411.6562,  125015.4688],\n",
      "       device='cuda:0')\n",
      "['purple' 'recipes' 'pink' 'basketball' 'tree' 'dress' 'desk' 'companies'\n",
      " 'nba' 'trees']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1595\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.7032, 1.0121, 0.9699, 0.6696, 0.5974, 0.5353, 0.4877, 0.4620, 0.4565,\n",
      "        0.4435], device='cuda:0')\n",
      "['thompson' 'poster' 'transportation' 'menu' 'transport' 'shown' 'zip'\n",
      " 'traditional' 'gray' 'transition']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2094543.2500,  466668.3125,  293625.9688,  289026.2500,  156517.0312,\n",
      "         156347.7969,  129203.6016,  121575.1562,  113255.8906,  103802.6875],\n",
      "       device='cuda:0')\n",
      "['recipes' 'poster' 'quotes' 'posters' 'menu' 'restaurants' 'program'\n",
      " 'motorcycle' 'thompson' 'programs']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2598\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.5254, 0.9227, 0.4425, 0.3876, 0.3389, 0.3291, 0.3248, 0.3028, 0.2866,\n",
      "        0.2497], device='cuda:0')\n",
      "['font' 'lp' 'pearl' 'potter' 'record' 'toy' 'pick' 'title' 'thumbnail'\n",
      " 'type']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([507832.8125, 306140.6250, 238988.5156, 206188.5000, 190886.7500,\n",
      "        130148.4609, 129311.5000, 119109.3672, 111610.8750, 105460.8672],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'recipes' 'attorney' 'lawyer' 'doctor' 'doctors' 'jewelry'\n",
      " 'picks' 'furniture' 'pharmacy']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 546\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.4227, 2.3021, 1.8974, 1.8410, 0.7722, 0.7714, 0.7016, 0.5319, 0.4785,\n",
      "        0.4240], device='cuda:0')\n",
      "['bars' 'quotes' 'cumshots' 'facts' 'counter' 'yard' 'posts' 'shots'\n",
      " 'yards' 'boats']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([51146396.0000,  6766153.5000,  2835597.0000,  2392978.5000,\n",
      "         2289484.7500,  1835542.1250,  1320150.2500,  1197643.1250,\n",
      "          337254.9688,   319317.1250], device='cuda:0')\n",
      "['quotes' 'boats' 'shots' 'ships' 'cumshots' 'recipes' 'bathroom' 'facts'\n",
      " 'colleges' 'laptops']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 20\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.4079, 2.0080, 1.0389, 0.8115, 0.7598, 0.5985, 0.4649, 0.4161, 0.3732,\n",
      "        0.3545], device='cuda:0')\n",
      "['front' 'card' 'shown' 'thumbnail' 'drivers' 'rack' 'includes' 'supplied'\n",
      " 'russell' 'file']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([198330.7188, 134875.8906, 129988.4766, 108520.7031, 104219.9688,\n",
      "         94611.3438,  93797.0469,  89464.1875,  88821.7656,  70137.1484],\n",
      "       device='cuda:0')\n",
      "['drivers' 'customers' 'front' 'catalog' 'quotes' 'christmas' 'businesses'\n",
      " 'catalogue' 'creek' 'sponsors']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 606\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([4.0924, 2.2490, 1.7059, 0.9756, 0.7656, 0.6915, 0.6427, 0.6345, 0.5758,\n",
      "        0.5561], device='cuda:0')\n",
      "['front' 'net' 'wallpapers' 'affiliates' 'websites' 'foto' 'ice'\n",
      " 'homepage' 'article' 'newsletters']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2667959.2500, 2190085.5000, 2003725.6250, 1250657.8750, 1233651.6250,\n",
      "        1183094.1250,  807195.7500,  695407.8125,  456517.9375,  456133.2500],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'brands' 'businesses' 'logos' 'companies' 'beach'\n",
      " 'restaurants' 'affiliates' 'shops' 'recipes']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2536\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.2484, 1.5341, 1.4611, 0.9772, 0.5025, 0.4059, 0.3905, 0.3713, 0.3422,\n",
      "        0.2817], device='cuda:0')\n",
      "['assumes' 'lingerie' 'boots' 'lane' 'commission' 'journal' 'shoes'\n",
      " 'glasses' 'lighting' 'front']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([16155314.0000,   736444.7500,   382466.0312,   372484.7500,\n",
      "          345167.5625,   315292.8438,   242554.0156,   233106.2656,\n",
      "          201766.1719,   191973.2031], device='cuda:0')\n",
      "['lingerie' 'boots' 'trees' 'laptops' 'shoes' 'lights' 'jewellery'\n",
      " 'flowers' 'catalogue' 'dress']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 393\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.3910, 1.9670, 1.8826, 1.8575, 0.6752, 0.6254, 0.5467, 0.4074, 0.3949,\n",
      "        0.3591], device='cuda:0')\n",
      "['wallpapers' 'wallpaper' 'mens' 'printable' 'windows' 'screen'\n",
      " 'thumbnail' 'replacement' 'card' 'cards']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([3752818.5000, 1271304.6250,  663150.5625,  638900.0000,  502519.5000,\n",
      "         407124.0000,  381434.0938,  292170.0000,  259159.6719,  162967.5000],\n",
      "       device='cuda:0')\n",
      "['wallpapers' 'catalog' 'windows' 'wallpaper' 'catalogue' 'printable'\n",
      " 'shirts' 'limousines' 'bathroom' 'mens']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2726\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.7628, 1.1587, 0.9932, 0.8779, 0.8405, 0.7014, 0.6252, 0.4783, 0.3491,\n",
      "        0.3294], device='cuda:0')\n",
      "['pets' 'dogs' 'printable' 'stars' 'bears' 'merchandise' 'sharing'\n",
      " 'friends' 'pair' 'guides']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2978085.0000, 2485363.7500, 1512741.1250, 1511416.3750, 1404908.5000,\n",
      "        1210662.0000,  836621.1875,  827574.9375,  320507.0312,  286712.7812],\n",
      "       device='cuda:0')\n",
      "['stars' 'pets' 'shops' 'appliances' 'dogs' 'bears' 'quotes' 'customers'\n",
      " 'bedrooms' 'cats']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2596\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.6464, 0.9712, 0.7784, 0.6897, 0.6781, 0.5210, 0.5115, 0.4340, 0.4253,\n",
      "        0.4057], device='cuda:0')\n",
      "['alan' 'after' 'dell' 'jack' 'ink' 'michigan' 'front' 'instance' 'allen'\n",
      " 'www']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1309097.6250,  248114.0469,  239742.2656,  238925.4844,  194389.5938,\n",
      "         186788.8438,  151547.7188,  137702.7969,   97871.4453,   94334.4922],\n",
      "       device='cuda:0')\n",
      "['sponsors' 'jobs' 'et' 'interracial' 'ink' 'kitchen' 'sponsor' 'black'\n",
      " 'maryland' 'laptops']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 113\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.3232, 1.1973, 0.9963, 0.9148, 0.7955, 0.6233, 0.6232, 0.5473, 0.4685,\n",
      "        0.4278], device='cuda:0')\n",
      "['case' 'epson' 'cars' 'covers' 'oh' 'ha' 'script' 'numerous' 'simpson'\n",
      " 'mi']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1782244.1250, 1365237.3750,  416640.8750,  387976.3125,  336183.1875,\n",
      "         310284.0312,  224127.9844,  164271.9375,  156830.9375,  140350.2500],\n",
      "       device='cuda:0')\n",
      "['cars' 'recipes' 'purple' 'citysearch' 'bags' 'simpson' 'flags' 'laptops'\n",
      " 'pink' 'cats']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2773\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.1665, 1.5146, 1.3686, 1.2030, 0.9335, 0.8795, 0.6181, 0.4788, 0.4416,\n",
      "        0.3848], device='cuda:0')\n",
      "['site' 'pair' 'park' 'summit' 'yard' 'mountains' 'mountain' 'garden'\n",
      " 'sky' 'place']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([14071230.0000,  4022893.0000,  3711028.5000,  2826417.2500,\n",
      "         1503570.7500,  1463912.8750,  1171204.5000,   972006.3750,\n",
      "          768217.3750,   557892.1250], device='cuda:0')\n",
      "['mountains' 'garden' 'buildings' 'beach' 'shops' 'mountain' 'window'\n",
      " 'ships' 'sky' 'park']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 478\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.8818, 1.6864, 1.4566, 1.4344, 0.7505, 0.6280, 0.6102, 0.5832, 0.5454,\n",
      "        0.5134], device='cuda:0')\n",
      "['gps' 'wet' 'net' 'satellite' 'card' 'cards' 'belt' 'pet' 'walk' 'walker']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1410219.5000,  572744.0625,  469981.3750,  323998.3125,  257712.5312,\n",
      "         252670.1875,  241666.7812,  239298.5156,  220022.9688,  217284.2500],\n",
      "       device='cuda:0')\n",
      "['computers' 'pool' 'vehicles' 'belt' 'desk' 'keyboard' 'recipes' 'boats'\n",
      " 'wet' 'satellite']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 138\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([6.7233, 1.3604, 0.6994, 0.5156, 0.3708, 0.3353, 0.2849, 0.2564, 0.2551,\n",
      "        0.2271], device='cuda:0')\n",
      "['toll' 'richmond' 'philippines' 'rear' 'vietnam' 'au' 'split' 'laptops'\n",
      " 'ny' 'porn']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1963520.7500, 1292381.5000, 1010057.7500,  723075.4375,  444938.4688,\n",
      "         401963.0312,  320871.0625,  307211.8125,  288893.5312,  274083.7500],\n",
      "       device='cuda:0')\n",
      "['richmond' 'toll' 'citysearch' 'laptops' 'phentermine' 'customers'\n",
      " 'philippines' 'companies' 'vermont' 'singapore']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 854\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.9181, 1.8446, 0.9240, 0.8769, 0.5678, 0.5216, 0.5139, 0.4680, 0.4605,\n",
      "        0.3885], device='cuda:0')\n",
      "['sizes' 'card' 'tags' 'cards' 'coupons' 'receipt' 'requirement'\n",
      " 'measurements' 'height' 'maintenance']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1859564.7500, 1155548.8750,  743835.2500,  441827.7188,  434814.4375,\n",
      "         428178.6250,  343454.4688,  210698.5938,  205899.7969,  201211.7344],\n",
      "       device='cuda:0')\n",
      "['coupons' 'sizes' 'tags' 'certificates' 'lingerie' 'apartments' 'receipt'\n",
      " 'buildings' 'router' 'bathroom']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2594\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([2.1201, 1.7385, 1.5036, 1.4168, 0.9892, 0.7898, 0.7851, 0.6542, 0.6421,\n",
      "        0.5935], device='cuda:0')\n",
      "['font' 'banner' 'thumbnail' 'sign' 'shoes' 'signature' 'symbol'\n",
      " 'wallpapers' 'named' 'basket']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([2575603.5000, 2511213.5000, 1358309.3750, 1040752.1875,  877303.0625,\n",
      "         768154.4375,  694595.9375,  529737.5000,  407802.5000,  400254.1875],\n",
      "       device='cuda:0')\n",
      "['kitchen' 'boats' 'logos' 'wallpapers' 'shoes' 'beach' 'businesses'\n",
      " 'citysearch' 'sea' 'quotes']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1839\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.3635, 1.1346, 1.0250, 0.9259, 0.8612, 0.7988, 0.7627, 0.3945, 0.3944,\n",
      "        0.3089], device='cuda:0')\n",
      "['addition' 'narrow' 'numerous' 'attendance' 'oak' 'anthony' 'platform'\n",
      " 'monitoring' 'affordable' 'amounts']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([988598.9375, 343576.0938, 279280.5625, 249616.5156, 240667.9531,\n",
      "        144926.4688, 141386.5469, 137037.0781, 133050.5312, 123893.1328],\n",
      "       device='cuda:0')\n",
      "['bedroom' 'databases' 'platform' 'warranty' 'businesses' 'recipes'\n",
      " 'attendance' 'addresses' 'bedrooms' 'purple']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1325\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([3.1179, 1.4296, 1.2648, 1.2150, 0.9210, 0.8355, 0.5543, 0.4855, 0.3212,\n",
      "        0.3132], device='cuda:0')\n",
      "['listings' 'leads' 'remove' 'bidding' 'ads' 'buffer' 'sitemap'\n",
      " 'thumbnail' 'listing' 'printable']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([1321141.8750,  998457.9375,  509052.5000,  488908.6875,  297258.0000,\n",
      "         251860.4844,  220048.3438,  207403.2812,  191740.4531,  159990.7031],\n",
      "       device='cuda:0')\n",
      "['listings' 'bedroom' 'sitemap' 'quotes' 'bedrooms' 'shorts' 'bidding'\n",
      " 'affiliates' 'bathroom' 'ads']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 2741\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([1.9580, 1.3410, 1.2733, 0.7332, 0.6476, 0.5962, 0.5122, 0.4577, 0.4391,\n",
      "        0.3341], device='cuda:0')\n",
      "['draft' 'brands' 'brief' 'registry' 'breast' 'breasts' 'representatives'\n",
      " 'cart' 'charter' 'logos']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([5283648.0000, 2924777.5000, 2010074.0000, 1606387.2500, 1545736.0000,\n",
      "         987600.6875,  614350.5625,  587157.6875,  285979.0625,  248569.2188],\n",
      "       device='cuda:0')\n",
      "['brands' 'companies' 'sponsors' 'recipes' 'restaurants' 'logos'\n",
      " 'businesses' 'catering' 'hospitals' 'restaurant']\n",
      "========================================================================================\n",
      "\n",
      "For Feature 1405\n",
      "text_probs_altered.softmax(): torch.Size([32, 5000])\n",
      "\n",
      "Most Changed, by Absolute Diff Over 32 Images:\n",
      "tensor([5.6341, 1.1810, 0.9582, 0.6237, 0.3481, 0.2812, 0.2640, 0.2632, 0.2541,\n",
      "        0.2537], device='cuda:0')\n",
      "['pool' 'sex' 'vhs' 'los' 'flood' 'bedrooms' 'heating' 'vs' 'case' 'louis']\n",
      "\n",
      "Most Changed, by Ratio Over 32 Images:\n",
      "tensor([11758970.0000,  8104548.0000,  1334392.6250,  1303291.6250,\n",
      "          477888.9062,   376399.8438,   368158.5625,   344161.7812,\n",
      "          316802.3438,   173440.2344], device='cuda:0')\n",
      "['pool' 'bedroom' 'sex' 'bedrooms' 'bathroom' 'shower' 'vhs' 'apartment'\n",
      " 'apartments' 'quotes']\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "from collections import defaultdict\n",
    "max_samples = cfg.eval_max\n",
    "\n",
    "encoder_biases = sparse_autoencoder.b_enc#[interesting_features_indices]\n",
    "encoder_weights = sparse_autoencoder.W_enc#[:, interesting_features_indices]\n",
    "\n",
    "steering_strengths = [0.0, 5.0, 10.0, 20.0, 50.0, 150.0, 300.0, 500.0]#, -200.0, -300.0]\n",
    "\n",
    "\n",
    "steering_strength_image_results = defaultdict(dict)\n",
    "steering_strength_info = {}\n",
    "\n",
    "og_model.cuda()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for steering_strength in steering_strengths:\n",
    "    print(f\"{'==============' * 2} steering_strength: {steering_strength} {'==============' * 2}\")\n",
    "    # ===== Get Steered and Default CLIP Outputs =====\n",
    "    top_k=10\n",
    "    processed_samples = 0\n",
    "    default_embeds_list = []\n",
    "    feature_steered_embeds = defaultdict(list)\n",
    "    l = 0\n",
    "    \n",
    "    # remove tqdm\n",
    "    for batch_images, _, batch_indices in tqdm(val_dataloader, total=max_samples // cfg.batch_size):\n",
    "        batch_images = batch_images.to(cfg.device)\n",
    "        batch_indices = batch_indices.to(cfg.device)\n",
    "        batch_size = batch_images.shape[0]\n",
    "\n",
    "        altered_embeds_list, default_embeds = compute_feature_activations_set_feat(\n",
    "            batch_images, model, sparse_autoencoder, encoder_weights, encoder_biases,\n",
    "            None, None, top_k, steering_strength\n",
    "        )\n",
    "        default_embeds_list.append(default_embeds)\n",
    "        for j, altered_embeds in enumerate(altered_embeds_list):\n",
    "            feature_steered_embeds[random_feat_idxs[j]].extend(altered_embeds)\n",
    "        # either label embeds or optimize to maximal token in text transformer embedding face\n",
    "        l += 1\n",
    "        if l >= 1:\n",
    "            break    \n",
    "    default_embeds = torch.cat(default_embeds_list)\n",
    "    \n",
    "    with open(\"/workspace/clip_dissect_raw.txt\", \"r\") as f:\n",
    "        larger_vocab = [line[:-1] for line in f.readlines()][:5000]\n",
    "\n",
    "\n",
    "    # ===== CLIP Embeds =====\n",
    "    # use clip vocab here and compare embeds\n",
    "    tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "    text = tokenizer(larger_vocab)\n",
    "    text_features = og_model.encode_text(text.cuda())\n",
    "    text_features_normed = text_features/text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "    print(f\"text_features_normed.shape: {text_features_normed.shape}\")\n",
    "    text_probs_altered_list = []\n",
    "    with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "        for key in feature_steered_embeds:\n",
    "            print(key)\n",
    "            # embeds already have L2 norm of 1\n",
    "            text_probs_altered = (100.0 * torch.stack(feature_steered_embeds[key]) @ text_features_normed.T).softmax(dim=-1)\n",
    "            text_probs_altered_list.append(text_probs_altered)\n",
    "        text_probs_default = (100.0 * default_embeds @ text_features_normed.T).softmax(dim=-1)\n",
    "\n",
    "#     print(\"Label probs altered:\", text_probs_altered.shape)  # prints: [[1., 0., 0.]]\n",
    "#     print(\"Label probs default:\", text_probs_default.shape)  # prints: [[1., 0., 0.]]\n",
    "    \n",
    "    \n",
    "    # ===== Logit Difference =====\n",
    "    # indexed as such in steering_strength_image_results:\n",
    "    # per steering strength\n",
    "    # per feature\n",
    "    # per image\n",
    "    \n",
    "    selected_vocab = larger_vocab\n",
    "\n",
    "    top_concept_per_feat = {}\n",
    "    top_val_per_feat = {}\n",
    "    top_diff_per_feat = {}\n",
    "    top_ratio_per_feat = {}\n",
    "    \n",
    "    # run this for sampled features over all of imagenet eval\n",
    "    for j, text_probs_altered in enumerate(text_probs_altered_list):\n",
    "        print(f\"{'============================================'*2}\\n\\nFor Feature {random_feat_idxs[j]}\")\n",
    "#         print(\"actual image content:\")\n",
    "        default_vals_softmax, default_idxs_softmax = torch.topk(text_probs_default,k=10)\n",
    "#         print(default_vals_softmax, \"\\n\", np.array(selected_vocab)[default_idxs_softmax.cpu()])\n",
    "\n",
    "\n",
    "        logit_diff = text_probs_altered - text_probs_default\n",
    "        logit_diff_aggregate = logit_diff.sum(dim=0)\n",
    "\n",
    "        logit_ratio = text_probs_altered/text_probs_default\n",
    "        logit_ratio_aggregate = logit_ratio.mean(dim=0)\n",
    "\n",
    "        print(f\"text_probs_altered.softmax(): {text_probs_altered.softmax(1).shape}\")\n",
    "        text_probs_altered_softmax = text_probs_altered.softmax(1)\n",
    "        vals_softmax, idxs_softmax = torch.topk(text_probs_altered_softmax,k=10)\n",
    "\n",
    "    #     print(f\"text_probs_altered.softmax(): {text_probs_altered.sum(0).softmax(0).shape}\")\n",
    "    #     text_probs_altered_softmax_agg = text_probs_altered.sum(0).softmax(0)\n",
    "    #     vals_softmax_agg, idxs_softmax_agg = torch.topk(text_probs_altered_softmax_agg,k=10)\n",
    "\n",
    "#         print(f\"\\nSoftmax Over {text_probs_altered.shape[0]} Images:\\n{vals_softmax}\")\n",
    "#         print(np.array(selected_vocab)[idxs_softmax.cpu()])\n",
    "#         for i in range(vals_softmax.shape[0]):\n",
    "#             print(vals_softmax[i], \"\\n\", np.array(selected_vocab)[idxs_softmax.cpu()][i])\n",
    "#             break\n",
    "\n",
    "    #     print(f\"\\nAgg Softmax Over {text_probs_altered.shape[0]} Images:\\n{vals_softmax_agg}\")\n",
    "    #     print(np.array(selected_vocab)[idxs_softmax_agg.cpu()])\n",
    "\n",
    "        vals_agg, idxs_agg = torch.topk(logit_diff_aggregate,k=10)\n",
    "        vals_least_agg, idxs_least_agg = torch.topk(logit_diff_aggregate,k=10,largest=False)\n",
    "\n",
    "        ratios_agg, ratios_idxs_agg = torch.topk(logit_ratio_aggregate,k=10)\n",
    "        ratios_least_agg, ratios_idxs_least_agg = torch.topk(logit_ratio_aggregate,k=10,largest=False)\n",
    "\n",
    "        vals, idxs = torch.topk(logit_diff,k=5)\n",
    "        vals_least, idxs_least = torch.topk(logit_diff,k=5,largest=False)\n",
    "\n",
    "        ratios, ratios_idxs = torch.topk(logit_ratio,k=5)\n",
    "        ratios_least, ratios_idxs_least = torch.topk(logit_ratio,k=5,largest=False)\n",
    "\n",
    "        # random_feat_idxs[j] is the index of the feature\n",
    "        for img_idx in range(batch_images.shape[0]):\n",
    "            if random_feat_idxs[j] not in steering_strength_image_results[str(steering_strength)].keys():\n",
    "                steering_strength_image_results[str(steering_strength)][random_feat_idxs[j].copy()] = []\n",
    "            # entries are torch.topk(k=10) results\n",
    "            steering_strength_image_results[str(steering_strength)][random_feat_idxs[j]].append((np.array(selected_vocab, copy=True)[idxs_softmax.cpu()][img_idx], torch.clone(vals_softmax[img_idx])))\n",
    "        \n",
    "        # per image\n",
    "        top_concept_per_feat[random_feat_idxs[j]] = np.array(selected_vocab)[idxs_softmax.cpu()][0][0]\n",
    "        top_val_per_feat[random_feat_idxs[j]] = vals_softmax[0][0]\n",
    "        \n",
    "        # aggregate\n",
    "        top_diff_per_feat[random_feat_idxs[j]] = vals_agg[0]\n",
    "        top_ratio_per_feat[random_feat_idxs[j]] = ratios_agg[0]\n",
    "\n",
    "\n",
    "        print(f\"\\nMost Changed, by Absolute Diff Over {logit_diff.shape[0]} Images:\\n{vals_agg}\")\n",
    "        print(np.array(selected_vocab)[idxs_agg.cpu()])\n",
    "#         print(vals_least_agg)\n",
    "#         print(np.array(selected_vocab)[idxs_least_agg.cpu()])\n",
    "\n",
    "        print(f\"\\nMost Changed, by Ratio Over {logit_diff.shape[0]} Images:\")\n",
    "        print(ratios_agg)\n",
    "        print(np.array(selected_vocab)[ratios_idxs_agg.cpu()])\n",
    "#         print(ratios_least_agg)\n",
    "#         print(np.array(selected_vocab)[ratios_idxs_least_agg.cpu()])\n",
    "    \n",
    "    steering_strength_info[steering_strength] = (top_concept_per_feat,top_val_per_feat,top_ratio_per_feat,top_diff_per_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(dict_keys(['0.0', '5.0', '10.0', '20.0', '50.0', '150.0', '300.0', '500.0']),\n",
       " dict_keys([655, 656, 665, 204, 1692, 371, 1595, 2598, 546, 20, 606, 2536, 393, 2726, 2596, 113, 2773, 478, 138, 854, 2594, 1839, 1325, 2741, 1405]))"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "steering_strength_image_results.keys(), steering_strength_image_results[str(steering_strength)].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=====================\n",
      "feat_num: 665\n",
      "0.0 bed\n",
      "0.0 0.00027093198150396347\n",
      "5.0 dolls\n",
      "5.0 0.00026961290859617293\n",
      "10.0 dolls\n",
      "10.0 0.0002578500716481358\n",
      "20.0 cute\n",
      "20.0 0.00025297317188233137\n",
      "50.0 cute\n",
      "50.0 0.00021267806005198509\n",
      "150.0 anime\n",
      "150.0 0.00022063031792640686\n",
      "300.0 anime\n",
      "300.0 0.00021524658950511366\n",
      "500.0 anime\n",
      "500.0 0.00021318456856533885\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "# 0: python, 3: bowl, 4: bed, 6: guinea\n",
    "image_idx = 4\n",
    "feat_num = 665\n",
    "\n",
    "# to iterate over many features:\n",
    "# for feat_num in steering_strength_image_results[str(steering_strength)].keys():\n",
    "\n",
    "print(f\"=====================\\nfeat_num: {feat_num}\")\n",
    "feat_num_concept_arr = []\n",
    "feat_num_prob_arr = []\n",
    "for dict_key in steering_strengths:\n",
    "    # image, tuple position, idx of top-k\n",
    "    # modify this to do top-k at some point\n",
    "    print(str(dict_key), steering_strength_image_results[str(dict_key)][feat_num][image_idx][0][0])\n",
    "    feat_num_concept_arr.append((dict_key, steering_strength_image_results[str(dict_key)][feat_num][image_idx][0][0]))\n",
    "    print(str(dict_key), steering_strength_image_results[str(dict_key)][feat_num][image_idx][1][0].item())\n",
    "    feat_num_prob_arr.append((dict_key, steering_strength_image_results[str(dict_key)][feat_num][image_idx][1][0].item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "x = [tup[0] for tup in sorted(feat_num_concept_arr)]\n",
    "y1 = [tup[1] for tup in sorted(feat_num_concept_arr)]\n",
    "y2 = [tup[1] for tup in sorted(feat_num_prob_arr)]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each line with different colors and markers\n",
    "plt.plot(np.array(x), y2, 'rs-', label='Prob, Label at Strength')  # Red line with squares\n",
    "\n",
    "# Label each point\n",
    "for i in range(len(x)):\n",
    "    # Labels for series\n",
    "    plt.annotate(f'({y2[i]:01f}, {y1[i]})', \n",
    "                (x[i], y2[i]), \n",
    "                textcoords=\"offset points\", \n",
    "                xytext=(0,-15),\n",
    "                ha='center')\n",
    "    \n",
    "# Customize the plot\n",
    "plt.xlabel('Feature Steering Strength (feat = Strength)')\n",
    "plt.ylabel('Probability of TPL, Top Predicted Label')\n",
    "plt.title(f'Most Likely Class by Feature Steering Strength, Feature {feat_num}\\n Label at 0.0: {steering_strength_image_results[str(0.0)][feat_num][image_idx][0][0]}. Label at max steered val ({str(max(steering_strengths))}): {steering_strength_image_results[str(max(steering_strengths))][feat_num][image_idx][0][0]}.')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to prevent label overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "\n",
    "# plt.savefig(\"test.svg\")\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# i = 0\n",
    "# for feat_num in steering_strength_info[steering_strength][0].keys():\n",
    "#     print(f\"=====================\\nfeat_num: {feat_num}\")\n",
    "#     feat_num_concept_arr = []\n",
    "#     feat_num_prob_arr = []\n",
    "#     feat_num_ratio_arr = []\n",
    "#     for key in steering_strength_info:\n",
    "#         print(key, steering_strength_info[key][0][feat_num])\n",
    "#         feat_num_concept_arr.append((key, steering_strength_info[key][0][feat_num]))\n",
    "#         print(key, steering_strength_info[key][1][feat_num])\n",
    "#         feat_num_prob_arr.append((key, steering_strength_info[key][1][feat_num].item()))\n",
    "#         print(key, steering_strength_info[key][2][feat_num])\n",
    "#         feat_num_ratio_arr.append((key, steering_strength_info[key][2][feat_num].item()))\n",
    "#     i += 1\n",
    "#     if i > 7:\n",
    "#         break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prev Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(feature_steered_embeds[random_feat_idxs[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_embeds.shape\n",
    "len(default_embeds_list)\n",
    "default_embeds = torch.cat(default_embeds_list)\n",
    "default_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "len(altered_embeds_list), altered_embeds_list[0].shape, default_embeds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "og_model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "with open(\"/workspace/clip_dissect_raw.txt\", \"r\") as f:\n",
    "    larger_vocab = [line[:-1] for line in f.readlines()][:5000]\n",
    "\n",
    "# with open(\"/workspace/better_img_desc.txt\", \"r\") as f:\n",
    "#     larger_vocab = [line[:-1] for line in f.readlines()][:5000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# use clip vocab here and compare embeds\n",
    "import torch\n",
    "from PIL import Image\n",
    "\n",
    "tokenizer = open_clip.get_tokenizer('ViT-B-32')\n",
    "text = tokenizer(larger_vocab)\n",
    "text_features = og_model.encode_text(text.cuda())\n",
    "text_features_normed = text_features/text_features.norm(dim=-1, keepdim=True)\n",
    "\n",
    "\n",
    "print(f\"text_features_normed.shape: {text_features_normed.shape}\")\n",
    "text_probs_altered_list = []\n",
    "with torch.no_grad(), torch.cuda.amp.autocast():\n",
    "    for key in feature_steered_embeds:\n",
    "        print(key)\n",
    "        # embeds already have L2 norm of 1\n",
    "        text_probs_altered = (100.0 * torch.stack(feature_steered_embeds[key]) @ text_features_normed.T).softmax(dim=-1)\n",
    "        text_probs_altered_list.append(text_probs_altered)\n",
    "    text_probs_default = (100.0 * default_embeds @ text_features_normed.T).softmax(dim=-1)\n",
    "\n",
    "print(\"Label probs altered:\", text_probs_altered.shape)  # prints: [[1., 0., 0.]]\n",
    "print(\"Label probs default:\", text_probs_default.shape)  # prints: [[1., 0., 0.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summed Logit Difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# subtract from default, label, and print trends\n",
    "text_probs_altered.shape\n",
    "\n",
    "# selected_vocab = all_imagenet_class_names\n",
    "selected_vocab = larger_vocab\n",
    "\n",
    "top_concept_per_feat = {}\n",
    "top_val_per_feat = {}\n",
    "top_diff_per_feat = {}\n",
    "top_ratio_per_feat = {}\n",
    "# run this for sampled features over all of imagenet eval\n",
    "for j, text_probs_altered in enumerate(text_probs_altered_list):\n",
    "    print(f\"{'============================================'*2}\\n\\nFor Feature {random_feat_idxs[j]}\")\n",
    "    print(\"actual image content:\")\n",
    "    default_vals_softmax, default_idxs_softmax = torch.topk(text_probs_default,k=10)\n",
    "    print(default_vals_softmax, \"\\n\", np.array(selected_vocab)[default_idxs_softmax.cpu()])\n",
    "    \n",
    "    \n",
    "    logit_diff = text_probs_altered - text_probs_default\n",
    "    logit_diff_aggregate = logit_diff.sum(dim=0)\n",
    "    \n",
    "    logit_ratio = text_probs_altered/text_probs_default\n",
    "    logit_ratio_aggregate = logit_ratio.mean(dim=0)\n",
    "    \n",
    "    print(f\"text_probs_altered.softmax(): {text_probs_altered.softmax(1).shape}\")\n",
    "    text_probs_altered_softmax = text_probs_altered.softmax(1)\n",
    "    vals_softmax, idxs_softmax = torch.topk(text_probs_altered_softmax,k=10)\n",
    "    \n",
    "#     print(f\"text_probs_altered.softmax(): {text_probs_altered.sum(0).softmax(0).shape}\")\n",
    "#     text_probs_altered_softmax_agg = text_probs_altered.sum(0).softmax(0)\n",
    "#     vals_softmax_agg, idxs_softmax_agg = torch.topk(text_probs_altered_softmax_agg,k=10)\n",
    "    \n",
    "    print(f\"\\nSoftmax Over {text_probs_altered.shape[0]} Images:\\n{vals_softmax}\")\n",
    "    print(np.array(selected_vocab)[idxs_softmax.cpu()])\n",
    "    for i in range(vals_softmax.shape[0]):\n",
    "        print(vals_softmax[i], \"\\n\", np.array(selected_vocab)[idxs_softmax.cpu()][i])\n",
    "        break\n",
    "        \n",
    "#     print(f\"\\nAgg Softmax Over {text_probs_altered.shape[0]} Images:\\n{vals_softmax_agg}\")\n",
    "#     print(np.array(selected_vocab)[idxs_softmax_agg.cpu()])\n",
    "    \n",
    "    vals_agg, idxs_agg = torch.topk(logit_diff_aggregate,k=10)\n",
    "    vals_least_agg, idxs_least_agg = torch.topk(logit_diff_aggregate,k=10,largest=False)\n",
    "    \n",
    "    ratios_agg, ratios_idxs_agg = torch.topk(logit_ratio_aggregate,k=10)\n",
    "    ratios_least_agg, ratios_idxs_least_agg = torch.topk(logit_ratio_aggregate,k=10,largest=False)\n",
    "    \n",
    "    vals, idxs = torch.topk(logit_diff,k=5)\n",
    "    vals_least, idxs_least = torch.topk(logit_diff,k=5,largest=False)\n",
    "    \n",
    "    ratios, ratios_idxs = torch.topk(logit_ratio,k=5)\n",
    "    ratios_least, ratios_idxs_least = torch.topk(logit_ratio,k=5,largest=False)\n",
    "    \n",
    "    top_concept_per_feat[random_feat_idxs[j]] = np.array(selected_vocab)[idxs_softmax.cpu()][0][0]\n",
    "    top_val_per_feat[random_feat_idxs[j]] = vals_softmax[0][0]\n",
    "    top_diff_per_feat[random_feat_idxs[j]] = vals_agg[0]\n",
    "    top_ratio_per_feat[random_feat_idxs[j]] = ratios_agg[0]\n",
    "    \n",
    "    \n",
    "    print(f\"\\nMost Changed, by Absolute Diff Over {logit_diff.shape[0]} Images:\\n{vals_agg}\")\n",
    "    print(np.array(selected_vocab)[idxs_agg.cpu()])\n",
    "    print(vals_least_agg)\n",
    "    print(np.array(selected_vocab)[idxs_least_agg.cpu()])\n",
    "    \n",
    "    print(f\"\\nMost Changed, by Ratio Over {logit_diff.shape[0]} Images:\")\n",
    "    print(ratios_agg)\n",
    "    print(np.array(selected_vocab)[ratios_idxs_agg.cpu()])\n",
    "    print(vals_least_agg)\n",
    "    print(np.array(selected_vocab)[ratios_idxs_least_agg.cpu()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_concept_per_feat,top_val_per_feat,top_ratio_per_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_strength_info = {}\n",
    "steering_strength_info[steering_strength] = (top_concept_per_feat,top_val_per_feat,top_ratio_per_feat,top_diff_per_feat)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "steering_strength_info[steering_strength][0].keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "steering_strength_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for feat_num in steering_strength_info[steering_strength][0].keys():\n",
    "    print(f\"=====================\\nfeat_num: {feat_num}\")\n",
    "    feat_num_concept_arr = []\n",
    "    feat_num_prob_arr = []\n",
    "    feat_num_ratio_arr = []\n",
    "    for key in steering_strength_info:\n",
    "        print(key, steering_strength_info[key][0][feat_num])\n",
    "        feat_num_concept_arr.append((key, steering_strength_info[key][0][feat_num]))\n",
    "        print(key, steering_strength_info[key][1][feat_num])\n",
    "        feat_num_prob_arr.append((key, steering_strength_info[key][1][feat_num].item()))\n",
    "        print(key, steering_strength_info[key][2][feat_num])\n",
    "        feat_num_ratio_arr.append((key, steering_strength_info[key][2][feat_num].item()))\n",
    "    i += 1\n",
    "    if i > 5:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(feat_num_concept_arr),sorted(feat_num_prob_arr),sorted(feat_num_ratio_arr),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "x = [tup[0] for tup in sorted(feat_num_concept_arr)]\n",
    "y1 = [tup[1] for tup in sorted(feat_num_concept_arr)]\n",
    "y2 = [tup[1] for tup in sorted(feat_num_prob_arr)]\n",
    "# y3 = [tup[1] for tup in sorted(feat_num_ratio_arr)]\n",
    "\n",
    "# Create the plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "\n",
    "# Plot each line with different colors and markers\n",
    "# plt.plot(x, y1, 'bo-', label='Series 1')  # Blue line with circles\n",
    "plt.plot(np.array(x), y2, 'rs-', label='Series 2')  # Red line with squares\n",
    "# plt.plot(x, y3, 'gd-', label='Series 3')  # Green line with diamonds\n",
    "\n",
    "# Label each point for all three series\n",
    "for i in range(len(x)):\n",
    "#     # Labels for series 1\n",
    "#     plt.annotate(f'({x[i]}, {y1[i]})', \n",
    "#                 (x[i], y1[i]), \n",
    "#                 textcoords=\"offset points\", \n",
    "#                 xytext=(0,10),\n",
    "#                 ha='center')\n",
    "    \n",
    "    # Labels for series 2\n",
    "    plt.annotate(f'({y2[i]:01f}, {y1[i]})', \n",
    "                (x[i], y2[i]), \n",
    "                textcoords=\"offset points\", \n",
    "                xytext=(0,-15),\n",
    "                ha='center')\n",
    "    \n",
    "#     # Labels for series 3\n",
    "#     plt.annotate(f'({x[i]}, {y3[i]})', \n",
    "#                 (x[i], y3[i]), \n",
    "#                 textcoords=\"offset points\", \n",
    "#                 xytext=(0,10),\n",
    "#                 ha='center')\n",
    "\n",
    "# Customize the plot\n",
    "plt.xlabel('X-axis')\n",
    "plt.ylabel('Y-axis')\n",
    "plt.title(f'Most Likely Class by Feature Steering Strength, Feature {feat_num}\\n Label at 0.0: {steering_strength_info[0.0][0][feat_num]}. Label at max steered val: {steering_strength_info[max(list(steering_strength_info.keys()))][0][feat_num]}.')\n",
    "plt.legend()\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "# Adjust layout to prevent label overlap\n",
    "plt.tight_layout()\n",
    "\n",
    "# Show the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enc/Dec Clustering/Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_weights_for_math = sparse_autoencoder.W_enc\n",
    "decoder_weights_for_math = sparse_autoencoder.W_dec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_from_feat_0 = encoder_weights_for_math[0] - encoder_weights_for_math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_from_feat_0_normalized = encoder_weights_for_math[0]/encoder_weights_for_math[0].norm(p=2) - encoder_weights_for_math/encoder_weights_for_math.norm(p=2,dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dists_from_feat_0.norm(p=2, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(bins[:-1], bins)\n",
    "plt.hist(dists_from_feat_0.norm(p=2, dim=0).cpu(), density=True, bins=1000, histtype='step')  # density=False would make counts\n",
    "plt.title('Encoder Dist from feat 0')\n",
    "plt.ylabel('L2 Distance')\n",
    "plt.xlabel('Density (of ~50k feats)');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(dists_from_feat_0.norm(p=2, dim=0),k=10,largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_dists_from_feat_0 = decoder_weights_for_math[0]/decoder_weights_for_math[0].norm(p=2) - decoder_weights_for_math/decoder_weights_for_math.norm(p=2)\n",
    "dec_dists_from_feat_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(bins[:-1], bins)\n",
    "plt.hist(dec_dists_from_feat_0.T.norm(p=2, dim=0).cpu(), density=True, bins=1000, histtype='step')  # density=False would make counts\n",
    "plt.title('Decoder Dist from feat 0')\n",
    "plt.ylabel('L2 Distance')\n",
    "plt.xlabel('Density (of ~50k feats)');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.topk(dec_dists_from_feat_0.T.norm(p=2, dim=0),k=10,largest=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dec_dists_from_feat_0.T.norm(p=2, dim=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
